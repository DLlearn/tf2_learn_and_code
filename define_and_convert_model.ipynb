{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test 是干扰模型，test_class是分类模型\n",
    "测试结果：\n",
    "intel 异步结果：\n",
    "\n",
    "model|FPS\n",
    ":-:|:-:\n",
    "model1|378\n",
    "model2|106\n",
    "\n",
    "我们自己的同步：\n",
    "\n",
    "model|FPS\n",
    ":-:|:-:\n",
    "model1|207\n",
    "model2|40.5\n",
    "\n",
    "我们的异步：\n",
    "\n",
    "model1:\n",
    "infer request=6\n",
    "FPS=274\n",
    "model2:\n",
    "infer request=4\n",
    "FPS=74"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01-13 11:03:47,540 INFO:Hello world!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "#from importlib import reload  # Not needed in Python 2\n",
    "import logging as log\n",
    "#reload(logging)\n",
    "log.basicConfig(format='%(asctime)s %(levelname)s:%(message)s', level=log.INFO,stream=sys.stdout)\n",
    "log.info('Hello world!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "import shutil\n",
    "import tensorflow.contrib.slim as slim\n",
    "from tensorflow.contrib.layers.python.layers import utils \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The path(test) is exist,do you want to delete it and remake?(y/n):\n",
      "y\n",
      "____________________________model output shape_______________________________\n",
      "name: test_model/conv1/Relu   shape: [None, 1, 500, 128]\n",
      "name: test_model/conv1-1/Relu   shape: [None, 1, 500, 128]\n",
      "name: test_model/pool1/MaxPool   shape: [None, 1, 250, 128]\n",
      "name: test_model/conv2/Relu   shape: [None, 1, 250, 256]\n",
      "name: test_model/pool2/MaxPool   shape: [None, 1, 125, 256]\n",
      "name: test_model/conv3/Relu   shape: [None, 1, 125, 256]\n",
      "name: test_model/pool3/MaxPool   shape: [None, 1, 62, 256]\n",
      "name: test_model/fc1/Relu   shape: [None, 256]\n",
      "name: test_model/fc2/Relu   shape: [None, 512]\n",
      "name: test_model/logits/BiasAdd   shape: [None, 3]\n",
      "name: test_model/predictions/Reshape_1   shape: [None, 3]\n",
      "2020-01-07 19:18:19,887 INFO:Froze 12 variables.\n",
      "2020-01-07 19:18:19,907 INFO:Converted 12 variables to const ops.\n",
      "node: input_node\n",
      "node: test_model/conv1-1/weights\n",
      "node: test_model/conv1-1/biases\n",
      "node: test_model/conv1-1/Conv2D\n",
      "node: test_model/conv1-1/BiasAdd\n",
      "node: test_model/conv1-1/Relu\n",
      "node: test_model/pool1/MaxPool\n",
      "node: test_model/conv2/weights\n",
      "node: test_model/conv2/biases\n",
      "node: test_model/conv2/Conv2D\n",
      "node: test_model/conv2/BiasAdd\n",
      "node: test_model/conv2/Relu\n",
      "node: test_model/pool2/MaxPool\n",
      "node: test_model/conv3/weights\n",
      "node: test_model/conv3/biases\n",
      "node: test_model/conv3/Conv2D\n",
      "node: test_model/conv3/BiasAdd\n",
      "node: test_model/conv3/Relu\n",
      "node: test_model/pool3/MaxPool\n",
      "node: test_model/Reshape/shape\n",
      "node: test_model/Reshape\n",
      "node: test_model/fc1/weights\n",
      "node: test_model/fc1/biases\n",
      "node: test_model/fc1/MatMul\n",
      "node: test_model/fc1/BiasAdd\n",
      "node: test_model/fc1/Relu\n",
      "node: test_model/fc2/weights\n",
      "node: test_model/fc2/biases\n",
      "node: test_model/fc2/MatMul\n",
      "node: test_model/fc2/BiasAdd\n",
      "node: test_model/fc2/Relu\n",
      "node: test_model/logits/weights\n",
      "node: test_model/logits/biases\n",
      "node: test_model/logits/MatMul\n",
      "node: test_model/logits/BiasAdd\n",
      "node: myoutputnode\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "@slim.add_arg_scope\n",
    "def block(inputs, fir, sec, thir, four, name, outputs_collections = None):\n",
    "    with tf.variable_scope(name) as scope:\n",
    "        branch_1x3 = slim.conv2d(inputs, fir, [1, 5], [1, 1], padding = \"SAME\", scope = 'branch_1x5')\n",
    "        branch_1x7 = slim.conv2d(inputs, sec, [1, 9], [1, 1], padding = \"SAME\", scope = 'branch_1x9')\n",
    "        branch_1x11 = slim.conv2d(inputs, thir, [1, 21], [1, 1], padding = \"SAME\", scope = 'branch_1x21')\n",
    "\n",
    "        branch_poola = slim.avg_pool2d(inputs, [1, 5], [1, 1], padding = \"SAME\", scope = 'branch_poola')\n",
    "        branch_poolb = slim.conv2d(branch_poola, four, [1, 1], [1, 1], padding = \"SAME\", scope = 'branch_poolb')\n",
    "        out = tf.concat(axis = 3, values = [branch_1x3, branch_1x7, branch_1x11, branch_poolb])\n",
    "        out = slim.utils.collect_named_outputs(outputs_collections, scope.name, out)\n",
    "\n",
    "        return out\n",
    "def inceptionv1_arg_scope(weight_decay = 0.0005):\n",
    "    with slim.arg_scope([slim.variable, slim.model_variable], device = '/cpu:0'):\n",
    "        with slim.arg_scope(\n",
    "                [slim.conv2d, slim.fully_connected],\n",
    "                weights_initializer = slim.variance_scaling_initializer(),\n",
    "                weights_regularizer = slim.l2_regularizer(weight_decay),\n",
    "                activation_fn = tf.nn.relu,\n",
    "                biases_initializer = tf.zeros_initializer()):\n",
    "            with slim.arg_scope([slim.conv2d], padding = 'SAME'):\n",
    "                with slim.arg_scope([slim.avg_pool2d], padding = 'SAME') as arg_sc:\n",
    "                    return arg_sc\n",
    "def noise(inputs,\n",
    "          num_classes = 1000,\n",
    "          dropout_keep_prob = 0.5,\n",
    "          is_training=True):\n",
    "    with tf.variable_scope('test_model', [inputs, num_classes]) as sc:\n",
    "#         tf.reset_default_graph()\n",
    "        # Collect outputs for conv2d, fully_connected and max_pool2d.\n",
    "        end_points_collection = sc.original_name_scope + 'end_points'\n",
    "        with slim.arg_scope(\n",
    "                [slim.conv2d, slim.fully_connected, slim.max_pool2d],\n",
    "                outputs_collections = end_points_collection):\n",
    "            net = slim.conv2d(inputs, 128, [1, 5], [1, 1], scope = 'conv1')  # 496\n",
    "            net = slim.conv2d(inputs, 128, [1, 5], [1, 1], scope = 'conv1-1')  # 496\n",
    "            net = slim.max_pool2d(net, [1, 2], [1, 2], scope = 'pool1')  # 248\n",
    "            net = slim.conv2d(net, 256, [1, 5], [1, 1], scope = 'conv2')  # 244\n",
    "            net = slim.max_pool2d(net, [1, 2], [1, 2], scope = 'pool2')  # 122\n",
    "            net = slim.conv2d(net, 256, [1, 5], [1, 1], scope = 'conv3')  # 118\n",
    "            net = slim.max_pool2d(net, [1, 2], [1, 2], scope = 'pool3')  # 59\n",
    "            shape = net.get_shape().as_list()\n",
    "            net = tf.reshape(net, [-1, shape[1] * shape[2] * shape[3]])\n",
    "            net = slim.fully_connected(net, 256, scope = 'fc1')\n",
    "            net = slim.fully_connected(net, 512, scope = 'fc2')\n",
    "#             net = slim.dropout(net, dropout_keep_prob, scope = 'dropout2')\n",
    "            net = slim.fully_connected(net, num_classes, activation_fn = None, scope = 'logits')\n",
    "            end_points = utils.convert_collection_to_dict(end_points_collection)\n",
    "            if num_classes is not None:\n",
    "                end_points['predictions'] = slim.softmax(net, scope = 'predictions')\n",
    "            return net, end_points\n",
    "\n",
    "    \n",
    "def _activation_summary(x):\n",
    "\n",
    "    print(\"name:\", x.op.name, ' ', \"shape:\", x.get_shape().as_list())\n",
    "\n",
    "def _activation_summaries(endpoints):\n",
    "    with tf.name_scope('summaries'):\n",
    "        print('____________________________model output shape_______________________________')\n",
    "        for act in endpoints.values():\n",
    "            _activation_summary(act)\n",
    "def inference_inceptionv1(images, num_classes, is_training = False):\n",
    "    with slim.arg_scope(inceptionv1_arg_scope()):\n",
    "        logits, endpoints = noise(\n",
    "            images,\n",
    "            dropout_keep_prob = 0.5,\n",
    "            num_classes = num_classes,\n",
    "            is_training = is_training)\n",
    "\n",
    "    # Add summaries for viewing model statistics on TensorBoard.\n",
    "    _activation_summaries(endpoints)\n",
    "\n",
    "    # Grab the logits associated with the side head. Employed during training.\n",
    "\n",
    "    return logits\n",
    "\n",
    "test='test'\n",
    "model_out='test/model_out'\n",
    "model_converted='test/model_converted'\n",
    "if os.path.exists(test):\n",
    "    t=input(\"The path(%s) is exist,do you want to delete it and remake?(y/n):\\n\" %(test,)).strip()\n",
    "    while t not in ['y','n']:\n",
    "        t = input(\"your input is invalid,please input again(y/n):\\n\")\n",
    "    if t =='y':\n",
    "        shutil.rmtree(test)\n",
    "        os.makedirs(model_out)\n",
    "        os.makedirs(model_converted)\n",
    "    else:\n",
    "        pass\n",
    "else:\n",
    "    print(\"The test path is not exist! make it !\\n\")\n",
    "    os.makedirs(model_out)\n",
    "    os.makedirs(model_converted)\n",
    "       \n",
    "    \n",
    "with tf.Graph().as_default() as g:\n",
    "    images=tf.placeholder(dtype=tf.float32,shape=(None,1,500,1),name='input_node')\n",
    "    logits = inference_inceptionv1(images, 3, is_training = False)\n",
    "    probs = tf.nn.softmax(logits,name='myoutputnode')\n",
    "    saver=tf.train.Saver()\n",
    "    tf.set_random_seed(123)\n",
    "    init = tf.global_variables_initializer()\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        saver.save(sess,model_out+'/model.ckpt')\n",
    "        graph = tf.get_default_graph()\n",
    "        input_graph_def = graph.as_graph_def()\n",
    "        output_graph_def = tf.graph_util.convert_variables_to_constants(\n",
    "            sess,\n",
    "            input_graph_def,\n",
    "            ['myoutputnode']\n",
    "        )\n",
    "        outgraph=tf.graph_util.remove_training_nodes(output_graph_def)\n",
    "        for node in outgraph.node:\n",
    "            print('node:',node.name)\n",
    "        tf.train.write_graph(outgraph,model_out,'frozen_model.pb',as_text=False)\n",
    "        tf.train.write_graph(outgraph,model_out,'frozen_model.pbtxt')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[setupvars.sh] OpenVINO environment initialized\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "source /opt/intel/openvino/bin/setupvars.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Optimizer arguments:\n",
      "Common parameters:\n",
      "\t- Path to the Input Model: \t/home/tianliang/2019r3/./test/model_out/frozen_model.pb\n",
      "\t- Path for generated IR: \t/home/tianliang/2019r3/./test/model_converted/model_fp16\n",
      "\t- IR output name: \tmodel_fp16\n",
      "\t- Log level: \tERROR\n",
      "\t- Batch: \tNot specified, inherited from the model\n",
      "\t- Input layers: \tinput_node\n",
      "\t- Output layers: \tmyoutputnode\n",
      "\t- Input shapes: \t[1,1,500,1]\n",
      "\t- Mean values: \tNot specified\n",
      "\t- Scale values: \tNot specified\n",
      "\t- Scale factor: \tNot specified\n",
      "\t- Precision of IR: \tFP16\n",
      "\t- Enable fusing: \tTrue\n",
      "\t- Enable grouped convolutions fusing: \tTrue\n",
      "\t- Move mean values to preprocess section: \tFalse\n",
      "\t- Reverse input channels: \tFalse\n",
      "TensorFlow specific parameters:\n",
      "\t- Input model in text protobuf format: \tFalse\n",
      "\t- Path to model dump for TensorBoard: \tNone\n",
      "\t- List of shared libraries with TensorFlow custom layers implementation: \tNone\n",
      "\t- Update the configuration file with input/output node names: \tNone\n",
      "\t- Use configuration file used to generate the model with Object Detection API: \tNone\n",
      "\t- Operations to offload: \tNone\n",
      "\t- Patterns to offload: \tNone\n",
      "\t- Use the config file: \tNone\n",
      "Model Optimizer version: \t2019.3.0-408-gac8584cb7\n",
      "\n",
      "[ SUCCESS ] Generated IR model.\n",
      "[ SUCCESS ] XML file: /home/tianliang/2019r3/./test/model_converted/model_fp16/model_fp16.xml\n",
      "[ SUCCESS ] BIN file: /home/tianliang/2019r3/./test/model_converted/model_fp16/model_fp16.bin\n",
      "[ SUCCESS ] Total execution time: 3.69 seconds. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "scribe=\"/opt/intel/openvino/deployment_tools/model_optimizer/mo_tf.py\"\n",
    "python3 $scribe --input input_node --output myoutputnode --input_model ./test/model_out/frozen_model.pb --model_name model_fp16 --output_dir ./test/model_converted/model_fp16 --log_level=ERROR --data_type=FP16 --input_shape [1,1,500,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The path(test_class) is exist,do you want to delete it and remake?(y/n):\n",
      "y\n",
      "[None, 1, 6, 480]\n",
      "____________________________model output shape_______________________________\n",
      "name: inceptionv1/conv1/Relu   shape: [None, 1, 498, 64]\n",
      "name: inceptionv1/pool1/MaxPool   shape: [None, 1, 248, 64]\n",
      "name: inceptionv1/conv2/Relu   shape: [None, 1, 248, 96]\n",
      "name: inceptionv1/pool2/MaxPool   shape: [None, 1, 123, 96]\n",
      "name: inceptionv1/mixed_128/branch_1x5/Relu   shape: [None, 1, 123, 32]\n",
      "name: inceptionv1/mixed_128/branch_1x9/Relu   shape: [None, 1, 123, 64]\n",
      "name: inceptionv1/mixed_128/branch_1x21/Relu   shape: [None, 1, 123, 16]\n",
      "name: inceptionv1/mixed_128/branch_poolb/Relu   shape: [None, 1, 123, 16]\n",
      "name: inceptionv1/mixed_128/concat   shape: [None, 1, 123, 128]\n",
      "name: inceptionv1/mixed_240/branch_1x5/Relu   shape: [None, 1, 123, 64]\n",
      "name: inceptionv1/mixed_240/branch_1x9/Relu   shape: [None, 1, 123, 96]\n",
      "name: inceptionv1/mixed_240/branch_1x21/Relu   shape: [None, 1, 123, 48]\n",
      "name: inceptionv1/mixed_240/branch_poolb/Relu   shape: [None, 1, 123, 32]\n",
      "name: inceptionv1/mixed_240/concat   shape: [None, 1, 123, 240]\n",
      "name: inceptionv1/pool_after_mixed_240/MaxPool   shape: [None, 1, 61, 240]\n",
      "name: inceptionv1/mixed_264/branch_1x5/Relu   shape: [None, 1, 61, 96]\n",
      "name: inceptionv1/mixed_264/branch_1x9/Relu   shape: [None, 1, 61, 112]\n",
      "name: inceptionv1/mixed_264/branch_1x21/Relu   shape: [None, 1, 61, 24]\n",
      "name: inceptionv1/mixed_264/branch_poolb/Relu   shape: [None, 1, 61, 32]\n",
      "name: inceptionv1/mixed_264/concat   shape: [None, 1, 61, 264]\n",
      "name: inceptionv1/mixed_272_1/branch_1x5/Relu   shape: [None, 1, 61, 80]\n",
      "name: inceptionv1/mixed_272_1/branch_1x9/Relu   shape: [None, 1, 61, 128]\n",
      "name: inceptionv1/mixed_272_1/branch_1x21/Relu   shape: [None, 1, 61, 32]\n",
      "name: inceptionv1/mixed_272_1/branch_poolb/Relu   shape: [None, 1, 61, 32]\n",
      "name: inceptionv1/mixed_272_1/concat   shape: [None, 1, 61, 272]\n",
      "name: inceptionv1/pool_after_mixed_272_1/MaxPool   shape: [None, 1, 30, 272]\n",
      "name: inceptionv1/mixed_272_2/branch_1x5/Relu   shape: [None, 1, 30, 64]\n",
      "name: inceptionv1/mixed_272_2/branch_1x9/Relu   shape: [None, 1, 30, 144]\n",
      "name: inceptionv1/mixed_272_2/branch_1x21/Relu   shape: [None, 1, 30, 32]\n",
      "name: inceptionv1/mixed_272_2/branch_poolb/Relu   shape: [None, 1, 30, 32]\n",
      "name: inceptionv1/mixed_272_2/concat   shape: [None, 1, 30, 272]\n",
      "name: inceptionv1/mixed_384_1/branch_1x5/Relu   shape: [None, 1, 30, 96]\n",
      "name: inceptionv1/mixed_384_1/branch_1x9/Relu   shape: [None, 1, 30, 160]\n",
      "name: inceptionv1/mixed_384_1/branch_1x21/Relu   shape: [None, 1, 30, 64]\n",
      "name: inceptionv1/mixed_384_1/branch_poolb/Relu   shape: [None, 1, 30, 64]\n",
      "name: inceptionv1/mixed_384_1/concat   shape: [None, 1, 30, 384]\n",
      "name: inceptionv1/pool_after_mixed_384_1/MaxPool   shape: [None, 1, 14, 384]\n",
      "name: inceptionv1/mixed_384_2/branch_1x5/Relu   shape: [None, 1, 14, 96]\n",
      "name: inceptionv1/mixed_384_2/branch_1x9/Relu   shape: [None, 1, 14, 160]\n",
      "name: inceptionv1/mixed_384_2/branch_1x21/Relu   shape: [None, 1, 14, 64]\n",
      "name: inceptionv1/mixed_384_2/branch_poolb/Relu   shape: [None, 1, 14, 64]\n",
      "name: inceptionv1/mixed_384_2/concat   shape: [None, 1, 14, 384]\n",
      "name: inceptionv1/mixed_480/branch_1x5/Relu   shape: [None, 1, 14, 128]\n",
      "name: inceptionv1/mixed_480/branch_1x9/Relu   shape: [None, 1, 14, 192]\n",
      "name: inceptionv1/mixed_480/branch_1x21/Relu   shape: [None, 1, 14, 80]\n",
      "name: inceptionv1/mixed_480/branch_poolb/Relu   shape: [None, 1, 14, 80]\n",
      "name: inceptionv1/mixed_480/concat   shape: [None, 1, 14, 480]\n",
      "name: inceptionv1/pool_after_mixed_288/MaxPool   shape: [None, 1, 6, 480]\n",
      "name: inceptionv1/conv_fc1/Relu   shape: [None, 1, 1, 512]\n",
      "name: inceptionv1/conv_fc2/Relu   shape: [None, 1, 1, 512]\n",
      "name: inceptionv1/logits/BiasAdd   shape: [None, 1, 1, 12]\n",
      "name: inceptionv1/predictions/Reshape_1   shape: [None, 12]\n",
      "2020-01-07 19:21:04,115 INFO:Froze 74 variables.\n",
      "2020-01-07 19:21:04,139 INFO:Converted 74 variables to const ops.\n",
      "node: input_node\n",
      "node: inceptionv1/conv1/weights\n",
      "node: inceptionv1/conv1/biases\n",
      "node: inceptionv1/conv1/Conv2D\n",
      "node: inceptionv1/conv1/BiasAdd\n",
      "node: inceptionv1/conv1/Relu\n",
      "node: inceptionv1/pool1/MaxPool\n",
      "node: inceptionv1/conv2/weights\n",
      "node: inceptionv1/conv2/biases\n",
      "node: inceptionv1/conv2/Conv2D\n",
      "node: inceptionv1/conv2/BiasAdd\n",
      "node: inceptionv1/conv2/Relu\n",
      "node: inceptionv1/pool2/MaxPool\n",
      "node: inceptionv1/mixed_128/branch_1x5/weights\n",
      "node: inceptionv1/mixed_128/branch_1x5/biases\n",
      "node: inceptionv1/mixed_128/branch_1x5/Conv2D\n",
      "node: inceptionv1/mixed_128/branch_1x5/BiasAdd\n",
      "node: inceptionv1/mixed_128/branch_1x5/Relu\n",
      "node: inceptionv1/mixed_128/branch_1x9/weights\n",
      "node: inceptionv1/mixed_128/branch_1x9/biases\n",
      "node: inceptionv1/mixed_128/branch_1x9/Conv2D\n",
      "node: inceptionv1/mixed_128/branch_1x9/BiasAdd\n",
      "node: inceptionv1/mixed_128/branch_1x9/Relu\n",
      "node: inceptionv1/mixed_128/branch_1x21/weights\n",
      "node: inceptionv1/mixed_128/branch_1x21/biases\n",
      "node: inceptionv1/mixed_128/branch_1x21/Conv2D\n",
      "node: inceptionv1/mixed_128/branch_1x21/BiasAdd\n",
      "node: inceptionv1/mixed_128/branch_1x21/Relu\n",
      "node: inceptionv1/mixed_128/branch_poola/AvgPool\n",
      "node: inceptionv1/mixed_128/branch_poolb/weights\n",
      "node: inceptionv1/mixed_128/branch_poolb/biases\n",
      "node: inceptionv1/mixed_128/branch_poolb/Conv2D\n",
      "node: inceptionv1/mixed_128/branch_poolb/BiasAdd\n",
      "node: inceptionv1/mixed_128/branch_poolb/Relu\n",
      "node: inceptionv1/mixed_128/concat/axis\n",
      "node: inceptionv1/mixed_128/concat\n",
      "node: inceptionv1/mixed_240/branch_1x5/weights\n",
      "node: inceptionv1/mixed_240/branch_1x5/biases\n",
      "node: inceptionv1/mixed_240/branch_1x5/Conv2D\n",
      "node: inceptionv1/mixed_240/branch_1x5/BiasAdd\n",
      "node: inceptionv1/mixed_240/branch_1x5/Relu\n",
      "node: inceptionv1/mixed_240/branch_1x9/weights\n",
      "node: inceptionv1/mixed_240/branch_1x9/biases\n",
      "node: inceptionv1/mixed_240/branch_1x9/Conv2D\n",
      "node: inceptionv1/mixed_240/branch_1x9/BiasAdd\n",
      "node: inceptionv1/mixed_240/branch_1x9/Relu\n",
      "node: inceptionv1/mixed_240/branch_1x21/weights\n",
      "node: inceptionv1/mixed_240/branch_1x21/biases\n",
      "node: inceptionv1/mixed_240/branch_1x21/Conv2D\n",
      "node: inceptionv1/mixed_240/branch_1x21/BiasAdd\n",
      "node: inceptionv1/mixed_240/branch_1x21/Relu\n",
      "node: inceptionv1/mixed_240/branch_poola/AvgPool\n",
      "node: inceptionv1/mixed_240/branch_poolb/weights\n",
      "node: inceptionv1/mixed_240/branch_poolb/biases\n",
      "node: inceptionv1/mixed_240/branch_poolb/Conv2D\n",
      "node: inceptionv1/mixed_240/branch_poolb/BiasAdd\n",
      "node: inceptionv1/mixed_240/branch_poolb/Relu\n",
      "node: inceptionv1/mixed_240/concat/axis\n",
      "node: inceptionv1/mixed_240/concat\n",
      "node: inceptionv1/pool_after_mixed_240/MaxPool\n",
      "node: inceptionv1/mixed_264/branch_1x5/weights\n",
      "node: inceptionv1/mixed_264/branch_1x5/biases\n",
      "node: inceptionv1/mixed_264/branch_1x5/Conv2D\n",
      "node: inceptionv1/mixed_264/branch_1x5/BiasAdd\n",
      "node: inceptionv1/mixed_264/branch_1x5/Relu\n",
      "node: inceptionv1/mixed_264/branch_1x9/weights\n",
      "node: inceptionv1/mixed_264/branch_1x9/biases\n",
      "node: inceptionv1/mixed_264/branch_1x9/Conv2D\n",
      "node: inceptionv1/mixed_264/branch_1x9/BiasAdd\n",
      "node: inceptionv1/mixed_264/branch_1x9/Relu\n",
      "node: inceptionv1/mixed_264/branch_1x21/weights\n",
      "node: inceptionv1/mixed_264/branch_1x21/biases\n",
      "node: inceptionv1/mixed_264/branch_1x21/Conv2D\n",
      "node: inceptionv1/mixed_264/branch_1x21/BiasAdd\n",
      "node: inceptionv1/mixed_264/branch_1x21/Relu\n",
      "node: inceptionv1/mixed_264/branch_poola/AvgPool\n",
      "node: inceptionv1/mixed_264/branch_poolb/weights\n",
      "node: inceptionv1/mixed_264/branch_poolb/biases\n",
      "node: inceptionv1/mixed_264/branch_poolb/Conv2D\n",
      "node: inceptionv1/mixed_264/branch_poolb/BiasAdd\n",
      "node: inceptionv1/mixed_264/branch_poolb/Relu\n",
      "node: inceptionv1/mixed_264/concat/axis\n",
      "node: inceptionv1/mixed_264/concat\n",
      "node: inceptionv1/mixed_272_1/branch_1x5/weights\n",
      "node: inceptionv1/mixed_272_1/branch_1x5/biases\n",
      "node: inceptionv1/mixed_272_1/branch_1x5/Conv2D\n",
      "node: inceptionv1/mixed_272_1/branch_1x5/BiasAdd\n",
      "node: inceptionv1/mixed_272_1/branch_1x5/Relu\n",
      "node: inceptionv1/mixed_272_1/branch_1x9/weights\n",
      "node: inceptionv1/mixed_272_1/branch_1x9/biases\n",
      "node: inceptionv1/mixed_272_1/branch_1x9/Conv2D\n",
      "node: inceptionv1/mixed_272_1/branch_1x9/BiasAdd\n",
      "node: inceptionv1/mixed_272_1/branch_1x9/Relu\n",
      "node: inceptionv1/mixed_272_1/branch_1x21/weights\n",
      "node: inceptionv1/mixed_272_1/branch_1x21/biases\n",
      "node: inceptionv1/mixed_272_1/branch_1x21/Conv2D\n",
      "node: inceptionv1/mixed_272_1/branch_1x21/BiasAdd\n",
      "node: inceptionv1/mixed_272_1/branch_1x21/Relu\n",
      "node: inceptionv1/mixed_272_1/branch_poola/AvgPool\n",
      "node: inceptionv1/mixed_272_1/branch_poolb/weights\n",
      "node: inceptionv1/mixed_272_1/branch_poolb/biases\n",
      "node: inceptionv1/mixed_272_1/branch_poolb/Conv2D\n",
      "node: inceptionv1/mixed_272_1/branch_poolb/BiasAdd\n",
      "node: inceptionv1/mixed_272_1/branch_poolb/Relu\n",
      "node: inceptionv1/mixed_272_1/concat/axis\n",
      "node: inceptionv1/mixed_272_1/concat\n",
      "node: inceptionv1/pool_after_mixed_272_1/MaxPool\n",
      "node: inceptionv1/mixed_272_2/branch_1x5/weights\n",
      "node: inceptionv1/mixed_272_2/branch_1x5/biases\n",
      "node: inceptionv1/mixed_272_2/branch_1x5/Conv2D\n",
      "node: inceptionv1/mixed_272_2/branch_1x5/BiasAdd\n",
      "node: inceptionv1/mixed_272_2/branch_1x5/Relu\n",
      "node: inceptionv1/mixed_272_2/branch_1x9/weights\n",
      "node: inceptionv1/mixed_272_2/branch_1x9/biases\n",
      "node: inceptionv1/mixed_272_2/branch_1x9/Conv2D\n",
      "node: inceptionv1/mixed_272_2/branch_1x9/BiasAdd\n",
      "node: inceptionv1/mixed_272_2/branch_1x9/Relu\n",
      "node: inceptionv1/mixed_272_2/branch_1x21/weights\n",
      "node: inceptionv1/mixed_272_2/branch_1x21/biases\n",
      "node: inceptionv1/mixed_272_2/branch_1x21/Conv2D\n",
      "node: inceptionv1/mixed_272_2/branch_1x21/BiasAdd\n",
      "node: inceptionv1/mixed_272_2/branch_1x21/Relu\n",
      "node: inceptionv1/mixed_272_2/branch_poola/AvgPool\n",
      "node: inceptionv1/mixed_272_2/branch_poolb/weights\n",
      "node: inceptionv1/mixed_272_2/branch_poolb/biases\n",
      "node: inceptionv1/mixed_272_2/branch_poolb/Conv2D\n",
      "node: inceptionv1/mixed_272_2/branch_poolb/BiasAdd\n",
      "node: inceptionv1/mixed_272_2/branch_poolb/Relu\n",
      "node: inceptionv1/mixed_272_2/concat/axis\n",
      "node: inceptionv1/mixed_272_2/concat\n",
      "node: inceptionv1/mixed_384_1/branch_1x5/weights\n",
      "node: inceptionv1/mixed_384_1/branch_1x5/biases\n",
      "node: inceptionv1/mixed_384_1/branch_1x5/Conv2D\n",
      "node: inceptionv1/mixed_384_1/branch_1x5/BiasAdd\n",
      "node: inceptionv1/mixed_384_1/branch_1x5/Relu\n",
      "node: inceptionv1/mixed_384_1/branch_1x9/weights\n",
      "node: inceptionv1/mixed_384_1/branch_1x9/biases\n",
      "node: inceptionv1/mixed_384_1/branch_1x9/Conv2D\n",
      "node: inceptionv1/mixed_384_1/branch_1x9/BiasAdd\n",
      "node: inceptionv1/mixed_384_1/branch_1x9/Relu\n",
      "node: inceptionv1/mixed_384_1/branch_1x21/weights\n",
      "node: inceptionv1/mixed_384_1/branch_1x21/biases\n",
      "node: inceptionv1/mixed_384_1/branch_1x21/Conv2D\n",
      "node: inceptionv1/mixed_384_1/branch_1x21/BiasAdd\n",
      "node: inceptionv1/mixed_384_1/branch_1x21/Relu\n",
      "node: inceptionv1/mixed_384_1/branch_poola/AvgPool\n",
      "node: inceptionv1/mixed_384_1/branch_poolb/weights\n",
      "node: inceptionv1/mixed_384_1/branch_poolb/biases\n",
      "node: inceptionv1/mixed_384_1/branch_poolb/Conv2D\n",
      "node: inceptionv1/mixed_384_1/branch_poolb/BiasAdd\n",
      "node: inceptionv1/mixed_384_1/branch_poolb/Relu\n",
      "node: inceptionv1/mixed_384_1/concat/axis\n",
      "node: inceptionv1/mixed_384_1/concat\n",
      "node: inceptionv1/pool_after_mixed_384_1/MaxPool\n",
      "node: inceptionv1/mixed_384_2/branch_1x5/weights\n",
      "node: inceptionv1/mixed_384_2/branch_1x5/biases\n",
      "node: inceptionv1/mixed_384_2/branch_1x5/Conv2D\n",
      "node: inceptionv1/mixed_384_2/branch_1x5/BiasAdd\n",
      "node: inceptionv1/mixed_384_2/branch_1x5/Relu\n",
      "node: inceptionv1/mixed_384_2/branch_1x9/weights\n",
      "node: inceptionv1/mixed_384_2/branch_1x9/biases\n",
      "node: inceptionv1/mixed_384_2/branch_1x9/Conv2D\n",
      "node: inceptionv1/mixed_384_2/branch_1x9/BiasAdd\n",
      "node: inceptionv1/mixed_384_2/branch_1x9/Relu\n",
      "node: inceptionv1/mixed_384_2/branch_1x21/weights\n",
      "node: inceptionv1/mixed_384_2/branch_1x21/biases\n",
      "node: inceptionv1/mixed_384_2/branch_1x21/Conv2D\n",
      "node: inceptionv1/mixed_384_2/branch_1x21/BiasAdd\n",
      "node: inceptionv1/mixed_384_2/branch_1x21/Relu\n",
      "node: inceptionv1/mixed_384_2/branch_poola/AvgPool\n",
      "node: inceptionv1/mixed_384_2/branch_poolb/weights\n",
      "node: inceptionv1/mixed_384_2/branch_poolb/biases\n",
      "node: inceptionv1/mixed_384_2/branch_poolb/Conv2D\n",
      "node: inceptionv1/mixed_384_2/branch_poolb/BiasAdd\n",
      "node: inceptionv1/mixed_384_2/branch_poolb/Relu\n",
      "node: inceptionv1/mixed_384_2/concat/axis\n",
      "node: inceptionv1/mixed_384_2/concat\n",
      "node: inceptionv1/mixed_480/branch_1x5/weights\n",
      "node: inceptionv1/mixed_480/branch_1x5/biases\n",
      "node: inceptionv1/mixed_480/branch_1x5/Conv2D\n",
      "node: inceptionv1/mixed_480/branch_1x5/BiasAdd\n",
      "node: inceptionv1/mixed_480/branch_1x5/Relu\n",
      "node: inceptionv1/mixed_480/branch_1x9/weights\n",
      "node: inceptionv1/mixed_480/branch_1x9/biases\n",
      "node: inceptionv1/mixed_480/branch_1x9/Conv2D\n",
      "node: inceptionv1/mixed_480/branch_1x9/BiasAdd\n",
      "node: inceptionv1/mixed_480/branch_1x9/Relu\n",
      "node: inceptionv1/mixed_480/branch_1x21/weights\n",
      "node: inceptionv1/mixed_480/branch_1x21/biases\n",
      "node: inceptionv1/mixed_480/branch_1x21/Conv2D\n",
      "node: inceptionv1/mixed_480/branch_1x21/BiasAdd\n",
      "node: inceptionv1/mixed_480/branch_1x21/Relu\n",
      "node: inceptionv1/mixed_480/branch_poola/AvgPool\n",
      "node: inceptionv1/mixed_480/branch_poolb/weights\n",
      "node: inceptionv1/mixed_480/branch_poolb/biases\n",
      "node: inceptionv1/mixed_480/branch_poolb/Conv2D\n",
      "node: inceptionv1/mixed_480/branch_poolb/BiasAdd\n",
      "node: inceptionv1/mixed_480/branch_poolb/Relu\n",
      "node: inceptionv1/mixed_480/concat/axis\n",
      "node: inceptionv1/mixed_480/concat\n",
      "node: inceptionv1/pool_after_mixed_288/MaxPool\n",
      "node: inceptionv1/pool_end/AvgPool\n",
      "node: inceptionv1/conv_fc1/weights\n",
      "node: inceptionv1/conv_fc1/biases\n",
      "node: inceptionv1/conv_fc1/Conv2D\n",
      "node: inceptionv1/conv_fc1/BiasAdd\n",
      "node: inceptionv1/conv_fc1/Relu\n",
      "node: inceptionv1/conv_fc2/weights\n",
      "node: inceptionv1/conv_fc2/biases\n",
      "node: inceptionv1/conv_fc2/Conv2D\n",
      "node: inceptionv1/conv_fc2/BiasAdd\n",
      "node: inceptionv1/conv_fc2/Relu\n",
      "node: inceptionv1/logits/weights\n",
      "node: inceptionv1/logits/biases\n",
      "node: inceptionv1/logits/Tensordot/Shape\n",
      "node: inceptionv1/logits/Tensordot/Rank\n",
      "node: inceptionv1/logits/Tensordot/axes\n",
      "node: inceptionv1/logits/Tensordot/GreaterEqual/y\n",
      "node: inceptionv1/logits/Tensordot/GreaterEqual\n",
      "node: inceptionv1/logits/Tensordot/Cast\n",
      "node: inceptionv1/logits/Tensordot/mul\n",
      "node: inceptionv1/logits/Tensordot/Less/y\n",
      "node: inceptionv1/logits/Tensordot/Less\n",
      "node: inceptionv1/logits/Tensordot/Cast_1\n",
      "node: inceptionv1/logits/Tensordot/add\n",
      "node: inceptionv1/logits/Tensordot/mul_1\n",
      "node: inceptionv1/logits/Tensordot/add_1\n",
      "node: inceptionv1/logits/Tensordot/range/start\n",
      "node: inceptionv1/logits/Tensordot/range/delta\n",
      "node: inceptionv1/logits/Tensordot/range\n",
      "node: inceptionv1/logits/Tensordot/ListDiff\n",
      "node: inceptionv1/logits/Tensordot/GatherV2/axis\n",
      "node: inceptionv1/logits/Tensordot/GatherV2\n",
      "node: inceptionv1/logits/Tensordot/GatherV2_1/axis\n",
      "node: inceptionv1/logits/Tensordot/GatherV2_1\n",
      "node: inceptionv1/logits/Tensordot/Const\n",
      "node: inceptionv1/logits/Tensordot/Prod\n",
      "node: inceptionv1/logits/Tensordot/Const_1\n",
      "node: inceptionv1/logits/Tensordot/Prod_1\n",
      "node: inceptionv1/logits/Tensordot/concat_1/axis\n",
      "node: inceptionv1/logits/Tensordot/concat_1\n",
      "node: inceptionv1/logits/Tensordot/stack\n",
      "node: inceptionv1/logits/Tensordot/transpose\n",
      "node: inceptionv1/logits/Tensordot/Reshape\n",
      "node: inceptionv1/logits/Tensordot/transpose_1/perm\n",
      "node: inceptionv1/logits/Tensordot/transpose_1\n",
      "node: inceptionv1/logits/Tensordot/Reshape_1/shape\n",
      "node: inceptionv1/logits/Tensordot/Reshape_1\n",
      "node: inceptionv1/logits/Tensordot/MatMul\n",
      "node: inceptionv1/logits/Tensordot/Const_2\n",
      "node: inceptionv1/logits/Tensordot/concat_2/axis\n",
      "node: inceptionv1/logits/Tensordot/concat_2\n",
      "node: inceptionv1/logits/Tensordot\n",
      "node: inceptionv1/logits/BiasAdd\n",
      "node: inceptionv1/SpatialSqueeze_logits\n",
      "node: myoutputnode\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "@slim.add_arg_scope\n",
    "def block(inputs, fir, sec, thir, four, name, outputs_collections = None):\n",
    "    with tf.variable_scope(name) as scope:\n",
    "        branch_1x3 = slim.conv2d(inputs, fir, [1, 5], [1, 1], padding = \"SAME\", scope = 'branch_1x5')\n",
    "        branch_1x7 = slim.conv2d(inputs, sec, [1, 9], [1, 1], padding = \"SAME\", scope = 'branch_1x9')\n",
    "        branch_1x11 = slim.conv2d(inputs, thir, [1, 21], [1, 1], padding = \"SAME\", scope = 'branch_1x21')\n",
    "\n",
    "        branch_poola = slim.avg_pool2d(inputs, [1, 5], [1, 1], padding = \"SAME\", scope = 'branch_poola')\n",
    "        branch_poolb = slim.conv2d(branch_poola, four, [1, 1], [1, 1], padding = \"SAME\", scope = 'branch_poolb')\n",
    "        out = tf.concat(axis = 3, values = [branch_1x3, branch_1x7, branch_1x11, branch_poolb])\n",
    "        out = slim.utils.collect_named_outputs(outputs_collections, scope.name, out)\n",
    "\n",
    "        return out\n",
    "def inceptionv1_arg_scope(weight_decay = 0.0005):\n",
    "    with slim.arg_scope([slim.variable, slim.model_variable], device = '/cpu:0'):\n",
    "        with slim.arg_scope(\n",
    "                [slim.conv2d, slim.fully_connected],\n",
    "                weights_initializer = slim.variance_scaling_initializer(),\n",
    "                weights_regularizer = slim.l2_regularizer(weight_decay),\n",
    "                activation_fn = tf.nn.relu,\n",
    "                biases_initializer = tf.zeros_initializer()):\n",
    "            with slim.arg_scope([slim.conv2d], padding = 'SAME'):\n",
    "                with slim.arg_scope([slim.avg_pool2d], padding = 'SAME') as arg_sc:\n",
    "                    return arg_sc\n",
    "                \n",
    "def inceptionv1(inputs,\n",
    "          num_classes = 1000,\n",
    "          dropout_keep_prob = 0.5,\n",
    "          is_training=True):\n",
    "    with tf.variable_scope('inceptionv1', [inputs, num_classes]) as sc:\n",
    "        end_points_collection = sc.original_name_scope + '_end_points'\n",
    "        # Collect outputs for conv2d, fully_connected and max_pool2d.\n",
    "\n",
    "        with slim.arg_scope(\n",
    "                [slim.conv2d, slim.fully_connected, slim.max_pool2d, block],\n",
    "                outputs_collections = end_points_collection):\n",
    "            # print(inputs.get_shape()[1].value)\n",
    "            net = slim.conv2d(inputs, 64, [inputs.get_shape()[1].value, 5], [1, 2],padding=\"VALID\", scope = 'conv1')  # 996\n",
    "            net = slim.max_pool2d(net, [1, 3], [1, 2], scope = 'pool1')  # 497\n",
    "            net = slim.conv2d(net, 96, [1, 5], [1, 1], scope = 'conv2')  # 493\n",
    "            net = slim.max_pool2d(net, [1, 3], [1, 2], scope = 'pool2')  # 246\n",
    "            net = block(net, 32, 64, 16, 16, 'mixed_128')  # 246\n",
    "            net = block(net, 64, 96, 48, 32, 'mixed_240')  # 246\n",
    "            net = slim.max_pool2d(net, [1, 3], [1, 2], scope = 'pool_after_mixed_240')  # 122\n",
    "            net = block(net, 96, 112, 24, 32, 'mixed_264')  # 122\n",
    "            net = block(net, 80, 128, 32, 32, 'mixed_272_1')  # 122\n",
    "            net = slim.max_pool2d(net, [1, 3], [1, 2], scope = 'pool_after_mixed_272_1')  # 60\n",
    "            net = block(net, 64, 144, 32, 32, 'mixed_272_2')  # 60\n",
    "            net = block(net, 96, 160, 64, 64, 'mixed_384_1')  # 60\n",
    "            net = slim.max_pool2d(net, [1, 3], [1, 2], scope = 'pool_after_mixed_384_1')  # 29\n",
    "            net = block(net, 96, 160, 64, 64, 'mixed_384_2')  # 29\n",
    "            net = block(net, 128, 192, 80, 80, 'mixed_480')  # 29\n",
    "            net = slim.max_pool2d(net, [1, 3], [1, 2], scope = 'pool_after_mixed_288')  # 14\n",
    "            shape = net.get_shape().as_list()\n",
    "            print(shape)\n",
    "#             net = tf.reshape(net, [-1, shape[1] * shape[2] * shape[3]])\n",
    "#             net = slim.fully_connected(net, 512, scope = \"fc1\")\n",
    "#             net = slim.fully_connected(net, 512, scope = \"fc2\")\n",
    "            # net = slim.conv2d(net, 256, [1, 5], [1, 1], scope = 'conv_end')  # 6\n",
    "            # print(net)\n",
    "            net = slim.avg_pool2d(net, [1, 6], [1, 1],padding=\"VALID\", scope = 'pool_end')  # 1\n",
    "            #\n",
    "            net = slim.conv2d(net, 512, [1, 1], scope = 'conv_fc1')\n",
    "            net = slim.conv2d(net, 512, [1, 1], scope = 'conv_fc2')\n",
    "           \n",
    "            # net = slim.conv2d(net, num_classes, [1, 1], activation_fn = None, normalizer_fn = None,\n",
    "            #                   scope = 'logits')\n",
    "            net = slim.fully_connected(net, num_classes, activation_fn = None, scope = 'logits')\n",
    "            if net.get_shape().ndims != 2:\n",
    "                net = tf.squeeze(net, [1, 2], name = 'SpatialSqueeze_logits')\n",
    "            end_points = utils.convert_collection_to_dict(end_points_collection)\n",
    "            if num_classes is not None:\n",
    "                end_points['predictions'] = slim.softmax(net, scope = 'predictions')\n",
    "            return net, end_points\n",
    "\n",
    "    \n",
    "def _activation_summary(x):\n",
    "\n",
    "    print(\"name:\", x.op.name, ' ', \"shape:\", x.get_shape().as_list())\n",
    "\n",
    "def _activation_summaries(endpoints):\n",
    "    with tf.name_scope('summaries'):\n",
    "        print('____________________________model output shape_______________________________')\n",
    "        for act in endpoints.values():\n",
    "            _activation_summary(act)\n",
    "def inference_inceptionv1(images, num_classes, is_training = False):\n",
    "    with slim.arg_scope(inceptionv1_arg_scope()):\n",
    "        logits, endpoints = inceptionv1(\n",
    "            images,\n",
    "            dropout_keep_prob = 0.5,\n",
    "            num_classes = num_classes,\n",
    "            is_training = is_training)\n",
    "\n",
    "    # Add summaries for viewing model statistics on TensorBoard.\n",
    "    _activation_summaries(endpoints)\n",
    "\n",
    "    # Grab the logits associated with the side head. Employed during training.\n",
    "\n",
    "    return logits\n",
    "\n",
    "test='test_class'\n",
    "model_out='test_class/model_out'\n",
    "model_converted='test_class/model_converted'\n",
    "if os.path.exists(test):\n",
    "    t=input(\"The path(%s) is exist,do you want to delete it and remake?(y/n):\\n\" %(test,)).strip()\n",
    "    while t not in ['y','n']:\n",
    "        t = input(\"your input is invalid,please input again(y/n):\\n\")\n",
    "    if t =='y':\n",
    "        shutil.rmtree(test)\n",
    "        os.makedirs(model_out)\n",
    "        os.makedirs(model_converted)\n",
    "    else:\n",
    "        pass\n",
    "else:\n",
    "    print(\"The test path is not exist! make it !\\n\")\n",
    "    os.makedirs(model_out)\n",
    "    os.makedirs(model_converted)\n",
    "       \n",
    "    \n",
    "with tf.Graph().as_default() as g:\n",
    "    images=tf.placeholder(dtype=tf.float32,shape=(None,3,1000,1),name='input_node')\n",
    "    logits = inference_inceptionv1(images, 12, is_training = False)\n",
    "    probs = tf.nn.softmax(logits,name='myoutputnode')\n",
    "    saver=tf.train.Saver()\n",
    "    tf.set_random_seed(123)\n",
    "    init = tf.global_variables_initializer()\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        saver.save(sess,model_out+'/model.ckpt')\n",
    "        graph = tf.get_default_graph()\n",
    "        input_graph_def = graph.as_graph_def()\n",
    "        output_graph_def = tf.graph_util.convert_variables_to_constants(\n",
    "            sess,\n",
    "            input_graph_def,\n",
    "            ['myoutputnode']\n",
    "        )\n",
    "        outgraph=tf.graph_util.remove_training_nodes(output_graph_def)\n",
    "        for node in outgraph.node:\n",
    "            print('node:',node.name)\n",
    "        tf.train.write_graph(outgraph,model_out,'frozen_model.pb',as_text=False)\n",
    "        tf.train.write_graph(outgraph,model_out,'frozen_model.pbtxt')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test path is not exist! make it !\n",
      "\n",
      "[None, 1, 6, 480]\n",
      "____________________________model output shape_______________________________\n",
      "name: inceptionv1/conv1/Relu   shape: [None, 1, 498, 64]\n",
      "name: inceptionv1/pool1/MaxPool   shape: [None, 1, 248, 64]\n",
      "name: inceptionv1/conv2/Relu   shape: [None, 1, 248, 96]\n",
      "name: inceptionv1/pool2/MaxPool   shape: [None, 1, 123, 96]\n",
      "name: inceptionv1/mixed_128/branch_1x5/Relu   shape: [None, 1, 123, 32]\n",
      "name: inceptionv1/mixed_128/branch_1x9/Relu   shape: [None, 1, 123, 64]\n",
      "name: inceptionv1/mixed_128/branch_1x21/Relu   shape: [None, 1, 123, 16]\n",
      "name: inceptionv1/mixed_128/branch_poolb/Relu   shape: [None, 1, 123, 16]\n",
      "name: inceptionv1/mixed_128/concat   shape: [None, 1, 123, 128]\n",
      "name: inceptionv1/mixed_240/branch_1x5/Relu   shape: [None, 1, 123, 64]\n",
      "name: inceptionv1/mixed_240/branch_1x9/Relu   shape: [None, 1, 123, 96]\n",
      "name: inceptionv1/mixed_240/branch_1x21/Relu   shape: [None, 1, 123, 48]\n",
      "name: inceptionv1/mixed_240/branch_poolb/Relu   shape: [None, 1, 123, 32]\n",
      "name: inceptionv1/mixed_240/concat   shape: [None, 1, 123, 240]\n",
      "name: inceptionv1/pool_after_mixed_240/MaxPool   shape: [None, 1, 61, 240]\n",
      "name: inceptionv1/mixed_264/branch_1x5/Relu   shape: [None, 1, 61, 96]\n",
      "name: inceptionv1/mixed_264/branch_1x9/Relu   shape: [None, 1, 61, 112]\n",
      "name: inceptionv1/mixed_264/branch_1x21/Relu   shape: [None, 1, 61, 24]\n",
      "name: inceptionv1/mixed_264/branch_poolb/Relu   shape: [None, 1, 61, 32]\n",
      "name: inceptionv1/mixed_264/concat   shape: [None, 1, 61, 264]\n",
      "name: inceptionv1/mixed_272_1/branch_1x5/Relu   shape: [None, 1, 61, 80]\n",
      "name: inceptionv1/mixed_272_1/branch_1x9/Relu   shape: [None, 1, 61, 128]\n",
      "name: inceptionv1/mixed_272_1/branch_1x21/Relu   shape: [None, 1, 61, 32]\n",
      "name: inceptionv1/mixed_272_1/branch_poolb/Relu   shape: [None, 1, 61, 32]\n",
      "name: inceptionv1/mixed_272_1/concat   shape: [None, 1, 61, 272]\n",
      "name: inceptionv1/pool_after_mixed_272_1/MaxPool   shape: [None, 1, 30, 272]\n",
      "name: inceptionv1/mixed_272_2/branch_1x5/Relu   shape: [None, 1, 30, 64]\n",
      "name: inceptionv1/mixed_272_2/branch_1x9/Relu   shape: [None, 1, 30, 144]\n",
      "name: inceptionv1/mixed_272_2/branch_1x21/Relu   shape: [None, 1, 30, 32]\n",
      "name: inceptionv1/mixed_272_2/branch_poolb/Relu   shape: [None, 1, 30, 32]\n",
      "name: inceptionv1/mixed_272_2/concat   shape: [None, 1, 30, 272]\n",
      "name: inceptionv1/mixed_384_1/branch_1x5/Relu   shape: [None, 1, 30, 96]\n",
      "name: inceptionv1/mixed_384_1/branch_1x9/Relu   shape: [None, 1, 30, 160]\n",
      "name: inceptionv1/mixed_384_1/branch_1x21/Relu   shape: [None, 1, 30, 64]\n",
      "name: inceptionv1/mixed_384_1/branch_poolb/Relu   shape: [None, 1, 30, 64]\n",
      "name: inceptionv1/mixed_384_1/concat   shape: [None, 1, 30, 384]\n",
      "name: inceptionv1/pool_after_mixed_384_1/MaxPool   shape: [None, 1, 14, 384]\n",
      "name: inceptionv1/mixed_384_2/branch_1x5/Relu   shape: [None, 1, 14, 96]\n",
      "name: inceptionv1/mixed_384_2/branch_1x9/Relu   shape: [None, 1, 14, 160]\n",
      "name: inceptionv1/mixed_384_2/branch_1x21/Relu   shape: [None, 1, 14, 64]\n",
      "name: inceptionv1/mixed_384_2/branch_poolb/Relu   shape: [None, 1, 14, 64]\n",
      "name: inceptionv1/mixed_384_2/concat   shape: [None, 1, 14, 384]\n",
      "name: inceptionv1/mixed_480/branch_1x5/Relu   shape: [None, 1, 14, 128]\n",
      "name: inceptionv1/mixed_480/branch_1x9/Relu   shape: [None, 1, 14, 192]\n",
      "name: inceptionv1/mixed_480/branch_1x21/Relu   shape: [None, 1, 14, 80]\n",
      "name: inceptionv1/mixed_480/branch_poolb/Relu   shape: [None, 1, 14, 80]\n",
      "name: inceptionv1/mixed_480/concat   shape: [None, 1, 14, 480]\n",
      "name: inceptionv1/pool_after_mixed_288/MaxPool   shape: [None, 1, 6, 480]\n",
      "name: inceptionv1/fc1/Relu   shape: [None, 512]\n",
      "name: inceptionv1/fc2/Relu   shape: [None, 512]\n",
      "name: inceptionv1/logits/BiasAdd   shape: [None, 12]\n",
      "name: inceptionv1/predictions/Reshape_1   shape: [None, 12]\n",
      "2020-01-07 20:05:53,428 INFO:Froze 74 variables.\n",
      "2020-01-07 20:05:53,460 INFO:Converted 74 variables to const ops.\n",
      "node: input_node\n",
      "node: inceptionv1/conv1/weights\n",
      "node: inceptionv1/conv1/biases\n",
      "node: inceptionv1/conv1/Conv2D\n",
      "node: inceptionv1/conv1/BiasAdd\n",
      "node: inceptionv1/conv1/Relu\n",
      "node: inceptionv1/pool1/MaxPool\n",
      "node: inceptionv1/conv2/weights\n",
      "node: inceptionv1/conv2/biases\n",
      "node: inceptionv1/conv2/Conv2D\n",
      "node: inceptionv1/conv2/BiasAdd\n",
      "node: inceptionv1/conv2/Relu\n",
      "node: inceptionv1/pool2/MaxPool\n",
      "node: inceptionv1/mixed_128/branch_1x5/weights\n",
      "node: inceptionv1/mixed_128/branch_1x5/biases\n",
      "node: inceptionv1/mixed_128/branch_1x5/Conv2D\n",
      "node: inceptionv1/mixed_128/branch_1x5/BiasAdd\n",
      "node: inceptionv1/mixed_128/branch_1x5/Relu\n",
      "node: inceptionv1/mixed_128/branch_1x9/weights\n",
      "node: inceptionv1/mixed_128/branch_1x9/biases\n",
      "node: inceptionv1/mixed_128/branch_1x9/Conv2D\n",
      "node: inceptionv1/mixed_128/branch_1x9/BiasAdd\n",
      "node: inceptionv1/mixed_128/branch_1x9/Relu\n",
      "node: inceptionv1/mixed_128/branch_1x21/weights\n",
      "node: inceptionv1/mixed_128/branch_1x21/biases\n",
      "node: inceptionv1/mixed_128/branch_1x21/Conv2D\n",
      "node: inceptionv1/mixed_128/branch_1x21/BiasAdd\n",
      "node: inceptionv1/mixed_128/branch_1x21/Relu\n",
      "node: inceptionv1/mixed_128/branch_poola/AvgPool\n",
      "node: inceptionv1/mixed_128/branch_poolb/weights\n",
      "node: inceptionv1/mixed_128/branch_poolb/biases\n",
      "node: inceptionv1/mixed_128/branch_poolb/Conv2D\n",
      "node: inceptionv1/mixed_128/branch_poolb/BiasAdd\n",
      "node: inceptionv1/mixed_128/branch_poolb/Relu\n",
      "node: inceptionv1/mixed_128/concat/axis\n",
      "node: inceptionv1/mixed_128/concat\n",
      "node: inceptionv1/mixed_240/branch_1x5/weights\n",
      "node: inceptionv1/mixed_240/branch_1x5/biases\n",
      "node: inceptionv1/mixed_240/branch_1x5/Conv2D\n",
      "node: inceptionv1/mixed_240/branch_1x5/BiasAdd\n",
      "node: inceptionv1/mixed_240/branch_1x5/Relu\n",
      "node: inceptionv1/mixed_240/branch_1x9/weights\n",
      "node: inceptionv1/mixed_240/branch_1x9/biases\n",
      "node: inceptionv1/mixed_240/branch_1x9/Conv2D\n",
      "node: inceptionv1/mixed_240/branch_1x9/BiasAdd\n",
      "node: inceptionv1/mixed_240/branch_1x9/Relu\n",
      "node: inceptionv1/mixed_240/branch_1x21/weights\n",
      "node: inceptionv1/mixed_240/branch_1x21/biases\n",
      "node: inceptionv1/mixed_240/branch_1x21/Conv2D\n",
      "node: inceptionv1/mixed_240/branch_1x21/BiasAdd\n",
      "node: inceptionv1/mixed_240/branch_1x21/Relu\n",
      "node: inceptionv1/mixed_240/branch_poola/AvgPool\n",
      "node: inceptionv1/mixed_240/branch_poolb/weights\n",
      "node: inceptionv1/mixed_240/branch_poolb/biases\n",
      "node: inceptionv1/mixed_240/branch_poolb/Conv2D\n",
      "node: inceptionv1/mixed_240/branch_poolb/BiasAdd\n",
      "node: inceptionv1/mixed_240/branch_poolb/Relu\n",
      "node: inceptionv1/mixed_240/concat/axis\n",
      "node: inceptionv1/mixed_240/concat\n",
      "node: inceptionv1/pool_after_mixed_240/MaxPool\n",
      "node: inceptionv1/mixed_264/branch_1x5/weights\n",
      "node: inceptionv1/mixed_264/branch_1x5/biases\n",
      "node: inceptionv1/mixed_264/branch_1x5/Conv2D\n",
      "node: inceptionv1/mixed_264/branch_1x5/BiasAdd\n",
      "node: inceptionv1/mixed_264/branch_1x5/Relu\n",
      "node: inceptionv1/mixed_264/branch_1x9/weights\n",
      "node: inceptionv1/mixed_264/branch_1x9/biases\n",
      "node: inceptionv1/mixed_264/branch_1x9/Conv2D\n",
      "node: inceptionv1/mixed_264/branch_1x9/BiasAdd\n",
      "node: inceptionv1/mixed_264/branch_1x9/Relu\n",
      "node: inceptionv1/mixed_264/branch_1x21/weights\n",
      "node: inceptionv1/mixed_264/branch_1x21/biases\n",
      "node: inceptionv1/mixed_264/branch_1x21/Conv2D\n",
      "node: inceptionv1/mixed_264/branch_1x21/BiasAdd\n",
      "node: inceptionv1/mixed_264/branch_1x21/Relu\n",
      "node: inceptionv1/mixed_264/branch_poola/AvgPool\n",
      "node: inceptionv1/mixed_264/branch_poolb/weights\n",
      "node: inceptionv1/mixed_264/branch_poolb/biases\n",
      "node: inceptionv1/mixed_264/branch_poolb/Conv2D\n",
      "node: inceptionv1/mixed_264/branch_poolb/BiasAdd\n",
      "node: inceptionv1/mixed_264/branch_poolb/Relu\n",
      "node: inceptionv1/mixed_264/concat/axis\n",
      "node: inceptionv1/mixed_264/concat\n",
      "node: inceptionv1/mixed_272_1/branch_1x5/weights\n",
      "node: inceptionv1/mixed_272_1/branch_1x5/biases\n",
      "node: inceptionv1/mixed_272_1/branch_1x5/Conv2D\n",
      "node: inceptionv1/mixed_272_1/branch_1x5/BiasAdd\n",
      "node: inceptionv1/mixed_272_1/branch_1x5/Relu\n",
      "node: inceptionv1/mixed_272_1/branch_1x9/weights\n",
      "node: inceptionv1/mixed_272_1/branch_1x9/biases\n",
      "node: inceptionv1/mixed_272_1/branch_1x9/Conv2D\n",
      "node: inceptionv1/mixed_272_1/branch_1x9/BiasAdd\n",
      "node: inceptionv1/mixed_272_1/branch_1x9/Relu\n",
      "node: inceptionv1/mixed_272_1/branch_1x21/weights\n",
      "node: inceptionv1/mixed_272_1/branch_1x21/biases\n",
      "node: inceptionv1/mixed_272_1/branch_1x21/Conv2D\n",
      "node: inceptionv1/mixed_272_1/branch_1x21/BiasAdd\n",
      "node: inceptionv1/mixed_272_1/branch_1x21/Relu\n",
      "node: inceptionv1/mixed_272_1/branch_poola/AvgPool\n",
      "node: inceptionv1/mixed_272_1/branch_poolb/weights\n",
      "node: inceptionv1/mixed_272_1/branch_poolb/biases\n",
      "node: inceptionv1/mixed_272_1/branch_poolb/Conv2D\n",
      "node: inceptionv1/mixed_272_1/branch_poolb/BiasAdd\n",
      "node: inceptionv1/mixed_272_1/branch_poolb/Relu\n",
      "node: inceptionv1/mixed_272_1/concat/axis\n",
      "node: inceptionv1/mixed_272_1/concat\n",
      "node: inceptionv1/pool_after_mixed_272_1/MaxPool\n",
      "node: inceptionv1/mixed_272_2/branch_1x5/weights\n",
      "node: inceptionv1/mixed_272_2/branch_1x5/biases\n",
      "node: inceptionv1/mixed_272_2/branch_1x5/Conv2D\n",
      "node: inceptionv1/mixed_272_2/branch_1x5/BiasAdd\n",
      "node: inceptionv1/mixed_272_2/branch_1x5/Relu\n",
      "node: inceptionv1/mixed_272_2/branch_1x9/weights\n",
      "node: inceptionv1/mixed_272_2/branch_1x9/biases\n",
      "node: inceptionv1/mixed_272_2/branch_1x9/Conv2D\n",
      "node: inceptionv1/mixed_272_2/branch_1x9/BiasAdd\n",
      "node: inceptionv1/mixed_272_2/branch_1x9/Relu\n",
      "node: inceptionv1/mixed_272_2/branch_1x21/weights\n",
      "node: inceptionv1/mixed_272_2/branch_1x21/biases\n",
      "node: inceptionv1/mixed_272_2/branch_1x21/Conv2D\n",
      "node: inceptionv1/mixed_272_2/branch_1x21/BiasAdd\n",
      "node: inceptionv1/mixed_272_2/branch_1x21/Relu\n",
      "node: inceptionv1/mixed_272_2/branch_poola/AvgPool\n",
      "node: inceptionv1/mixed_272_2/branch_poolb/weights\n",
      "node: inceptionv1/mixed_272_2/branch_poolb/biases\n",
      "node: inceptionv1/mixed_272_2/branch_poolb/Conv2D\n",
      "node: inceptionv1/mixed_272_2/branch_poolb/BiasAdd\n",
      "node: inceptionv1/mixed_272_2/branch_poolb/Relu\n",
      "node: inceptionv1/mixed_272_2/concat/axis\n",
      "node: inceptionv1/mixed_272_2/concat\n",
      "node: inceptionv1/mixed_384_1/branch_1x5/weights\n",
      "node: inceptionv1/mixed_384_1/branch_1x5/biases\n",
      "node: inceptionv1/mixed_384_1/branch_1x5/Conv2D\n",
      "node: inceptionv1/mixed_384_1/branch_1x5/BiasAdd\n",
      "node: inceptionv1/mixed_384_1/branch_1x5/Relu\n",
      "node: inceptionv1/mixed_384_1/branch_1x9/weights\n",
      "node: inceptionv1/mixed_384_1/branch_1x9/biases\n",
      "node: inceptionv1/mixed_384_1/branch_1x9/Conv2D\n",
      "node: inceptionv1/mixed_384_1/branch_1x9/BiasAdd\n",
      "node: inceptionv1/mixed_384_1/branch_1x9/Relu\n",
      "node: inceptionv1/mixed_384_1/branch_1x21/weights\n",
      "node: inceptionv1/mixed_384_1/branch_1x21/biases\n",
      "node: inceptionv1/mixed_384_1/branch_1x21/Conv2D\n",
      "node: inceptionv1/mixed_384_1/branch_1x21/BiasAdd\n",
      "node: inceptionv1/mixed_384_1/branch_1x21/Relu\n",
      "node: inceptionv1/mixed_384_1/branch_poola/AvgPool\n",
      "node: inceptionv1/mixed_384_1/branch_poolb/weights\n",
      "node: inceptionv1/mixed_384_1/branch_poolb/biases\n",
      "node: inceptionv1/mixed_384_1/branch_poolb/Conv2D\n",
      "node: inceptionv1/mixed_384_1/branch_poolb/BiasAdd\n",
      "node: inceptionv1/mixed_384_1/branch_poolb/Relu\n",
      "node: inceptionv1/mixed_384_1/concat/axis\n",
      "node: inceptionv1/mixed_384_1/concat\n",
      "node: inceptionv1/pool_after_mixed_384_1/MaxPool\n",
      "node: inceptionv1/mixed_384_2/branch_1x5/weights\n",
      "node: inceptionv1/mixed_384_2/branch_1x5/biases\n",
      "node: inceptionv1/mixed_384_2/branch_1x5/Conv2D\n",
      "node: inceptionv1/mixed_384_2/branch_1x5/BiasAdd\n",
      "node: inceptionv1/mixed_384_2/branch_1x5/Relu\n",
      "node: inceptionv1/mixed_384_2/branch_1x9/weights\n",
      "node: inceptionv1/mixed_384_2/branch_1x9/biases\n",
      "node: inceptionv1/mixed_384_2/branch_1x9/Conv2D\n",
      "node: inceptionv1/mixed_384_2/branch_1x9/BiasAdd\n",
      "node: inceptionv1/mixed_384_2/branch_1x9/Relu\n",
      "node: inceptionv1/mixed_384_2/branch_1x21/weights\n",
      "node: inceptionv1/mixed_384_2/branch_1x21/biases\n",
      "node: inceptionv1/mixed_384_2/branch_1x21/Conv2D\n",
      "node: inceptionv1/mixed_384_2/branch_1x21/BiasAdd\n",
      "node: inceptionv1/mixed_384_2/branch_1x21/Relu\n",
      "node: inceptionv1/mixed_384_2/branch_poola/AvgPool\n",
      "node: inceptionv1/mixed_384_2/branch_poolb/weights\n",
      "node: inceptionv1/mixed_384_2/branch_poolb/biases\n",
      "node: inceptionv1/mixed_384_2/branch_poolb/Conv2D\n",
      "node: inceptionv1/mixed_384_2/branch_poolb/BiasAdd\n",
      "node: inceptionv1/mixed_384_2/branch_poolb/Relu\n",
      "node: inceptionv1/mixed_384_2/concat/axis\n",
      "node: inceptionv1/mixed_384_2/concat\n",
      "node: inceptionv1/mixed_480/branch_1x5/weights\n",
      "node: inceptionv1/mixed_480/branch_1x5/biases\n",
      "node: inceptionv1/mixed_480/branch_1x5/Conv2D\n",
      "node: inceptionv1/mixed_480/branch_1x5/BiasAdd\n",
      "node: inceptionv1/mixed_480/branch_1x5/Relu\n",
      "node: inceptionv1/mixed_480/branch_1x9/weights\n",
      "node: inceptionv1/mixed_480/branch_1x9/biases\n",
      "node: inceptionv1/mixed_480/branch_1x9/Conv2D\n",
      "node: inceptionv1/mixed_480/branch_1x9/BiasAdd\n",
      "node: inceptionv1/mixed_480/branch_1x9/Relu\n",
      "node: inceptionv1/mixed_480/branch_1x21/weights\n",
      "node: inceptionv1/mixed_480/branch_1x21/biases\n",
      "node: inceptionv1/mixed_480/branch_1x21/Conv2D\n",
      "node: inceptionv1/mixed_480/branch_1x21/BiasAdd\n",
      "node: inceptionv1/mixed_480/branch_1x21/Relu\n",
      "node: inceptionv1/mixed_480/branch_poola/AvgPool\n",
      "node: inceptionv1/mixed_480/branch_poolb/weights\n",
      "node: inceptionv1/mixed_480/branch_poolb/biases\n",
      "node: inceptionv1/mixed_480/branch_poolb/Conv2D\n",
      "node: inceptionv1/mixed_480/branch_poolb/BiasAdd\n",
      "node: inceptionv1/mixed_480/branch_poolb/Relu\n",
      "node: inceptionv1/mixed_480/concat/axis\n",
      "node: inceptionv1/mixed_480/concat\n",
      "node: inceptionv1/pool_after_mixed_288/MaxPool\n",
      "node: inceptionv1/Reshape/shape\n",
      "node: inceptionv1/Reshape\n",
      "node: inceptionv1/fc1/weights\n",
      "node: inceptionv1/fc1/biases\n",
      "node: inceptionv1/fc1/MatMul\n",
      "node: inceptionv1/fc1/BiasAdd\n",
      "node: inceptionv1/fc1/Relu\n",
      "node: inceptionv1/fc2/weights\n",
      "node: inceptionv1/fc2/biases\n",
      "node: inceptionv1/fc2/MatMul\n",
      "node: inceptionv1/fc2/BiasAdd\n",
      "node: inceptionv1/fc2/Relu\n",
      "node: inceptionv1/logits/weights\n",
      "node: inceptionv1/logits/biases\n",
      "node: inceptionv1/logits/MatMul\n",
      "node: inceptionv1/logits/BiasAdd\n",
      "node: myoutputnode\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "@slim.add_arg_scope\n",
    "def block(inputs, fir, sec, thir, four, name, outputs_collections = None):\n",
    "    with tf.variable_scope(name) as scope:\n",
    "        branch_1x3 = slim.conv2d(inputs, fir, [1, 5], [1, 1], padding = \"SAME\", scope = 'branch_1x5')\n",
    "        branch_1x7 = slim.conv2d(inputs, sec, [1, 9], [1, 1], padding = \"SAME\", scope = 'branch_1x9')\n",
    "        branch_1x11 = slim.conv2d(inputs, thir, [1, 21], [1, 1], padding = \"SAME\", scope = 'branch_1x21')\n",
    "\n",
    "        branch_poola = slim.avg_pool2d(inputs, [1, 5], [1, 1], padding = \"SAME\", scope = 'branch_poola')\n",
    "        branch_poolb = slim.conv2d(branch_poola, four, [1, 1], [1, 1], padding = \"SAME\", scope = 'branch_poolb')\n",
    "        out = tf.concat(axis = 3, values = [branch_1x3, branch_1x7, branch_1x11, branch_poolb])\n",
    "        out = slim.utils.collect_named_outputs(outputs_collections, scope.name, out)\n",
    "\n",
    "        return out\n",
    "def inceptionv1_arg_scope(weight_decay = 0.0005):\n",
    "    with slim.arg_scope([slim.variable, slim.model_variable], device = '/cpu:0'):\n",
    "        with slim.arg_scope(\n",
    "                [slim.conv2d, slim.fully_connected],\n",
    "                weights_initializer = slim.variance_scaling_initializer(),\n",
    "                weights_regularizer = slim.l2_regularizer(weight_decay),\n",
    "                activation_fn = tf.nn.relu,\n",
    "                biases_initializer = tf.zeros_initializer()):\n",
    "            with slim.arg_scope([slim.conv2d], padding = 'SAME'):\n",
    "                with slim.arg_scope([slim.avg_pool2d], padding = 'SAME') as arg_sc:\n",
    "                    return arg_sc\n",
    "                \n",
    "def inceptionv1(inputs,\n",
    "          num_classes = 1000,\n",
    "          dropout_keep_prob = 0.5,\n",
    "          is_training=True):\n",
    "    with tf.variable_scope('inceptionv1', [inputs, num_classes]) as sc:\n",
    "        end_points_collection = sc.original_name_scope + '_end_points'\n",
    "        # Collect outputs for conv2d, fully_connected and max_pool2d.\n",
    "\n",
    "        with slim.arg_scope(\n",
    "                [slim.conv2d, slim.fully_connected, slim.max_pool2d, block],\n",
    "                outputs_collections = end_points_collection):\n",
    "            # print(inputs.get_shape()[1].value)\n",
    "            net = slim.conv2d(inputs, 64, [inputs.get_shape()[1].value, 5], [1, 2],padding=\"VALID\", scope = 'conv1')  # 996\n",
    "            net = slim.max_pool2d(net, [1, 3], [1, 2], scope = 'pool1')  # 497\n",
    "            net = slim.conv2d(net, 96, [1, 5], [1, 1], scope = 'conv2')  # 493\n",
    "            net = slim.max_pool2d(net, [1, 3], [1, 2], scope = 'pool2')  # 246\n",
    "            net = block(net, 32, 64, 16, 16, 'mixed_128')  # 246\n",
    "            net = block(net, 64, 96, 48, 32, 'mixed_240')  # 246\n",
    "            net = slim.max_pool2d(net, [1, 3], [1, 2], scope = 'pool_after_mixed_240')  # 122\n",
    "            net = block(net, 96, 112, 24, 32, 'mixed_264')  # 122\n",
    "            net = block(net, 80, 128, 32, 32, 'mixed_272_1')  # 122\n",
    "            net = slim.max_pool2d(net, [1, 3], [1, 2], scope = 'pool_after_mixed_272_1')  # 60\n",
    "            net = block(net, 64, 144, 32, 32, 'mixed_272_2')  # 60\n",
    "            net = block(net, 96, 160, 64, 64, 'mixed_384_1')  # 60\n",
    "            net = slim.max_pool2d(net, [1, 3], [1, 2], scope = 'pool_after_mixed_384_1')  # 29\n",
    "            net = block(net, 96, 160, 64, 64, 'mixed_384_2')  # 29\n",
    "            net = block(net, 128, 192, 80, 80, 'mixed_480')  # 29\n",
    "            net = slim.max_pool2d(net, [1, 3], [1, 2], scope = 'pool_after_mixed_288')  # 14\n",
    "            shape = net.get_shape().as_list()\n",
    "            print(shape)\n",
    "            net = tf.reshape(net, [-1, shape[1] * shape[2] * shape[3]])\n",
    "            net = slim.fully_connected(net, 512, scope = \"fc1\")\n",
    "            net = slim.fully_connected(net, 512, scope = \"fc2\")\n",
    "            # net = slim.conv2d(net, 256, [1, 5], [1, 1], scope = 'conv_end')  # 6\n",
    "            # print(net)\n",
    "#             net = slim.avg_pool2d(net, [1, 6], [1, 1],padding=\"VALID\", scope = 'pool_end')  # 1\n",
    "#             #\n",
    "#             net = slim.conv2d(net, 512, [1, 1], scope = 'conv_fc1')\n",
    "#             net = slim.conv2d(net, 512, [1, 1], scope = 'conv_fc2')\n",
    "           \n",
    "            # net = slim.conv2d(net, num_classes, [1, 1], activation_fn = None, normalizer_fn = None,\n",
    "            #                   scope = 'logits')\n",
    "            net = slim.fully_connected(net, num_classes, activation_fn = None, scope = 'logits')\n",
    "            if net.get_shape().ndims != 2:\n",
    "                net = tf.squeeze(net, [1, 2], name = 'SpatialSqueeze_logits')\n",
    "            end_points = utils.convert_collection_to_dict(end_points_collection)\n",
    "            if num_classes is not None:\n",
    "                end_points['predictions'] = slim.softmax(net, scope = 'predictions')\n",
    "            return net, end_points\n",
    "\n",
    "    \n",
    "def _activation_summary(x):\n",
    "\n",
    "    print(\"name:\", x.op.name, ' ', \"shape:\", x.get_shape().as_list())\n",
    "\n",
    "def _activation_summaries(endpoints):\n",
    "    with tf.name_scope('summaries'):\n",
    "        print('____________________________model output shape_______________________________')\n",
    "        for act in endpoints.values():\n",
    "            _activation_summary(act)\n",
    "def inference_inceptionv1(images, num_classes, is_training = False):\n",
    "    with slim.arg_scope(inceptionv1_arg_scope()):\n",
    "        logits, endpoints = inceptionv1(\n",
    "            images,\n",
    "            dropout_keep_prob = 0.5,\n",
    "            num_classes = num_classes,\n",
    "            is_training = is_training)\n",
    "\n",
    "    # Add summaries for viewing model statistics on TensorBoard.\n",
    "    _activation_summaries(endpoints)\n",
    "\n",
    "    # Grab the logits associated with the side head. Employed during training.\n",
    "\n",
    "    return logits\n",
    "\n",
    "test='test_class1'\n",
    "model_out='test_class1/model_out'\n",
    "model_converted='test_class1/model_converted'\n",
    "if os.path.exists(test):\n",
    "    t=input(\"The path(%s) is exist,do you want to delete it and remake?(y/n):\\n\" %(test,)).strip()\n",
    "    while t not in ['y','n']:\n",
    "        t = input(\"your input is invalid,please input again(y/n):\\n\")\n",
    "    if t =='y':\n",
    "        shutil.rmtree(test)\n",
    "        os.makedirs(model_out)\n",
    "        os.makedirs(model_converted)\n",
    "    else:\n",
    "        pass\n",
    "else:\n",
    "    print(\"The test path is not exist! make it !\\n\")\n",
    "    os.makedirs(model_out)\n",
    "    os.makedirs(model_converted)\n",
    "       \n",
    "    \n",
    "with tf.Graph().as_default() as g:\n",
    "    images=tf.placeholder(dtype=tf.float32,shape=(None,3,1000,1),name='input_node')\n",
    "    logits = inference_inceptionv1(images, 12, is_training = False)\n",
    "    probs = tf.nn.softmax(logits,name='myoutputnode')\n",
    "    saver=tf.train.Saver()\n",
    "    tf.set_random_seed(123)\n",
    "    init = tf.global_variables_initializer()\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        saver.save(sess,model_out+'/model.ckpt')\n",
    "        graph = tf.get_default_graph()\n",
    "        input_graph_def = graph.as_graph_def()\n",
    "        output_graph_def = tf.graph_util.convert_variables_to_constants(\n",
    "            sess,\n",
    "            input_graph_def,\n",
    "            ['myoutputnode']\n",
    "        )\n",
    "        outgraph=tf.graph_util.remove_training_nodes(output_graph_def)\n",
    "        for node in outgraph.node:\n",
    "            print('node:',node.name)\n",
    "        tf.train.write_graph(outgraph,model_out,'frozen_model.pb',as_text=False)\n",
    "        tf.train.write_graph(outgraph,model_out,'frozen_model.pbtxt')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Optimizer arguments:\n",
      "Common parameters:\n",
      "\t- Path to the Input Model: \t/home/tianliang/2019r3/./test_class1/model_out/frozen_model.pb\n",
      "\t- Path for generated IR: \t/home/tianliang/2019r3/./test_class1/model_converted/model_fp16\n",
      "\t- IR output name: \tmodel_fp16\n",
      "\t- Log level: \tERROR\n",
      "\t- Batch: \tNot specified, inherited from the model\n",
      "\t- Input layers: \tinput_node\n",
      "\t- Output layers: \tmyoutputnode\n",
      "\t- Input shapes: \t[1,3,1000,1]\n",
      "\t- Mean values: \tNot specified\n",
      "\t- Scale values: \tNot specified\n",
      "\t- Scale factor: \tNot specified\n",
      "\t- Precision of IR: \tFP16\n",
      "\t- Enable fusing: \tTrue\n",
      "\t- Enable grouped convolutions fusing: \tTrue\n",
      "\t- Move mean values to preprocess section: \tFalse\n",
      "\t- Reverse input channels: \tFalse\n",
      "TensorFlow specific parameters:\n",
      "\t- Input model in text protobuf format: \tFalse\n",
      "\t- Path to model dump for TensorBoard: \tNone\n",
      "\t- List of shared libraries with TensorFlow custom layers implementation: \tNone\n",
      "\t- Update the configuration file with input/output node names: \tNone\n",
      "\t- Use configuration file used to generate the model with Object Detection API: \tNone\n",
      "\t- Operations to offload: \tNone\n",
      "\t- Patterns to offload: \tNone\n",
      "\t- Use the config file: \tNone\n",
      "Model Optimizer version: \t2019.3.0-408-gac8584cb7\n",
      "\n",
      "[ SUCCESS ] Generated IR model.\n",
      "[ SUCCESS ] XML file: /home/tianliang/2019r3/./test_class1/model_converted/model_fp16/model_fp16.xml\n",
      "[ SUCCESS ] BIN file: /home/tianliang/2019r3/./test_class1/model_converted/model_fp16/model_fp16.bin\n",
      "[ SUCCESS ] Total execution time: 8.03 seconds. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "scribe=\"/opt/intel/openvino/deployment_tools/model_optimizer/mo_tf.py\"\n",
    "python3 $scribe --input input_node --output myoutputnode --input_model ./test_class1/model_out/frozen_model.pb --model_name model_fp16 --output_dir ./test_class1/model_converted/model_fp16 --log_level=ERROR --data_type=FP16 --input_shape [1,3,1000,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = np.random.rand(72,500).flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用pb调用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01-07 19:22:27,353 WARNING:From <ipython-input-18-690f10e4cff2>:16: calling import_graph_def (from tensorflow.python.framework.importer) with op_dict is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please file an issue at https://github.com/tensorflow/tensorflow/issues if you depend on this feature.\n",
      "[0.2996923  0.04790032 0.6524074 ]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "classid_str = \"classid\"\n",
    "probability_str = \"probability\"\n",
    "n,h,w,c=1,1,500,1\n",
    "labels_map=None\n",
    "\n",
    "def load_graph(file_path):\n",
    "\n",
    "    with tf.gfile.GFile(file_path,'rb') as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "        with tf.Graph().as_default() as graph:\n",
    "            tf.import_graph_def(graph_def,input_map = None,return_elements = None,name = \"\",op_dict = None,producer_op_list = None)\n",
    "            graph_nodes = [n for n in graph_def.node]\n",
    "            return graph,graph_nodes\n",
    "pb_path = \"test/model_out/frozen_model.pb\"\n",
    "graph,graph_nodes = load_graph(pb_path)\n",
    "# for node in graph_nodes:\n",
    "#     print('node:', node.name)\n",
    "input = graph.get_tensor_by_name('input_node:0')\n",
    "output = graph.get_tensor_by_name('myoutputnode:0')\n",
    "\n",
    "\n",
    "data=np.load('data1.npy').reshape(1,h,w,c)\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    softmax_values = sess.run(output, feed_dict = {input: data})\n",
    "    \n",
    "    for i, probs in enumerate(softmax_values):\n",
    "        probs = np.squeeze(probs)\n",
    "        print(probs)\n",
    "#         top_ind = np.argsort(probs)[-:][::-1]\n",
    "#     print(classid_str, probability_str)\n",
    "#     print(\"{} {}\".format('-' * len(classid_str), '-' * len(probability_str)))\n",
    "#     for id in top_ind:\n",
    "#         det_label = labels_map[id] if labels_map else \"{}\".format(id)\n",
    "#         label_length = len(det_label)\n",
    "#         space_num_before = (len(classid_str) - label_length) // 2\n",
    "#         space_num_after = len(classid_str) - (space_num_before + label_length) + 2\n",
    "#         space_num_before_prob = (len(probability_str) - len(str(probs[id]))) // 2\n",
    "#         print(\"{}{}{}{}{:.7f}\".format(' ' * space_num_before, det_label,\n",
    "#                                       ' ' * space_num_after, ' ' * space_num_before_prob,\n",
    "#                                       probs[id]))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CPU fp16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01-07 19:22:32,720 INFO:Preparing input blobs\n",
      "1 1 1 500\n",
      "2020-01-07 19:22:32,722 INFO:Batch size is 1\n",
      "2020-01-07 19:22:32,722 INFO:Loading model to the plugin\n",
      "2020-01-07 19:22:33,183 INFO:Starting inference (100 iterations)\n",
      "2020-01-07 19:22:33,341 INFO:Average running time of one iteration: 1.5633392333984375 ms\n",
      "2020-01-07 19:22:33,342 INFO:Performance 639 FPS\n",
      "2020-01-07 19:22:33,343 INFO:Processing output blob\n",
      "2020-01-07 19:22:33,343 INFO:Top 5 results: \n",
      "classid probability\n",
      "------- -----------\n",
      "   2     0.6525519\n",
      "   0     0.2995729\n",
      "   1     0.0478752\n",
      "2020-01-07 19:22:33,344 INFO:Performance counters:\n",
      "name                                                         layer_type      exet_type                 status          real_time, us\n",
      "Relu                                                         ReLU            undef                     NOT_RUN         0         \n",
      "MatMul                                                       FullyConnected  gemm_blas_FP32            EXECUTED        29        \n",
      "out_myoutputnode                                             Output          unknown_FP32              NOT_RUN         0         \n",
      "Transpose                                                    Permute         unknown_FP32              EXECUTED        11        \n",
      "MaxPool                                                      Pooling         jit_avx_FP32              EXECUTED        15        \n",
      "MatMul                                                       FullyConnected  gemm_blas_FP32            EXECUTED        780       \n",
      "Relu                                                         ReLU            jit_avx2_FP32             EXECUTED        4         \n",
      "Conv2D                                                       Convolution     jit_avx2_FP32             EXECUTED        25        \n",
      "Conv2D                                                       Convolution     jit_avx2_FP32             EXECUTED        209       \n",
      "Conv2D                                                       Convolution     jit_avx2_FP32             EXECUTED        217       \n",
      "Relu                                                         ReLU            undef                     NOT_RUN         0         \n",
      "MaxPool                                                      Pooling         jit_avx_FP32              EXECUTED        8         \n",
      "Relu                                                         ReLU            undef                     NOT_RUN         0         \n",
      "MaxPool                                                      Pooling         jit_avx_FP32              EXECUTED        23        \n",
      "myoutputnode                                                 SoftMax         ref_any_FP32              EXECUTED        4         \n",
      "Relu                                                         ReLU            jit_avx2_FP32             EXECUTED        2         \n",
      "MatMul                                                       FullyConnected  gemm_blas_FP32            EXECUTED        2         \n",
      "Reshape                                                      Reshape         unknown_FP32              NOT_RUN         0         \n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "from time import time\n",
    "from openvino.inference_engine import IENetwork, IEPlugin\n",
    "\n",
    "\n",
    "class ObjDict(dict):\n",
    "    \"\"\"Makes a dictionary behave like an object, with attribute-style access.\n",
    "    \"\"\"\n",
    "\n",
    "    def __getattr__(self, name):\n",
    "        try:\n",
    "            return self[name]\n",
    "        except KeyError:\n",
    "            raise AttributeError(name)\n",
    "\n",
    "    def __setattr__(self, name, value):\n",
    "        self[name] = value\n",
    "args=ObjDict()\n",
    "\n",
    "args.device=\"CPU\"\n",
    "args.plugin_dir=None\n",
    "if args.device in ['CPU']:\n",
    "    args.model=\"test/model_converted/model_fp16/model_fp16.xml\"\n",
    "elif args.device in ['MYRIAD']:\n",
    "    args.model=\"test/model_converted/model_fp16/model_fp16.xml\"\n",
    "else:\n",
    "    args.model=\"test/model_converted/model_fp32/model_fp32.xml\"\n",
    "    #args.model=\"/home/ubuntu/tf_models/test20190704/model_converted/model_fp16/model_fp16.xml\"\n",
    "\n",
    "args.number_iter=100\n",
    "args.perf_counts=True\n",
    "args.number_top=5\n",
    "args.labels=None\n",
    "\n",
    "plugin = IEPlugin(device=args.device, plugin_dirs=args.plugin_dir)\n",
    "model_xml=args.model\n",
    "model_bin = os.path.splitext(model_xml)[0] + \".bin\"\n",
    "net = IENetwork(model=model_xml, weights=model_bin)\n",
    "\n",
    "if plugin.device == \"CPU\":\n",
    "    supported_layers = plugin.get_supported_layers(net)\n",
    "    not_supported_layers = [l for l in net.layers.keys() if l not in supported_layers]\n",
    "    if len(not_supported_layers) != 0:\n",
    "        log.error(\"Following layers are not supported by the plugin for specified device {}:\\n {}\".\n",
    "                  format(plugin.device, ', '.join(not_supported_layers)))\n",
    "        log.error(\"Please try to specify cpu extensions library path in sample's command line parameters using -l \"\n",
    "                  \"or --cpu_extension command line argument\")\n",
    "        sys.exit(1)\n",
    "        \n",
    "log.info(\"Preparing input blobs\")\n",
    "input_blob = next(iter(net.inputs))\n",
    "out_blob = next(iter(net.outputs))\n",
    "#net.batch_size = len(args.input)\n",
    "n,c,h,w=net.inputs[input_blob].shape\n",
    "print(n,c,h,w)\n",
    "\n",
    "for i in range(n):\n",
    "    np.random.seed(5)\n",
    "\n",
    "    args.input=np.load('data1.npy')\n",
    "    images = args.input.transpose((0,3, 1, 2))  # Change data layout from HWC to CHW\n",
    "\n",
    "log.info(\"Batch size is {}\".format(n))\n",
    "# Loading model to the plugin\n",
    "log.info(\"Loading model to the plugin\")\n",
    "exec_net = plugin.load(network=net)\n",
    "# Start sync inference\n",
    "log.info(\"Starting inference ({} iterations)\".format(args.number_iter))\n",
    "infer_time = []\n",
    "for i in range(args.number_iter):\n",
    "    t0 = time()\n",
    "    res = exec_net.infer(inputs={input_blob: images})\n",
    "    infer_time.append((time() - t0) * 1000)\n",
    "log.info(\"Average running time of one iteration: {} ms\".format(np.average(np.asarray(infer_time))))\n",
    "log.info(\"Performance {} FPS\".format(int(1000/np.average(np.asarray(infer_time)))))\n",
    "\n",
    "log.info(\"Processing output blob\")\n",
    "res = res[out_blob]\n",
    "log.info(\"Top {} results: \".format(args.number_top))\n",
    "if args.labels:\n",
    "    with open(args.labels, 'r') as f:\n",
    "        labels_map = [x.split(sep=' ', maxsplit=1)[-1].strip() for x in f]\n",
    "else:\n",
    "    labels_map = None\n",
    "    \n",
    "classid_str = \"classid\"\n",
    "probability_str = \"probability\"\n",
    "for i, probs in enumerate(res):\n",
    "    probs = np.squeeze(probs)\n",
    "    top_ind = np.argsort(probs)[-args.number_top:][::-1]\n",
    "    #print(\"Image {}\\n\".format(args.input[i]))\n",
    "    print(classid_str, probability_str)\n",
    "    print(\"{} {}\".format('-' * len(classid_str), '-' * len(probability_str)))\n",
    "    for id in top_ind:\n",
    "        det_label = labels_map[id] if labels_map else \"{}\".format(id)\n",
    "        label_length = len(det_label)\n",
    "        space_num_before = (len(classid_str) - label_length) // 2\n",
    "        space_num_after = len(classid_str) - (space_num_before + label_length) + 2\n",
    "        space_num_before_prob = (len(probability_str) - len(str(probs[id]))) // 2\n",
    "        print(\"{}{}{}{}{:.7f}\".format(' ' * space_num_before, det_label,\n",
    "                                      ' ' * space_num_after, ' ' * space_num_before_prob,\n",
    "                                      probs[id]))    \n",
    "if args.perf_counts:\n",
    "    perf_counts = exec_net.requests[0].get_perf_counts()\n",
    "    log.info(\"Performance counters:\")\n",
    "    print(\"{:<60} {:<15} {:<25} {:<15} {:<10}\".format('name', 'layer_type', 'exet_type', 'status', 'real_time, us'))\n",
    "    for layer, stats in perf_counts.items():\n",
    "        layer = layer.split('/')[-1]\n",
    "        print(\"{:<60} {:<15} {:<25} {:<15} {:<10}\".format(layer, stats['layer_type'], stats['exec_type'],\n",
    "                                                          stats['status'], stats['real_time']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('test_data.npy',data1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 以下为测试"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MYRIAD  fp16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01-07 19:22:37,857 INFO:Preparing input blobs\n",
      "1 1 1 500\n",
      "2020-01-07 19:22:37,859 INFO:Batch size is 1\n",
      "2020-01-07 19:22:37,860 INFO:Loading model to the plugin\n",
      "2020-01-07 19:22:39,865 INFO:Starting inference (100 iterations)\n",
      "2020-01-07 19:22:40,355 INFO:Average running time of one iteration: 4.889945983886719 ms\n",
      "2020-01-07 19:22:40,356 INFO:Performance 204.50 FPS\n",
      "2020-01-07 19:22:40,356 INFO:Processing output blob\n",
      "2020-01-07 19:22:40,357 INFO:Top 5 results: \n",
      "classid probability\n",
      "------- -----------\n",
      "   2      0.6484375\n",
      "   0     0.3024902\n",
      "   1     0.0493164\n",
      "2020-01-07 19:22:40,359 INFO:Performance counters:\n",
      "name                                                         layer_type      exet_type                 status          real_time, us\n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "MatMul                                                       FullyConnected  MyriadXHwOp               EXECUTED        53        \n",
      "input_node                                                   Input           NONE                      NOT_RUN         0         \n",
      "Transpose                                                    Permute         Permute                   EXECUTED        128       \n",
      "MaxPool                                                      Pooling         MaxPool                   EXECUTED        304       \n",
      "MatMul                                                       FullyConnected  Copy                      EXECUTED        1180      \n",
      "Relu                                                         ReLU            Relu                      EXECUTED        42        \n",
      "Conv2D                                                       Convolution     MyriadXHwOp               EXECUTED        79        \n",
      "Conv2D                                                       Convolution     MyriadXHwOp               EXECUTED        407       \n",
      "Conv2D                                                       Convolution     MyriadXHwOp               EXECUTED        479       \n",
      "MaxPool                                                      Pooling         MaxPool                   EXECUTED        189       \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "MatMul                                                       FullyConnected  MyriadXHwOp               EXECUTED        20        \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "MaxPool                                                      Pooling         MaxPool                   EXECUTED        270       \n",
      "myoutputnode                                                 SoftMax         SoftMax                   EXECUTED        36        \n",
      "Relu                                                         ReLU            Relu                      EXECUTED        31        \n",
      "<Extra>                                                      <Extra>         Convert_f32f16            EXECUTED        78        \n",
      "Reshape                                                      Reshape         Reshape                   NOT_RUN         0         \n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "from time import time\n",
    "from openvino.inference_engine import IENetwork, IEPlugin\n",
    "\n",
    "\n",
    "class ObjDict(dict):\n",
    "    \"\"\"Makes a dictionary behave like an object, with attribute-style access.\n",
    "    \"\"\"\n",
    "\n",
    "    def __getattr__(self, name):\n",
    "        try:\n",
    "            return self[name]\n",
    "        except KeyError:\n",
    "            raise AttributeError(name)\n",
    "\n",
    "    def __setattr__(self, name, value):\n",
    "        self[name] = value\n",
    "args=ObjDict()\n",
    "\n",
    "args.device=\"MYRIAD\"\n",
    "args.plugin_dir=None\n",
    "if args.device in ['CPU']:\n",
    "    args.model=\"test/model_converted/model_fp16/model_fp16.xml\"\n",
    "elif args.device in ['MYRIAD']:\n",
    "    args.model=\"test/model_converted/model_fp16/model_fp16.xml\"\n",
    "else:\n",
    "    args.model=\"test/model_converted/model_fp32/model_fp32.xml\"\n",
    "    #args.model=\"/home/ubuntu/tf_models/test20190704/model_converted/model_fp16/model_fp16.xml\"\n",
    "\n",
    "args.number_iter=100\n",
    "args.perf_counts=True\n",
    "args.number_top=5\n",
    "args.labels=None\n",
    "\n",
    "plugin = IEPlugin(device=args.device, plugin_dirs=args.plugin_dir)\n",
    "model_xml=args.model\n",
    "model_bin = os.path.splitext(model_xml)[0] + \".bin\"\n",
    "net = IENetwork(model=model_xml, weights=model_bin)\n",
    "\n",
    "if plugin.device == \"CPU\":\n",
    "    supported_layers = plugin.get_supported_layers(net)\n",
    "    not_supported_layers = [l for l in net.layers.keys() if l not in supported_layers]\n",
    "    if len(not_supported_layers) != 0:\n",
    "        log.error(\"Following layers are not supported by the plugin for specified device {}:\\n {}\".\n",
    "                  format(plugin.device, ', '.join(not_supported_layers)))\n",
    "        log.error(\"Please try to specify cpu extensions library path in sample's command line parameters using -l \"\n",
    "                  \"or --cpu_extension command line argument\")\n",
    "        sys.exit(1)\n",
    "        \n",
    "log.info(\"Preparing input blobs\")\n",
    "input_blob = next(iter(net.inputs))\n",
    "out_blob = next(iter(net.outputs))\n",
    "#net.batch_size = len(args.input)\n",
    "n,c,h,w=net.inputs[input_blob].shape\n",
    "print(n,c,h,w)\n",
    "\n",
    "for i in range(n):\n",
    "    np.random.seed(5)\n",
    "    args.input=np.load('data1.npy')\n",
    "    images = args.input.transpose((0,3, 1, 2))  # Change data layout from HWC to CHW\n",
    "\n",
    "log.info(\"Batch size is {}\".format(n))\n",
    "# Loading model to the plugin\n",
    "log.info(\"Loading model to the plugin\")\n",
    "exec_net = plugin.load(network=net)\n",
    "# Start sync inference\n",
    "log.info(\"Starting inference ({} iterations)\".format(args.number_iter))\n",
    "infer_time = []\n",
    "for i in range(args.number_iter):\n",
    "    t0 = time()\n",
    "    res = exec_net.infer(inputs={input_blob: images})\n",
    "    infer_time.append((time() - t0) * 1000)\n",
    "log.info(\"Average running time of one iteration: {} ms\".format(np.average(np.asarray(infer_time))))\n",
    "log.info(\"Performance {:.2f} FPS\".format((1000/np.average(np.asarray(infer_time)))))\n",
    "\n",
    "log.info(\"Processing output blob\")\n",
    "res = res[out_blob]\n",
    "log.info(\"Top {} results: \".format(args.number_top))\n",
    "if args.labels:\n",
    "    with open(args.labels, 'r') as f:\n",
    "        labels_map = [x.split(sep=' ', maxsplit=1)[-1].strip() for x in f]\n",
    "else:\n",
    "    labels_map = None\n",
    "    \n",
    "classid_str = \"classid\"\n",
    "probability_str = \"probability\"\n",
    "for i, probs in enumerate(res):\n",
    "    probs = np.squeeze(probs)\n",
    "    top_ind = np.argsort(probs)[-args.number_top:][::-1]\n",
    "    #print(\"Image {}\\n\".format(args.input[i]))\n",
    "    print(classid_str, probability_str)\n",
    "    print(\"{} {}\".format('-' * len(classid_str), '-' * len(probability_str)))\n",
    "    for id in top_ind:\n",
    "        det_label = labels_map[id] if labels_map else \"{}\".format(id)\n",
    "        label_length = len(det_label)\n",
    "        space_num_before = (len(classid_str) - label_length) // 2\n",
    "        space_num_after = len(classid_str) - (space_num_before + label_length) + 2\n",
    "        space_num_before_prob = (len(probability_str) - len(str(probs[id]))) // 2\n",
    "        print(\"{}{}{}{}{:.7f}\".format(' ' * space_num_before, det_label,\n",
    "                                      ' ' * space_num_after, ' ' * space_num_before_prob,\n",
    "                                      probs[id]))    \n",
    "if args.perf_counts:\n",
    "    perf_counts = exec_net.requests[0].get_perf_counts()\n",
    "    log.info(\"Performance counters:\")\n",
    "    print(\"{:<60} {:<15} {:<25} {:<15} {:<10}\".format('name', 'layer_type', 'exet_type', 'status', 'real_time, us'))\n",
    "    for layer, stats in perf_counts.items():\n",
    "        layer = layer.split('/')[-1]\n",
    "        print(\"{:<60} {:<15} {:<25} {:<15} {:<10}\".format(layer, stats['layer_type'], stats['exec_type'],\n",
    "                                                          stats['status'], stats['real_time']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第二个分类模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.2618225e-03 6.2778038e-03 1.0355789e-02 9.5154536e-01 1.8674359e-04\n",
      " 5.0049443e-03 4.7170813e-03 3.7591392e-03 9.4591480e-05 5.0033408e-04\n",
      " 1.4174117e-02 1.2224575e-04]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "classid_str = \"classid\"\n",
    "probability_str = \"probability\"\n",
    "n,h,w,c=1,3,1000,1\n",
    "labels_map=None\n",
    "\n",
    "def load_graph(file_path):\n",
    "\n",
    "    with tf.gfile.GFile(file_path,'rb') as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "        with tf.Graph().as_default() as graph:\n",
    "            tf.import_graph_def(graph_def,input_map = None,return_elements = None,name = \"\",op_dict = None,producer_op_list = None)\n",
    "            graph_nodes = [n for n in graph_def.node]\n",
    "            return graph,graph_nodes\n",
    "pb_path = \"test_class/model_out/frozen_model.pb\"\n",
    "graph,graph_nodes = load_graph(pb_path)\n",
    "# for node in graph_nodes:\n",
    "#     print('node:', node.name)\n",
    "input = graph.get_tensor_by_name('input_node:0')\n",
    "output = graph.get_tensor_by_name('myoutputnode:0')\n",
    "\n",
    "\n",
    "data=np.load('data2.npy').reshape(1,h,w,c)\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    softmax_values = sess.run(output, feed_dict = {input: data})\n",
    "    \n",
    "    for i, probs in enumerate(softmax_values):\n",
    "        probs = np.squeeze(probs)\n",
    "        print(probs)\n",
    "#         top_ind = np.argsort(probs)[-:][::-1]\n",
    "#     print(classid_str, probability_str)\n",
    "#     print(\"{} {}\".format('-' * len(classid_str), '-' * len(probability_str)))\n",
    "#     for id in top_ind:\n",
    "#         det_label = labels_map[id] if labels_map else \"{}\".format(id)\n",
    "#         label_length = len(det_label)\n",
    "#         space_num_before = (len(classid_str) - label_length) // 2\n",
    "#         space_num_after = len(classid_str) - (space_num_before + label_length) + 2\n",
    "#         space_num_before_prob = (len(probability_str) - len(str(probs[id]))) // 2\n",
    "#         print(\"{}{}{}{}{:.7f}\".format(' ' * space_num_before, det_label,\n",
    "#                                       ' ' * space_num_after, ' ' * space_num_before_prob,\n",
    "#                                       probs[id]))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01-07 19:24:22,983 ERROR:Following layers are not supported by the plugin for specified device CPU:\n",
      " inceptionv1/SpatialSqueeze_logits\n",
      "2020-01-07 19:24:22,984 ERROR:Please try to specify cpu extensions library path in sample's command line parameters using -l or --cpu_extension command line argument\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py:3334: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "from time import time\n",
    "from openvino.inference_engine import IENetwork, IEPlugin\n",
    "\n",
    "\n",
    "class ObjDict(dict):\n",
    "    \"\"\"Makes a dictionary behave like an object, with attribute-style access.\n",
    "    \"\"\"\n",
    "\n",
    "    def __getattr__(self, name):\n",
    "        try:\n",
    "            return self[name]\n",
    "        except KeyError:\n",
    "            raise AttributeError(name)\n",
    "\n",
    "    def __setattr__(self, name, value):\n",
    "        self[name] = value\n",
    "args=ObjDict()\n",
    "\n",
    "args.device=\"CPU\"\n",
    "args.plugin_dir=None\n",
    "if args.device in ['CPU']:\n",
    "    args.model=\"test_class/model_converted/model_fp16/model_fp16.xml\"\n",
    "elif args.device in ['MYRIAD']:\n",
    "    args.model=\"test_class/model_converted/model_fp16/model_fp16.xml\"\n",
    "else:\n",
    "    args.model=\"test_class/model_converted/model_fp32/model_fp32.xml\"\n",
    "    #args.model=\"/home/ubuntu/tf_models/test20190704/model_converted/model_fp16/model_fp16.xml\"\n",
    "\n",
    "args.number_iter=100\n",
    "args.perf_counts=True\n",
    "args.number_top=13\n",
    "args.labels=None\n",
    "\n",
    "plugin = IEPlugin(device=args.device, plugin_dirs=args.plugin_dir)\n",
    "model_xml=args.model\n",
    "model_bin = os.path.splitext(model_xml)[0] + \".bin\"\n",
    "net = IENetwork(model=model_xml, weights=model_bin)\n",
    "\n",
    "if plugin.device == \"CPU\":\n",
    "    supported_layers = plugin.get_supported_layers(net)\n",
    "    not_supported_layers = [l for l in net.layers.keys() if l not in supported_layers]\n",
    "    if len(not_supported_layers) != 0:\n",
    "        log.error(\"Following layers are not supported by the plugin for specified device {}:\\n {}\".\n",
    "                  format(plugin.device, ', '.join(not_supported_layers)))\n",
    "        log.error(\"Please try to specify cpu extensions library path in sample's command line parameters using -l \"\n",
    "                  \"or --cpu_extension command line argument\")\n",
    "        sys.exit(1)\n",
    "        \n",
    "log.info(\"Preparing input blobs\")\n",
    "input_blob = next(iter(net.inputs))\n",
    "out_blob = next(iter(net.outputs))\n",
    "#net.batch_size = len(args.input)\n",
    "n,c,h,w=net.inputs[input_blob].shape\n",
    "print(n,c,h,w)\n",
    "\n",
    "for i in range(n):\n",
    "    np.random.seed(5)\n",
    "\n",
    "    args.input=np.load('data2.npy')\n",
    "    images = args.input.transpose((0,3, 1, 2))  # Change data layout from HWC to CHW\n",
    "\n",
    "log.info(\"Batch size is {}\".format(n))\n",
    "# Loading model to the plugin\n",
    "log.info(\"Loading model to the plugin\")\n",
    "exec_net = plugin.load(network=net)\n",
    "# Start sync inference\n",
    "log.info(\"Starting inference ({} iterations)\".format(args.number_iter))\n",
    "infer_time = []\n",
    "for i in range(args.number_iter):\n",
    "    t0 = time()\n",
    "    res = exec_net.infer(inputs={input_blob: images})\n",
    "    infer_time.append((time() - t0) * 1000)\n",
    "log.info(\"Average running time of one iteration: {} ms\".format(np.average(np.asarray(infer_time))))\n",
    "log.info(\"Performance {} FPS\".format(int(1000/np.average(np.asarray(infer_time)))))\n",
    "\n",
    "log.info(\"Processing output blob\")\n",
    "res = res[out_blob]\n",
    "log.info(\"Top {} results: \".format(args.number_top))\n",
    "if args.labels:\n",
    "    with open(args.labels, 'r') as f:\n",
    "        labels_map = [x.split(sep=' ', maxsplit=1)[-1].strip() for x in f]\n",
    "else:\n",
    "    labels_map = None\n",
    "    \n",
    "classid_str = \"classid\"\n",
    "probability_str = \"probability\"\n",
    "for i, probs in enumerate(res):\n",
    "    probs = np.squeeze(probs)\n",
    "    top_ind = np.argsort(probs)[-args.number_top:][::-1]\n",
    "    #print(\"Image {}\\n\".format(args.input[i]))\n",
    "    print(classid_str, probability_str)\n",
    "    print(\"{} {}\".format('-' * len(classid_str), '-' * len(probability_str)))\n",
    "    for id in top_ind:\n",
    "        det_label = labels_map[id] if labels_map else \"{}\".format(id)\n",
    "        label_length = len(det_label)\n",
    "        space_num_before = (len(classid_str) - label_length) // 2\n",
    "        space_num_after = len(classid_str) - (space_num_before + label_length) + 2\n",
    "        space_num_before_prob = (len(probability_str) - len(str(probs[id]))) // 2\n",
    "        print(\"{}{}{}{}{:.7f}\".format(' ' * space_num_before, det_label,\n",
    "                                      ' ' * space_num_after, ' ' * space_num_before_prob,\n",
    "                                      probs[id]))    \n",
    "if args.perf_counts:\n",
    "    perf_counts = exec_net.requests[0].get_perf_counts()\n",
    "    log.info(\"Performance counters:\")\n",
    "    print(\"{:<60} {:<15} {:<25} {:<15} {:<10}\".format('name', 'layer_type', 'exet_type', 'status', 'real_time, us'))\n",
    "    for layer, stats in perf_counts.items():\n",
    "        layer = layer.split('/')[-1]\n",
    "        print(\"{:<60} {:<15} {:<25} {:<15} {:<10}\".format(layer, stats['layer_type'], stats['exec_type'],\n",
    "                                                          stats['status'], stats['real_time']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01-07 19:24:37,011 INFO:Preparing input blobs\n",
      "1 1 3 1000\n",
      "2020-01-07 19:24:37,014 INFO:Batch size is 1\n",
      "2020-01-07 19:24:37,014 INFO:Loading model to the plugin\n",
      "2020-01-07 19:24:39,118 INFO:Starting inference (100 iterations)\n",
      "2020-01-07 19:24:41,553 INFO:Average running time of one iteration: 24.34601068496704 ms\n",
      "2020-01-07 19:24:41,554 INFO:Performance 41.07 FPS\n",
      "2020-01-07 19:24:41,554 INFO:Processing output blob\n",
      "2020-01-07 19:24:41,555 INFO:Top 13 results: \n",
      "classid probability\n",
      "------- -----------\n",
      "   3      0.9428711\n",
      "  10     0.0159912\n",
      "   2     0.0113297\n",
      "   1     0.0066643\n",
      "   5     0.0064659\n",
      "   6     0.0064163\n",
      "   7     0.0050583\n",
      "   0     0.0040703\n",
      "   9     0.0006032\n",
      "   4     0.0002429\n",
      "  11     0.0001874\n",
      "   8     0.0001196\n",
      "2020-01-07 19:24:41,557 INFO:Performance counters:\n",
      "name                                                         layer_type      exet_type                 status          real_time, us\n",
      "MaxPool                                                      Pooling         MaxPool                   EXECUTED        108       \n",
      "Conv2D                                                       Convolution     MyriadXHwOp               EXECUTED        104       \n",
      "Conv2D                                                       Convolution     Conv                      EXECUTED        1857      \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "Conv2D                                                       Convolution     MyriadXHwOp               EXECUTED        21        \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "AvgPool                                                      Pooling         MyriadXHwOp + injected[BiasRelu] EXECUTED        38        \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "Conv2D                                                       Convolution     Conv                      EXECUTED        1513      \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "Conv2D                                                       Convolution     MyriadXHwOp + injected[BiasRelu] EXECUTED        281       \n",
      "MaxPool                                                      Pooling         MaxPool                   EXECUTED        147       \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "Conv2D                                                       Convolution     MyriadXHwOp               EXECUTED        107       \n",
      "Conv2D                                                       Convolution     MyriadXHwOp + injected[BiasRelu] EXECUTED        218       \n",
      "MaxPool                                                      Pooling         MaxPool                   EXECUTED        138       \n",
      "Conv2D                                                       Convolution     Conv                      EXECUTED        2687      \n",
      "Conv2D                                                       Convolution     Conv                      EXECUTED        656       \n",
      "Conv2D                                                       Convolution     MyriadXHwOp               EXECUTED        18        \n",
      "concat                                                       Concat          Concat                    NOT_RUN         0         \n",
      "input_node                                                   Input           NONE                      NOT_RUN         0         \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "Transpose                                                    Permute         Permute                   EXECUTED        23        \n",
      "Conv2D                                                       Convolution     MyriadXHwOp + injected[Copy] EXECUTED        73        \n",
      "Conv2D                                                       Convolution     MyriadXHwOp               EXECUTED        21        \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "Conv2D                                                       Convolution     MyriadXHwOp + injected[Copy] EXECUTED        123       \n",
      "Conv2D                                                       Convolution     MyriadXHwOp               EXECUTED        18        \n",
      "AvgPool                                                      Pooling         MyriadXHwOp               EXECUTED        35        \n",
      "AvgPool                                                      Pooling         GlobalAvgPool             EXECUTED        77        \n",
      "AvgPool                                                      Pooling         MyriadXHwOp               EXECUTED        24        \n",
      "Relu                                                         ReLU            BiasRelu                  EXECUTED        63        \n",
      "concat                                                       Concat          Concat                    NOT_RUN         0         \n",
      "Conv2D                                                       Convolution     MyriadXHwOp + injected[Copy] EXECUTED        98        \n",
      "Transpose                                                    Permute         Permute                   EXECUTED        13        \n",
      "Conv2D                                                       Convolution     Conv                      EXECUTED        2271      \n",
      "concat                                                       Concat          Concat                    NOT_RUN         0         \n",
      "Conv2D                                                       Convolution     Conv                      EXECUTED        2280      \n",
      "<Extra>                                                      <Extra>         Convert_f32f16            EXECUTED        95        \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "Conv2D                                                       Convolution     Conv                      EXECUTED        2239      \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "Conv2D                                                       Convolution     Copy                      EXECUTED        270       \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "Conv2D                                                       Convolution     MyriadXHwOp + injected[Copy] EXECUTED        104       \n",
      "Reshape                                                      Reshape         Reshape                   NOT_RUN         0         \n",
      "Conv2D                                                       Convolution     MyriadXHwOp               EXECUTED        15        \n",
      "Conv2D                                                       Convolution     MyriadXHwOp + injected[BiasRelu] EXECUTED        248       \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "AvgPool                                                      Pooling         MyriadXHwOp + injected[Copy] EXECUTED        23        \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "MaxPool                                                      Pooling         MaxPool                   EXECUTED        94        \n",
      "AvgPool                                                      Pooling         MyriadXHwOp + injected[Copy] EXECUTED        18        \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "Conv2D                                                       Convolution     Conv                      EXECUTED        2326      \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "SpatialSqueeze_logits                                        Squeeze         Reshape                   NOT_RUN         0         \n",
      "myoutputnode                                                 SoftMax         SoftMax                   EXECUTED        57        \n",
      "Conv2D                                                       Convolution     MyriadXHwOp + injected[BiasRelu] EXECUTED        257       \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "concat                                                       Concat          Concat                    NOT_RUN         0         \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "Conv2D                                                       Convolution     MyriadXHwOp + injected[BiasRelu] EXECUTED        146       \n",
      "concat                                                       Concat          Concat                    NOT_RUN         0         \n",
      "Conv2D                                                       Convolution     MyriadXHwOp + injected[Copy] EXECUTED        69        \n",
      "AvgPool                                                      Pooling         MyriadXHwOp               EXECUTED        28        \n",
      "Tensordot                                                    Reshape         Reshape                   NOT_RUN         0         \n",
      "AvgPool                                                      Pooling         MyriadXHwOp + injected[Copy] EXECUTED        34        \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "Conv2D                                                       Convolution     MyriadXHwOp               EXECUTED        18        \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "Conv2D                                                       Convolution     MyriadXHwOp + injected[Copy] EXECUTED        18        \n",
      "transpose                                                    Permute         Permute                   EXECUTED        26        \n",
      "MaxPool                                                      Pooling         MaxPool                   EXECUTED        120       \n",
      "Conv2D                                                       Convolution     MyriadXHwOp               EXECUTED        70        \n",
      "MaxPool                                                      Pooling         MaxPool                   EXECUTED        164       \n",
      "Conv2D                                                       Convolution     Conv                      EXECUTED        2180      \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "Add                                                          ScaleShift      ScaleShift                EXECUTED        47        \n",
      "Conv2D                                                       Convolution     MyriadXHwOp + injected[Copy] EXECUTED        100       \n",
      "concat                                                       Concat          Concat                    NOT_RUN         0         \n",
      "Conv2D                                                       Convolution     MyriadXHwOp               EXECUTED        17        \n",
      "MatMul                                                       FullyConnected  MyriadXHwOp               EXECUTED        24        \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "Conv2D                                                       Convolution     MyriadXHwOp + injected[BiasRelu] EXECUTED        242       \n",
      "Conv2D                                                       Convolution     MyriadXHwOp + injected[BiasRelu] EXECUTED        74        \n",
      "concat                                                       Concat          Concat                    NOT_RUN         0         \n",
      "Conv2D                                                       Convolution     MyriadXHwOp + injected[Copy] EXECUTED        65        \n",
      "AvgPool                                                      Pooling         MyriadXHwOp               EXECUTED        25        \n",
      "concat                                                       Concat          Concat                    NOT_RUN         0         \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "Conv2D                                                       Convolution     MyriadXHwOp + injected[Copy] EXECUTED        73        \n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "from time import time\n",
    "from openvino.inference_engine import IENetwork, IEPlugin\n",
    "\n",
    "\n",
    "class ObjDict(dict):\n",
    "    \"\"\"Makes a dictionary behave like an object, with attribute-style access.\n",
    "    \"\"\"\n",
    "\n",
    "    def __getattr__(self, name):\n",
    "        try:\n",
    "            return self[name]\n",
    "        except KeyError:\n",
    "            raise AttributeError(name)\n",
    "\n",
    "    def __setattr__(self, name, value):\n",
    "        self[name] = value\n",
    "args=ObjDict()\n",
    "\n",
    "args.device=\"MYRIAD\"\n",
    "args.plugin_dir=None\n",
    "if args.device in ['CPU']:\n",
    "    args.model=\"test_class/model_converted/model_fp16/model_fp16.xml\"\n",
    "elif args.device in ['MYRIAD']:\n",
    "    args.model=\"test_class/model_converted/model_fp16/model_fp16.xml\"\n",
    "else:\n",
    "    args.model=\"test_class/model_converted/model_fp32/model_fp32.xml\"\n",
    "    #args.model=\"/home/ubuntu/tf_models/test20190704/model_converted/model_fp16/model_fp16.xml\"\n",
    "\n",
    "args.number_iter=100\n",
    "args.perf_counts=True\n",
    "args.number_top=13\n",
    "args.labels=None\n",
    "\n",
    "plugin = IEPlugin(device=args.device, plugin_dirs=args.plugin_dir)\n",
    "model_xml=args.model\n",
    "model_bin = os.path.splitext(model_xml)[0] + \".bin\"\n",
    "net = IENetwork(model=model_xml, weights=model_bin)\n",
    "\n",
    "if plugin.device == \"CPU\":\n",
    "    supported_layers = plugin.get_supported_layers(net)\n",
    "    not_supported_layers = [l for l in net.layers.keys() if l not in supported_layers]\n",
    "    if len(not_supported_layers) != 0:\n",
    "        log.error(\"Following layers are not supported by the plugin for specified device {}:\\n {}\".\n",
    "                  format(plugin.device, ', '.join(not_supported_layers)))\n",
    "        log.error(\"Please try to specify cpu extensions library path in sample's command line parameters using -l \"\n",
    "                  \"or --cpu_extension command line argument\")\n",
    "        sys.exit(1)\n",
    "        \n",
    "log.info(\"Preparing input blobs\")\n",
    "input_blob = next(iter(net.inputs))\n",
    "out_blob = next(iter(net.outputs))\n",
    "#net.batch_size = len(args.input)\n",
    "n,c,h,w=net.inputs[input_blob].shape\n",
    "print(n,c,h,w)\n",
    "\n",
    "for i in range(n):\n",
    "    np.random.seed(5)\n",
    "\n",
    "    args.input=np.load('data2.npy')\n",
    "    images = args.input.transpose((0,3, 1, 2))  # Change data layout from HWC to CHW\n",
    "\n",
    "log.info(\"Batch size is {}\".format(n))\n",
    "# Loading model to the plugin\n",
    "log.info(\"Loading model to the plugin\")\n",
    "exec_net = plugin.load(network=net)\n",
    "# Start sync inference\n",
    "log.info(\"Starting inference ({} iterations)\".format(args.number_iter))\n",
    "infer_time = []\n",
    "for i in range(args.number_iter):\n",
    "    t0 = time()\n",
    "    res = exec_net.infer(inputs={input_blob: images})\n",
    "    infer_time.append((time() - t0) * 1000)\n",
    "log.info(\"Average running time of one iteration: {} ms\".format(np.average(np.asarray(infer_time))))\n",
    "log.info(\"Performance {:.2f} FPS\".format((1000/np.average(np.asarray(infer_time)))))\n",
    "\n",
    "log.info(\"Processing output blob\")\n",
    "res = res[out_blob]\n",
    "log.info(\"Top {} results: \".format(args.number_top))\n",
    "if args.labels:\n",
    "    with open(args.labels, 'r') as f:\n",
    "        labels_map = [x.split(sep=' ', maxsplit=1)[-1].strip() for x in f]\n",
    "else:\n",
    "    labels_map = None\n",
    "    \n",
    "classid_str = \"classid\"\n",
    "probability_str = \"probability\"\n",
    "for i, probs in enumerate(res):\n",
    "    probs = np.squeeze(probs)\n",
    "    top_ind = np.argsort(probs)[-args.number_top:][::-1]\n",
    "    #print(\"Image {}\\n\".format(args.input[i]))\n",
    "    print(classid_str, probability_str)\n",
    "    print(\"{} {}\".format('-' * len(classid_str), '-' * len(probability_str)))\n",
    "    for id in top_ind:\n",
    "        det_label = labels_map[id] if labels_map else \"{}\".format(id)\n",
    "        label_length = len(det_label)\n",
    "        space_num_before = (len(classid_str) - label_length) // 2\n",
    "        space_num_after = len(classid_str) - (space_num_before + label_length) + 2\n",
    "        space_num_before_prob = (len(probability_str) - len(str(probs[id]))) // 2\n",
    "        print(\"{}{}{}{}{:.7f}\".format(' ' * space_num_before, det_label,\n",
    "                                      ' ' * space_num_after, ' ' * space_num_before_prob,\n",
    "                                      probs[id]))    \n",
    "if args.perf_counts:\n",
    "    perf_counts = exec_net.requests[0].get_perf_counts()\n",
    "    log.info(\"Performance counters:\")\n",
    "    print(\"{:<60} {:<15} {:<25} {:<15} {:<10}\".format('name', 'layer_type', 'exet_type', 'status', 'real_time, us'))\n",
    "    for layer, stats in perf_counts.items():\n",
    "        layer = layer.split('/')[-1]\n",
    "        print(\"{:<60} {:<15} {:<25} {:<15} {:<10}\".format(layer, stats['layer_type'], stats['exec_type'],\n",
    "                                                          stats['status'], stats['real_time']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01-07 20:07:13,149 INFO:Preparing input blobs\n",
      "1 1 3 1000\n",
      "2020-01-07 20:07:13,150 INFO:Batch size is 1\n",
      "2020-01-07 20:07:13,151 INFO:Loading model to the plugin\n",
      "2020-01-07 20:07:15,325 INFO:Starting inference (100 iterations)\n",
      "2020-01-07 20:07:17,795 INFO:Average running time of one iteration: 24.68571901321411 ms\n",
      "2020-01-07 20:07:17,796 INFO:Performance 40.51 FPS\n",
      "2020-01-07 20:07:17,797 INFO:Processing output blob\n",
      "2020-01-07 20:07:17,797 INFO:Top 13 results: \n",
      "classid probability\n",
      "------- -----------\n",
      "   6      0.6801758\n",
      "  10     0.0928345\n",
      "   7     0.0728760\n",
      "   3     0.0479431\n",
      "   1      0.0340271\n",
      "   8     0.0271301\n",
      "  11     0.0204620\n",
      "   9     0.0099869\n",
      "   4     0.0096436\n",
      "   2     0.0038815\n",
      "   5     0.0007901\n",
      "   0     0.0003078\n",
      "2020-01-07 20:07:17,801 INFO:Performance counters:\n",
      "name                                                         layer_type      exet_type                 status          real_time, us\n",
      "concat                                                       Concat          Concat                    NOT_RUN         0         \n",
      "Transpose                                                    Permute         Permute                   EXECUTED        92        \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "Conv2D                                                       Convolution     MyriadXHwOp + injected[BiasRelu] EXECUTED        147       \n",
      "MaxPool                                                      Pooling         MaxPool                   EXECUTED        97        \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "Conv2D                                                       Convolution     MyriadXHwOp               EXECUTED        17        \n",
      "MatMul                                                       FullyConnected  MyriadXHwOp               EXECUTED        21        \n",
      "concat                                                       Concat          Concat                    NOT_RUN         0         \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "Conv2D                                                       Convolution     MyriadXHwOp               EXECUTED        15        \n",
      "Conv2D                                                       Convolution     MyriadXHwOp               EXECUTED        18        \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "Conv2D                                                       Convolution     MyriadXHwOp               EXECUTED        18        \n",
      "MatMul                                                       FullyConnected  MyriadXHwOp               EXECUTED        84        \n",
      "Conv2D                                                       Convolution     Conv                      EXECUTED        2158      \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "Reshape                                                      Reshape         Reshape                   NOT_RUN         0         \n",
      "Conv2D                                                       Convolution     MyriadXHwOp               EXECUTED        21        \n",
      "Conv2D                                                       Convolution     MyriadXHwOp + injected[Copy] EXECUTED        104       \n",
      "Conv2D                                                       Convolution     MyriadXHwOp + injected[BiasRelu] EXECUTED        239       \n",
      "<Extra>                                                      <Extra>         Convert_f32f16            EXECUTED        88        \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "Conv2D                                                       Convolution     Copy                      EXECUTED        269       \n",
      "Conv2D                                                       Convolution     MyriadXHwOp + injected[Copy] EXECUTED        73        \n",
      "Conv2D                                                       Convolution     MyriadXHwOp + injected[Copy] EXECUTED        127       \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "input_node                                                   Input           NONE                      NOT_RUN         0         \n",
      "Conv2D                                                       Convolution     MyriadXHwOp + injected[Copy] EXECUTED        67        \n",
      "concat                                                       Concat          Concat                    NOT_RUN         0         \n",
      "Conv2D                                                       Convolution     Conv                      EXECUTED        2273      \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "Conv2D                                                       Convolution     MyriadXHwOp + injected[Copy] EXECUTED        18        \n",
      "AvgPool                                                      Pooling         MyriadXHwOp + injected[Copy] EXECUTED        34        \n",
      "AvgPool                                                      Pooling         MyriadXHwOp + injected[Copy] EXECUTED        18        \n",
      "Conv2D                                                       Convolution     MyriadXHwOp + injected[Copy] EXECUTED        98        \n",
      "AvgPool                                                      Pooling         MyriadXHwOp + injected[BiasRelu] EXECUTED        38        \n",
      "Conv2D                                                       Convolution     Conv                      EXECUTED        1516      \n",
      "Conv2D                                                       Convolution     MyriadXHwOp               EXECUTED        105       \n",
      "Conv2D                                                       Convolution     MyriadXHwOp + injected[BiasRelu] EXECUTED        249       \n",
      "Conv2D                                                       Convolution     Conv                      EXECUTED        2332      \n",
      "AvgPool                                                      Pooling         MyriadXHwOp               EXECUTED        36        \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "concat                                                       Concat          Concat                    NOT_RUN         0         \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "AvgPool                                                      Pooling         MyriadXHwOp + injected[Copy] EXECUTED        23        \n",
      "MaxPool                                                      Pooling         MaxPool                   EXECUTED        137       \n",
      "MaxPool                                                      Pooling         MaxPool                   EXECUTED        118       \n",
      "Conv2D                                                       Convolution     Conv                      EXECUTED        2315      \n",
      "Conv2D                                                       Convolution     MyriadXHwOp + injected[Copy] EXECUTED        56        \n",
      "AvgPool                                                      Pooling         MyriadXHwOp               EXECUTED        24        \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "concat                                                       Concat          Concat                    NOT_RUN         0         \n",
      "Conv2D                                                       Convolution     MyriadXHwOp + injected[Copy] EXECUTED        100       \n",
      "Relu                                                         ReLU            BiasRelu                  EXECUTED        63        \n",
      "Relu                                                         ReLU            Relu                      EXECUTED        43        \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "Conv2D                                                       Convolution     MyriadXHwOp               EXECUTED        21        \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "Conv2D                                                       Convolution     MyriadXHwOp + injected[BiasRelu] EXECUTED        257       \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "Conv2D                                                       Convolution     Conv                      EXECUTED        654       \n",
      "Conv2D                                                       Convolution     Conv                      EXECUTED        1852      \n",
      "MaxPool                                                      Pooling         MaxPool                   EXECUTED        164       \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "concat                                                       Concat          Concat                    NOT_RUN         0         \n",
      "MaxPool                                                      Pooling         MaxPool                   EXECUTED        106       \n",
      "AvgPool                                                      Pooling         MyriadXHwOp               EXECUTED        25        \n",
      "Conv2D                                                       Convolution     MyriadXHwOp               EXECUTED        18        \n",
      "Conv2D                                                       Convolution     MyriadXHwOp + injected[Copy] EXECUTED        75        \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "MatMul                                                       FullyConnected  Copy                      EXECUTED        419       \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "concat                                                       Concat          Concat                    NOT_RUN         0         \n",
      "Conv2D                                                       Convolution     MyriadXHwOp + injected[BiasRelu] EXECUTED        278       \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "Conv2D                                                       Convolution     Conv                      EXECUTED        2711      \n",
      "concat                                                       Concat          Concat                    NOT_RUN         0         \n",
      "myoutputnode                                                 SoftMax         SoftMax                   EXECUTED        43        \n",
      "AvgPool                                                      Pooling         MyriadXHwOp               EXECUTED        29        \n",
      "Conv2D                                                       Convolution     MyriadXHwOp + injected[BiasRelu] EXECUTED        74        \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "Conv2D                                                       Convolution     MyriadXHwOp + injected[BiasRelu] EXECUTED        217       \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "Conv2D                                                       Convolution     Conv                      EXECUTED        2174      \n",
      "MaxPool                                                      Pooling         MaxPool                   EXECUTED        146       \n",
      "Relu                                                         ReLU            Relu                      EXECUTED        31        \n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "from time import time\n",
    "from openvino.inference_engine import IENetwork, IEPlugin\n",
    "\n",
    "\n",
    "class ObjDict(dict):\n",
    "    \"\"\"Makes a dictionary behave like an object, with attribute-style access.\n",
    "    \"\"\"\n",
    "\n",
    "    def __getattr__(self, name):\n",
    "        try:\n",
    "            return self[name]\n",
    "        except KeyError:\n",
    "            raise AttributeError(name)\n",
    "\n",
    "    def __setattr__(self, name, value):\n",
    "        self[name] = value\n",
    "args=ObjDict()\n",
    "\n",
    "args.device=\"MYRIAD\"\n",
    "args.plugin_dir=None\n",
    "if args.device in ['CPU']:\n",
    "    args.model=\"test_class1/model_converted/model_fp16/model_fp16.xml\"\n",
    "elif args.device in ['MYRIAD']:\n",
    "    args.model=\"test_class1/model_converted/model_fp16/model_fp16.xml\"\n",
    "else:\n",
    "    args.model=\"test_class1/model_converted/model_fp32/model_fp32.xml\"\n",
    "    #args.model=\"/home/ubuntu/tf_models/test20190704/model_converted/model_fp16/model_fp16.xml\"\n",
    "\n",
    "args.number_iter=100\n",
    "args.perf_counts=True\n",
    "args.number_top=13\n",
    "args.labels=None\n",
    "\n",
    "plugin = IEPlugin(device=args.device, plugin_dirs=args.plugin_dir)\n",
    "model_xml=args.model\n",
    "model_bin = os.path.splitext(model_xml)[0] + \".bin\"\n",
    "net = IENetwork(model=model_xml, weights=model_bin)\n",
    "\n",
    "if plugin.device == \"CPU\":\n",
    "    supported_layers = plugin.get_supported_layers(net)\n",
    "    not_supported_layers = [l for l in net.layers.keys() if l not in supported_layers]\n",
    "    if len(not_supported_layers) != 0:\n",
    "        log.error(\"Following layers are not supported by the plugin for specified device {}:\\n {}\".\n",
    "                  format(plugin.device, ', '.join(not_supported_layers)))\n",
    "        log.error(\"Please try to specify cpu extensions library path in sample's command line parameters using -l \"\n",
    "                  \"or --cpu_extension command line argument\")\n",
    "        sys.exit(1)\n",
    "        \n",
    "log.info(\"Preparing input blobs\")\n",
    "input_blob = next(iter(net.inputs))\n",
    "out_blob = next(iter(net.outputs))\n",
    "#net.batch_size = len(args.input)\n",
    "n,c,h,w=net.inputs[input_blob].shape\n",
    "print(n,c,h,w)\n",
    "\n",
    "for i in range(n):\n",
    "    np.random.seed(5)\n",
    "\n",
    "    args.input=np.load('data2.npy')\n",
    "    images = args.input.transpose((0,3, 1, 2))  # Change data layout from HWC to CHW\n",
    "\n",
    "log.info(\"Batch size is {}\".format(n))\n",
    "# Loading model to the plugin\n",
    "log.info(\"Loading model to the plugin\")\n",
    "exec_net = plugin.load(network=net)\n",
    "# Start sync inference\n",
    "log.info(\"Starting inference ({} iterations)\".format(args.number_iter))\n",
    "infer_time = []\n",
    "for i in range(args.number_iter):\n",
    "    t0 = time()\n",
    "    res = exec_net.infer(inputs={input_blob: images})\n",
    "    infer_time.append((time() - t0) * 1000)\n",
    "log.info(\"Average running time of one iteration: {} ms\".format(np.average(np.asarray(infer_time))))\n",
    "log.info(\"Performance {:.2f} FPS\".format((1000/np.average(np.asarray(infer_time)))))\n",
    "\n",
    "log.info(\"Processing output blob\")\n",
    "res = res[out_blob]\n",
    "log.info(\"Top {} results: \".format(args.number_top))\n",
    "if args.labels:\n",
    "    with open(args.labels, 'r') as f:\n",
    "        labels_map = [x.split(sep=' ', maxsplit=1)[-1].strip() for x in f]\n",
    "else:\n",
    "    labels_map = None\n",
    "    \n",
    "classid_str = \"classid\"\n",
    "probability_str = \"probability\"\n",
    "for i, probs in enumerate(res):\n",
    "    probs = np.squeeze(probs)\n",
    "    top_ind = np.argsort(probs)[-args.number_top:][::-1]\n",
    "    #print(\"Image {}\\n\".format(args.input[i]))\n",
    "    print(classid_str, probability_str)\n",
    "    print(\"{} {}\".format('-' * len(classid_str), '-' * len(probability_str)))\n",
    "    for id in top_ind:\n",
    "        det_label = labels_map[id] if labels_map else \"{}\".format(id)\n",
    "        label_length = len(det_label)\n",
    "        space_num_before = (len(classid_str) - label_length) // 2\n",
    "        space_num_after = len(classid_str) - (space_num_before + label_length) + 2\n",
    "        space_num_before_prob = (len(probability_str) - len(str(probs[id]))) // 2\n",
    "        print(\"{}{}{}{}{:.7f}\".format(' ' * space_num_before, det_label,\n",
    "                                      ' ' * space_num_after, ' ' * space_num_before_prob,\n",
    "                                      probs[id]))    \n",
    "if args.perf_counts:\n",
    "    perf_counts = exec_net.requests[0].get_perf_counts()\n",
    "    log.info(\"Performance counters:\")\n",
    "    print(\"{:<60} {:<15} {:<25} {:<15} {:<10}\".format('name', 'layer_type', 'exet_type', 'status', 'real_time, us'))\n",
    "    for layer, stats in perf_counts.items():\n",
    "        layer = layer.split('/')[-1]\n",
    "        print(\"{:<60} {:<15} {:<25} {:<15} {:<10}\".format(layer, stats['layer_type'], stats['exec_type'],\n",
    "                                                          stats['status'], stats['real_time']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2020年1月13日最新测试"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model1 同步"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01-13 11:21:35,483 INFO:Creating Inference Engine\n",
      "2020-01-13 11:21:35,484 INFO:Loading network files:\n",
      "\ttest/model_converted/model_fp16/model_fp16.xml\n",
      "\ttest/model_converted/model_fp16/model_fp16.bin\n",
      "2020-01-13 11:21:35,488 INFO:Preparing input blobs\n",
      "1 1 1 500\n",
      "2020-01-13 11:21:35,490 INFO:Batch size is 1\n",
      "2020-01-13 11:21:35,491 INFO:Loading model to the plugin\n",
      "2020-01-13 11:21:37,496 INFO:Starting inference in synchronous mode\n",
      "2020-01-13 11:21:37,497 INFO:Starting inference (1000 iterations)\n",
      "2020-01-13 11:21:42,314 INFO:Average running time of one iteration: 4.815056085586548 ms\n",
      "2020-01-13 11:21:42,314 INFO:Performance 207.68 FPS\n",
      "2020-01-13 11:21:42,315 INFO:Processing output blob\n",
      "2020-01-13 11:21:42,315 INFO:Top 5 results: \n",
      "classid probability\n",
      "------- -----------\n",
      "   2      0.6484375\n",
      "   0     0.3024902\n",
      "   1     0.0493164\n",
      "2020-01-13 11:21:42,317 INFO:Performance counters:\n",
      "name                                                         layer_type      exet_type                 status          real_time, us\n",
      "Relu                                                         ReLU            Relu                      EXECUTED        35        \n",
      "MaxPool                                                      Pooling         MaxPool                   EXECUTED        267       \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "Conv2D                                                       Convolution     MyriadXHwOp               EXECUTED        437       \n",
      "Conv2D                                                       Convolution     MyriadXHwOp               EXECUTED        77        \n",
      "myoutputnode                                                 SoftMax         SoftMax                   EXECUTED        37        \n",
      "MatMul                                                       FullyConnected  MyriadXHwOp               EXECUTED        20        \n",
      "input_node                                                   Input           NONE                      NOT_RUN         0         \n",
      "Transpose                                                    Permute         Permute                   EXECUTED        125       \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "Conv2D                                                       Convolution     MyriadXHwOp               EXECUTED        477       \n",
      "Relu                                                         ReLU            Relu                      EXECUTED        42        \n",
      "MaxPool                                                      Pooling         MaxPool                   EXECUTED        305       \n",
      "Reshape                                                      Reshape         Reshape                   NOT_RUN         0         \n",
      "MatMul                                                       FullyConnected  Copy                      EXECUTED        1165      \n",
      "MaxPool                                                      Pooling         MaxPool                   EXECUTED        189       \n",
      "<Extra>                                                      <Extra>         Convert_f32f16            EXECUTED        79        \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "MatMul                                                       FullyConnected  MyriadXHwOp               EXECUTED        69        \n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "from time import time\n",
    "import logging as log\n",
    "#reload(logging)\n",
    "from openvino.inference_engine import IENetwork, IECore\n",
    "log.basicConfig(format='%(asctime)s %(levelname)s:%(message)s', level=log.INFO,stream=sys.stdout)\n",
    "\n",
    "class ObjDict(dict):\n",
    "    \"\"\"Makes a dictionary behave like an object, with attribute-style access.\n",
    "    \"\"\"\n",
    "\n",
    "    def __getattr__(self, name):\n",
    "        try:\n",
    "            return self[name]\n",
    "        except KeyError:\n",
    "            raise AttributeError(name)\n",
    "\n",
    "    def __setattr__(self, name, value):\n",
    "        self[name] = value\n",
    "args=ObjDict()\n",
    "args.device=\"MYRIAD\"\n",
    "args.number_iter=1000\n",
    "args.perf_counts=True\n",
    "args.number_top=5\n",
    "args.labels=None\n",
    "\n",
    "\n",
    "if args.device in ['CPU']:\n",
    "    args.model=\"test/model_converted/model_fp16/model_fp16.xml\"\n",
    "elif args.device in ['MYRIAD']:\n",
    "    args.model=\"test/model_converted/model_fp16/model_fp16.xml\"\n",
    "else:\n",
    "    args.model=\"test/model_converted/model_fp32/model_fp32.xml\"\n",
    "    #args.model=\"/home/ubuntu/tf_models/test20190704/model_converted/model_fp16/model_fp16.xml\"\n",
    "    \n",
    "model_xml=args.model\n",
    "model_bin = os.path.splitext(model_xml)[0] + \".bin\"\n",
    "\n",
    "log.info(\"Creating Inference Engine\")\n",
    "ie = IECore()\n",
    "log.info(\"Loading network files:\\n\\t{}\\n\\t{}\".format(model_xml, model_bin))\n",
    "net = IENetwork(model=model_xml, weights=model_bin)\n",
    "\n",
    "log.info(\"Preparing input blobs\")\n",
    "input_blob = next(iter(net.inputs))\n",
    "out_blob = next(iter(net.outputs))\n",
    "n,c,h,w=net.inputs[input_blob].shape\n",
    "print(n,c,h,w)\n",
    "\n",
    "for i in range(n):\n",
    "    np.random.seed(5)\n",
    "    args.input=np.load('data1.npy')\n",
    "    images = args.input.transpose((0,3, 1, 2))  # Change data layout from HWC to CHW\n",
    "\n",
    "log.info(\"Batch size is {}\".format(n))\n",
    "# Loading model to the plugin\n",
    "log.info(\"Loading model to the plugin\")\n",
    "exec_net = ie.load_network(network=net, device_name=args.device)\n",
    "log.info(\"Starting inference in synchronous mode\")\n",
    "log.info(\"Starting inference ({} iterations)\".format(args.number_iter))\n",
    "infer_time = []\n",
    "for i in range(args.number_iter):\n",
    "    t0 = time()\n",
    "    res = exec_net.infer(inputs={input_blob: images})\n",
    "    infer_time.append((time() - t0) * 1000)\n",
    "log.info(\"Average running time of one iteration: {} ms\".format(np.average(np.asarray(infer_time))))\n",
    "log.info(\"Performance {:.2f} FPS\".format((1000/np.average(np.asarray(infer_time)))))\n",
    "\n",
    "log.info(\"Processing output blob\")\n",
    "res = res[out_blob]\n",
    "log.info(\"Top {} results: \".format(args.number_top))\n",
    "if args.labels:\n",
    "    with open(args.labels, 'r') as f:\n",
    "        labels_map = [x.split(sep=' ', maxsplit=1)[-1].strip() for x in f]\n",
    "else:\n",
    "    labels_map = None\n",
    "    \n",
    "classid_str = \"classid\"\n",
    "probability_str = \"probability\"\n",
    "for i, probs in enumerate(res):\n",
    "    probs = np.squeeze(probs)\n",
    "    top_ind = np.argsort(probs)[-args.number_top:][::-1]\n",
    "    #print(\"Image {}\\n\".format(args.input[i]))\n",
    "    print(classid_str, probability_str)\n",
    "    print(\"{} {}\".format('-' * len(classid_str), '-' * len(probability_str)))\n",
    "    for id in top_ind:\n",
    "        det_label = labels_map[id] if labels_map else \"{}\".format(id)\n",
    "        label_length = len(det_label)\n",
    "        space_num_before = (len(classid_str) - label_length) // 2\n",
    "        space_num_after = len(classid_str) - (space_num_before + label_length) + 2\n",
    "        space_num_before_prob = (len(probability_str) - len(str(probs[id]))) // 2\n",
    "        print(\"{}{}{}{}{:.7f}\".format(' ' * space_num_before, det_label,\n",
    "                                      ' ' * space_num_after, ' ' * space_num_before_prob,\n",
    "                                      probs[id]))    \n",
    "if args.perf_counts:\n",
    "    perf_counts = exec_net.requests[0].get_perf_counts()\n",
    "    log.info(\"Performance counters:\")\n",
    "    print(\"{:<60} {:<15} {:<25} {:<15} {:<10}\".format('name', 'layer_type', 'exet_type', 'status', 'real_time, us'))\n",
    "    for layer, stats in perf_counts.items():\n",
    "        layer = layer.split('/')[-1]\n",
    "        print(\"{:<60} {:<15} {:<25} {:<15} {:<10}\".format(layer, stats['layer_type'], stats['exec_type'],\n",
    "                                                          stats['status'], stats['real_time']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model2 同步"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01-13 11:24:39,221 INFO:Creating Inference Engine\n",
      "2020-01-13 11:24:39,224 INFO:Loading network files:\n",
      "\ttest_class/model_converted/model_fp16/model_fp16.xml\n",
      "\ttest_class/model_converted/model_fp16/model_fp16.bin\n",
      "2020-01-13 11:24:39,388 INFO:Preparing input blobs\n",
      "1 1 3 1000\n",
      "2020-01-13 11:24:39,409 INFO:Batch size is 1\n",
      "2020-01-13 11:24:39,410 INFO:Loading model to the plugin\n",
      "2020-01-13 11:24:41,509 INFO:Starting inference in synchronous mode\n",
      "2020-01-13 11:24:41,510 INFO:Starting inference (1000 iterations)\n",
      "2020-01-13 11:25:06,199 INFO:Average running time of one iteration: 24.682459831237793 ms\n",
      "2020-01-13 11:25:06,199 INFO:Performance 40.51 FPS\n",
      "2020-01-13 11:25:06,200 INFO:Processing output blob\n",
      "2020-01-13 11:25:06,200 INFO:Top 13 results: \n",
      "classid probability\n",
      "------- -----------\n",
      "   3      0.9428711\n",
      "  10     0.0159912\n",
      "   2     0.0113297\n",
      "   1     0.0066643\n",
      "   5     0.0064659\n",
      "   6     0.0064163\n",
      "   7     0.0050583\n",
      "   0     0.0040703\n",
      "   9     0.0006032\n",
      "   4     0.0002429\n",
      "  11     0.0001874\n",
      "   8     0.0001196\n",
      "2020-01-13 11:25:06,203 INFO:Performance counters:\n",
      "name                                                         layer_type      exet_type                 status          real_time, us\n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "Conv2D                                                       Convolution     Conv                      EXECUTED        651       \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "Conv2D                                                       Convolution     MyriadXHwOp + injected[BiasRelu] EXECUTED        74        \n",
      "MaxPool                                                      Pooling         MaxPool                   EXECUTED        120       \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "concat                                                       Concat          Concat                    NOT_RUN         0         \n",
      "AvgPool                                                      Pooling         MyriadXHwOp               EXECUTED        24        \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "concat                                                       Concat          Concat                    NOT_RUN         0         \n",
      "Conv2D                                                       Convolution     MyriadXHwOp               EXECUTED        70        \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "Conv2D                                                       Convolution     Conv                      EXECUTED        2229      \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "Tensordot                                                    Reshape         Reshape                   NOT_RUN         0         \n",
      "MatMul                                                       FullyConnected  MyriadXHwOp               EXECUTED        25        \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "input_node                                                   Input           NONE                      NOT_RUN         0         \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "Conv2D                                                       Convolution     MyriadXHwOp               EXECUTED        18        \n",
      "Conv2D                                                       Convolution     MyriadXHwOp               EXECUTED        105       \n",
      "AvgPool                                                      Pooling         MyriadXHwOp + injected[Copy] EXECUTED        23        \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "Conv2D                                                       Convolution     Conv                      EXECUTED        2688      \n",
      "Conv2D                                                       Convolution     MyriadXHwOp + injected[Copy] EXECUTED        63        \n",
      "concat                                                       Concat          Concat                    NOT_RUN         0         \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "concat                                                       Concat          Concat                    NOT_RUN         0         \n",
      "Conv2D                                                       Convolution     MyriadXHwOp               EXECUTED        21        \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "SpatialSqueeze_logits                                        Squeeze         Reshape                   NOT_RUN         0         \n",
      "Conv2D                                                       Convolution     MyriadXHwOp + injected[Copy] EXECUTED        98        \n",
      "Conv2D                                                       Convolution     Conv                      EXECUTED        2273      \n",
      "MaxPool                                                      Pooling         MaxPool                   EXECUTED        107       \n",
      "AvgPool                                                      Pooling         MyriadXHwOp + injected[Copy] EXECUTED        34        \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "Conv2D                                                       Convolution     MyriadXHwOp + injected[BiasRelu] EXECUTED        252       \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "Transpose                                                    Permute         Permute                   EXECUTED        12        \n",
      "AvgPool                                                      Pooling         MyriadXHwOp + injected[Copy] EXECUTED        19        \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "AvgPool                                                      Pooling         MyriadXHwOp               EXECUTED        27        \n",
      "Conv2D                                                       Convolution     MyriadXHwOp + injected[Copy] EXECUTED        99        \n",
      "AvgPool                                                      Pooling         MyriadXHwOp               EXECUTED        35        \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "MaxPool                                                      Pooling         MaxPool                   EXECUTED        146       \n",
      "Add                                                          ScaleShift      ScaleShift                EXECUTED        50        \n",
      "Conv2D                                                       Convolution     MyriadXHwOp + injected[Copy] EXECUTED        73        \n",
      "Conv2D                                                       Convolution     MyriadXHwOp               EXECUTED        21        \n",
      "MaxPool                                                      Pooling         MaxPool                   EXECUTED        164       \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "concat                                                       Concat          Concat                    NOT_RUN         0         \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "Conv2D                                                       Convolution     MyriadXHwOp               EXECUTED        113       \n",
      "Conv2D                                                       Convolution     Conv                      EXECUTED        2153      \n",
      "Conv2D                                                       Convolution     MyriadXHwOp + injected[BiasRelu] EXECUTED        237       \n",
      "AvgPool                                                      Pooling         GlobalAvgPool             EXECUTED        77        \n",
      "Conv2D                                                       Convolution     Conv                      EXECUTED        2234      \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "Conv2D                                                       Convolution     MyriadXHwOp + injected[Copy] EXECUTED        121       \n",
      "Conv2D                                                       Convolution     Conv                      EXECUTED        1511      \n",
      "Conv2D                                                       Convolution     MyriadXHwOp + injected[BiasRelu] EXECUTED        215       \n",
      "Conv2D                                                       Convolution     MyriadXHwOp + injected[BiasRelu] EXECUTED        146       \n",
      "Conv2D                                                       Convolution     Conv                      EXECUTED        1853      \n",
      "myoutputnode                                                 SoftMax         SoftMax                   EXECUTED        58        \n",
      "AvgPool                                                      Pooling         MyriadXHwOp + injected[BiasRelu] EXECUTED        38        \n",
      "MaxPool                                                      Pooling         MaxPool                   EXECUTED        138       \n",
      "Conv2D                                                       Convolution     MyriadXHwOp               EXECUTED        17        \n",
      "transpose                                                    Permute         Permute                   EXECUTED        26        \n",
      "MaxPool                                                      Pooling         MaxPool                   EXECUTED        94        \n",
      "Conv2D                                                       Convolution     MyriadXHwOp + injected[Copy] EXECUTED        73        \n",
      "Conv2D                                                       Convolution     MyriadXHwOp               EXECUTED        18        \n",
      "Reshape                                                      Reshape         Reshape                   NOT_RUN         0         \n",
      "Conv2D                                                       Convolution     MyriadXHwOp + injected[BiasRelu] EXECUTED        282       \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "Conv2D                                                       Convolution     Copy                      EXECUTED        267       \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "Conv2D                                                       Convolution     MyriadXHwOp + injected[Copy] EXECUTED        18        \n",
      "Conv2D                                                       Convolution     MyriadXHwOp + injected[BiasRelu] EXECUTED        246       \n",
      "Relu                                                         ReLU            BiasRelu                  EXECUTED        61        \n",
      "Transpose                                                    Permute         Permute                   EXECUTED        13        \n",
      "concat                                                       Concat          Concat                    NOT_RUN         0         \n",
      "Conv2D                                                       Convolution     MyriadXHwOp               EXECUTED        15        \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "Conv2D                                                       Convolution     MyriadXHwOp + injected[Copy] EXECUTED        57        \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "Conv2D                                                       Convolution     MyriadXHwOp               EXECUTED        18        \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "AvgPool                                                      Pooling         MyriadXHwOp               EXECUTED        25        \n",
      "concat                                                       Concat          Concat                    NOT_RUN         0         \n",
      "concat                                                       Concat          Concat                    NOT_RUN         0         \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "Conv2D                                                       Convolution     MyriadXHwOp + injected[Copy] EXECUTED        101       \n",
      "Conv2D                                                       Convolution     Conv                      EXECUTED        2332      \n",
      "<Extra>                                                      <Extra>         Convert_f32f16            EXECUTED        94        \n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "from time import time\n",
    "import logging as log\n",
    "#reload(logging)\n",
    "from openvino.inference_engine import IENetwork, IECore\n",
    "log.basicConfig(format='%(asctime)s %(levelname)s:%(message)s', level=log.INFO,stream=sys.stdout)\n",
    "\n",
    "class ObjDict(dict):\n",
    "    \"\"\"Makes a dictionary behave like an object, with attribute-style access.\n",
    "    \"\"\"\n",
    "\n",
    "    def __getattr__(self, name):\n",
    "        try:\n",
    "            return self[name]\n",
    "        except KeyError:\n",
    "            raise AttributeError(name)\n",
    "\n",
    "    def __setattr__(self, name, value):\n",
    "        self[name] = value\n",
    "args=ObjDict()\n",
    "args.device=\"MYRIAD\"\n",
    "args.number_iter=1000\n",
    "args.perf_counts=True\n",
    "args.number_top=13\n",
    "args.labels=None\n",
    "\n",
    "\n",
    "if args.device in ['CPU']:\n",
    "    args.model=\"test_class/model_converted/model_fp16/model_fp16.xml\"\n",
    "elif args.device in ['MYRIAD']:\n",
    "    args.model=\"test_class/model_converted/model_fp16/model_fp16.xml\"\n",
    "else:\n",
    "    args.model=\"test_class/model_converted/model_fp32/model_fp32.xml\"\n",
    "    #args.model=\"/home/ubuntu/tf_models/test20190704/model_converted/model_fp16/model_fp16.xml\"\n",
    "    \n",
    "model_xml=args.model\n",
    "model_bin = os.path.splitext(model_xml)[0] + \".bin\"\n",
    "\n",
    "log.info(\"Creating Inference Engine\")\n",
    "ie = IECore()\n",
    "log.info(\"Loading network files:\\n\\t{}\\n\\t{}\".format(model_xml, model_bin))\n",
    "net = IENetwork(model=model_xml, weights=model_bin)\n",
    "\n",
    "log.info(\"Preparing input blobs\")\n",
    "input_blob = next(iter(net.inputs))\n",
    "out_blob = next(iter(net.outputs))\n",
    "n,c,h,w=net.inputs[input_blob].shape\n",
    "print(n,c,h,w)\n",
    "\n",
    "for i in range(n):\n",
    "    np.random.seed(5)\n",
    "    args.input=np.load('data2.npy')\n",
    "    images = args.input.transpose((0,3, 1, 2))  # Change data layout from HWC to CHW\n",
    "\n",
    "log.info(\"Batch size is {}\".format(n))\n",
    "# Loading model to the plugin\n",
    "log.info(\"Loading model to the plugin\")\n",
    "exec_net = ie.load_network(network=net, device_name=args.device)\n",
    "log.info(\"Starting inference in synchronous mode\")\n",
    "log.info(\"Starting inference ({} iterations)\".format(args.number_iter))\n",
    "infer_time = []\n",
    "for i in range(args.number_iter):\n",
    "    t0 = time()\n",
    "    res = exec_net.infer(inputs={input_blob: images})\n",
    "    infer_time.append((time() - t0) * 1000)\n",
    "\n",
    "\n",
    "log.info(\"Processing output blob\")\n",
    "res = res[out_blob]\n",
    "log.info(\"Top {} results: \".format(args.number_top))\n",
    "if args.labels:\n",
    "    with open(args.labels, 'r') as f:\n",
    "        labels_map = [x.split(sep=' ', maxsplit=1)[-1].strip() for x in f]\n",
    "else:\n",
    "    labels_map = None\n",
    "    \n",
    "classid_str = \"classid\"\n",
    "probability_str = \"probability\"\n",
    "for i, probs in enumerate(res):\n",
    "    probs = np.squeeze(probs)\n",
    "    top_ind = np.argsort(probs)[-args.number_top:][::-1]\n",
    "    #print(\"Image {}\\n\".format(args.input[i]))\n",
    "    print(classid_str, probability_str)\n",
    "    print(\"{} {}\".format('-' * len(classid_str), '-' * len(probability_str)))\n",
    "    for id in top_ind:\n",
    "        det_label = labels_map[id] if labels_map else \"{}\".format(id)\n",
    "        label_length = len(det_label)\n",
    "        space_num_before = (len(classid_str) - label_length) // 2\n",
    "        space_num_after = len(classid_str) - (space_num_before + label_length) + 2\n",
    "        space_num_before_prob = (len(probability_str) - len(str(probs[id]))) // 2\n",
    "        print(\"{}{}{}{}{:.7f}\".format(' ' * space_num_before, det_label,\n",
    "                                      ' ' * space_num_after, ' ' * space_num_before_prob,\n",
    "                                      probs[id]))    \n",
    "if args.perf_counts:\n",
    "    perf_counts = exec_net.requests[0].get_perf_counts()\n",
    "    log.info(\"Performance counters:\")\n",
    "    print(\"{:<60} {:<15} {:<25} {:<15} {:<10}\".format('name', 'layer_type', 'exet_type', 'status', 'real_time, us'))\n",
    "    for layer, stats in perf_counts.items():\n",
    "        layer = layer.split('/')[-1]\n",
    "        print(\"{:<60} {:<15} {:<25} {:<15} {:<10}\".format(layer, stats['layer_type'], stats['exec_type'],\n",
    "                                                          stats['status'], stats['real_time']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## model1 异步"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01-13 13:11:49,740 INFO:Creating Inference Engine\n",
      "2020-01-13 13:11:49,741 INFO:Loading network files:\n",
      "\ttest_class/model_converted/model_fp16/model_fp16.xml\n",
      "\ttest_class/model_converted/model_fp16/model_fp16.bin\n",
      "2020-01-13 13:11:49,749 INFO:Preparing input blobs\n",
      "1 1 3 1000\n",
      "2020-01-13 13:11:49,750 INFO:Batch size is 1\n",
      "2020-01-13 13:11:49,751 INFO:Loading model to the plugin\n",
      "2020-01-13 13:11:51,860 INFO:Start inference (10 Synchronous executions)\n",
      "2020-01-13 13:11:51,885 INFO:Completed 1 Sync request execution\n",
      "2020-01-13 13:11:51,910 INFO:Completed 2 Sync request execution\n",
      "2020-01-13 13:11:51,934 INFO:Completed 3 Sync request execution\n",
      "2020-01-13 13:11:51,959 INFO:Completed 4 Sync request execution\n",
      "2020-01-13 13:11:51,984 INFO:Completed 5 Sync request execution\n",
      "2020-01-13 13:11:52,008 INFO:Completed 6 Sync request execution\n",
      "2020-01-13 13:11:52,033 INFO:Completed 7 Sync request execution\n",
      "2020-01-13 13:11:52,058 INFO:Completed 8 Sync request execution\n",
      "2020-01-13 13:11:52,082 INFO:Completed 9 Sync request execution\n",
      "2020-01-13 13:11:52,107 INFO:Completed 10 Sync request execution\n",
      "2020-01-13 13:11:52,107 INFO:Average running time of one iteration: 24.408984184265137 ms\n",
      "2020-01-13 13:11:52,108 INFO:Performance 40.97 FPS\n",
      "2020-01-13 13:11:52,108 INFO:Processing output blob\n",
      "2020-01-13 13:11:52,109 INFO:Top 13 results: \n",
      "classid probability\n",
      "------- -----------\n",
      "   3      0.9428711\n",
      "  10     0.0159912\n",
      "   2     0.0113297\n",
      "   1     0.0066643\n",
      "   5     0.0064659\n",
      "   6     0.0064163\n",
      "   7     0.0050583\n",
      "   0     0.0040703\n",
      "   9     0.0006032\n",
      "   4     0.0002429\n",
      "  11     0.0001874\n",
      "   8     0.0001196\n",
      "2020-01-13 13:11:52,111 INFO:Performance counters:\n",
      "name                                                         layer_type      exet_type                 status          real_time, us\n",
      "Conv2D                                                       Convolution     MyriadXHwOp               EXECUTED        18        \n",
      "MaxPool                                                      Pooling         MaxPool                   EXECUTED        119       \n",
      "Reshape                                                      Reshape         Reshape                   NOT_RUN         0         \n",
      "Conv2D                                                       Convolution     Conv                      EXECUTED        654       \n",
      "Conv2D                                                       Convolution     MyriadXHwOp + injected[Copy] EXECUTED        18        \n",
      "<Extra>                                                      <Extra>         Convert_f32f16            EXECUTED        108       \n",
      "input_node                                                   Input           NONE                      NOT_RUN         0         \n",
      "Conv2D                                                       Convolution     Conv                      EXECUTED        2326      \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "concat                                                       Concat          Concat                    NOT_RUN         0         \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "Conv2D                                                       Convolution     MyriadXHwOp               EXECUTED        70        \n",
      "SpatialSqueeze_logits                                        Squeeze         Reshape                   NOT_RUN         0         \n",
      "MaxPool                                                      Pooling         MaxPool                   EXECUTED        107       \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "Conv2D                                                       Convolution     MyriadXHwOp + injected[BiasRelu] EXECUTED        246       \n",
      "AvgPool                                                      Pooling         MyriadXHwOp + injected[BiasRelu] EXECUTED        38        \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "concat                                                       Concat          Concat                    NOT_RUN         0         \n",
      "AvgPool                                                      Pooling         MyriadXHwOp               EXECUTED        28        \n",
      "concat                                                       Concat          Concat                    NOT_RUN         0         \n",
      "AvgPool                                                      Pooling         GlobalAvgPool             EXECUTED        76        \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "Conv2D                                                       Convolution     MyriadXHwOp               EXECUTED        17        \n",
      "Conv2D                                                       Convolution     Conv                      EXECUTED        1514      \n",
      "Transpose                                                    Permute         Permute                   EXECUTED        12        \n",
      "MaxPool                                                      Pooling         MaxPool                   EXECUTED        138       \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "Relu                                                         ReLU            BiasRelu                  EXECUTED        63        \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "MaxPool                                                      Pooling         MaxPool                   EXECUTED        94        \n",
      "AvgPool                                                      Pooling         MyriadXHwOp + injected[Copy] EXECUTED        33        \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "Conv2D                                                       Convolution     Conv                      EXECUTED        2175      \n",
      "Conv2D                                                       Convolution     MyriadXHwOp + injected[Copy] EXECUTED        73        \n",
      "MaxPool                                                      Pooling         MaxPool                   EXECUTED        147       \n",
      "MaxPool                                                      Pooling         MaxPool                   EXECUTED        164       \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "Conv2D                                                       Convolution     MyriadXHwOp + injected[BiasRelu] EXECUTED        252       \n",
      "Add                                                          ScaleShift      ScaleShift                EXECUTED        47        \n",
      "Conv2D                                                       Convolution     MyriadXHwOp + injected[BiasRelu] EXECUTED        237       \n",
      "myoutputnode                                                 SoftMax         SoftMax                   EXECUTED        57        \n",
      "Conv2D                                                       Convolution     MyriadXHwOp + injected[Copy] EXECUTED        66        \n",
      "Conv2D                                                       Convolution     MyriadXHwOp               EXECUTED        112       \n",
      "Conv2D                                                       Convolution     Conv                      EXECUTED        2240      \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "concat                                                       Concat          Concat                    NOT_RUN         0         \n",
      "Conv2D                                                       Convolution     MyriadXHwOp + injected[Copy] EXECUTED        98        \n",
      "concat                                                       Concat          Concat                    NOT_RUN         0         \n",
      "Conv2D                                                       Convolution     Conv                      EXECUTED        1846      \n",
      "Conv2D                                                       Convolution     MyriadXHwOp + injected[BiasRelu] EXECUTED        278       \n",
      "Conv2D                                                       Convolution     MyriadXHwOp + injected[BiasRelu] EXECUTED        73        \n",
      "Conv2D                                                       Convolution     MyriadXHwOp               EXECUTED        21        \n",
      "Conv2D                                                       Convolution     MyriadXHwOp               EXECUTED        21        \n",
      "Conv2D                                                       Convolution     MyriadXHwOp + injected[Copy] EXECUTED        99        \n",
      "concat                                                       Concat          Concat                    NOT_RUN         0         \n",
      "Conv2D                                                       Convolution     MyriadXHwOp + injected[BiasRelu] EXECUTED        217       \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "concat                                                       Concat          Concat                    NOT_RUN         0         \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "AvgPool                                                      Pooling         MyriadXHwOp               EXECUTED        35        \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "MatMul                                                       FullyConnected  MyriadXHwOp               EXECUTED        24        \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "AvgPool                                                      Pooling         MyriadXHwOp + injected[Copy] EXECUTED        17        \n",
      "Conv2D                                                       Convolution     MyriadXHwOp + injected[Copy] EXECUTED        72        \n",
      "concat                                                       Concat          Concat                    NOT_RUN         0         \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "Conv2D                                                       Convolution     MyriadXHwOp + injected[BiasRelu] EXECUTED        146       \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "Conv2D                                                       Convolution     MyriadXHwOp               EXECUTED        18        \n",
      "Conv2D                                                       Convolution     Conv                      EXECUTED        2680      \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "Conv2D                                                       Convolution     Copy                      EXECUTED        267       \n",
      "Conv2D                                                       Convolution     Conv                      EXECUTED        2275      \n",
      "Transpose                                                    Permute         Permute                   EXECUTED        13        \n",
      "AvgPool                                                      Pooling         MyriadXHwOp + injected[Copy] EXECUTED        23        \n",
      "Conv2D                                                       Convolution     MyriadXHwOp + injected[Copy] EXECUTED        101       \n",
      "Tensordot                                                    Reshape         Reshape                   NOT_RUN         0         \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "AvgPool                                                      Pooling         MyriadXHwOp               EXECUTED        25        \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "Conv2D                                                       Convolution     MyriadXHwOp + injected[Copy] EXECUTED        57        \n",
      "transpose                                                    Permute         Permute                   EXECUTED        26        \n",
      "Conv2D                                                       Convolution     Conv                      EXECUTED        2134      \n",
      "AvgPool                                                      Pooling         MyriadXHwOp               EXECUTED        24        \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "Conv2D                                                       Convolution     MyriadXHwOp               EXECUTED        18        \n",
      "Conv2D                                                       Convolution     MyriadXHwOp + injected[Copy] EXECUTED        124       \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "Conv2D                                                       Convolution     MyriadXHwOp               EXECUTED        15        \n",
      "Conv2D                                                       Convolution     MyriadXHwOp               EXECUTED        105       \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n",
      "Relu                                                         ReLU            <none>                    OPTIMIZED_OUT   0         \n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import logging as log\n",
    "from time import time\n",
    "from openvino.inference_engine import IENetwork, IECore\n",
    "import threading\n",
    "\n",
    "log.basicConfig(format='%(asctime)s %(levelname)s:%(message)s', level=log.INFO,stream=sys.stdout)\n",
    "class InferReqWrap:\n",
    "    def __init__(self, request, id, num_iter):\n",
    "        self.id = id\n",
    "        self.request = request\n",
    "        self.num_iter = num_iter\n",
    "        self.cur_iter = 0\n",
    "        self.cv = threading.Condition()\n",
    "        self.request.set_completion_callback(self.callback, self.id)\n",
    "\n",
    "    def callback(self, statusCode, userdata):\n",
    "        if (userdata != self.id):\n",
    "            log.error(\"Request ID {} does not correspond to user data {}\".format(self.id, userdata))\n",
    "        elif statusCode != 0:\n",
    "            log.error(\"Request {} failed with status code {}\".format(self.id, statusCode))\n",
    "        self.cur_iter += 1\n",
    "        log.info(\"Completed {} Async request execution\".format(self.cur_iter))\n",
    "        if self.cur_iter < self.num_iter:\n",
    "            # here a user can read output containing inference results and put new input\n",
    "            # to repeat async request again\n",
    "            self.request.async_infer(self.input)\n",
    "        else:\n",
    "            # continue sample execution after last Asynchronous inference request execution\n",
    "            self.cv.acquire()\n",
    "            self.cv.notify()\n",
    "            self.cv.release()\n",
    "\n",
    "    def execute(self, mode, input_data):\n",
    "        if (mode == \"async\"):\n",
    "            log.info(\"Start inference ({} Asynchronous executions)\".format(self.num_iter))\n",
    "            self.input = input_data\n",
    "            # Start async request for the first time. Wait all repetitions of the async request\n",
    "            self.request.async_infer(input_data)\n",
    "            self.cv.acquire()\n",
    "            self.cv.wait()\n",
    "            self.cv.release()\n",
    "        elif (mode == \"sync\"):\n",
    "            infer_time = []  \n",
    "    \n",
    "            log.info(\"Start inference ({} Synchronous executions)\".format(self.num_iter))\n",
    "            for self.cur_iter in range(self.num_iter):\n",
    "                t0 = time()\n",
    "                # here we start inference synchronously and wait for\n",
    "                # last inference request execution\n",
    "                self.request.infer(input_data)\n",
    "                infer_time.append((time() - t0) * 1000)\n",
    "                log.info(\"Completed {} Sync request execution\".format(self.cur_iter + 1))\n",
    "            return infer_time\n",
    "        else:\n",
    "            log.error(\"wrong inference mode is chosen. Please use \\\"sync\\\" or \\\"async\\\" mode\")\n",
    "            sys.exit(1)\n",
    "\n",
    "class ObjDict(dict):\n",
    "    \"\"\"Makes a dictionary behave like an object, with attribute-style access.\n",
    "    \"\"\"\n",
    "\n",
    "    def __getattr__(self, name):\n",
    "        try:\n",
    "            return self[name]\n",
    "        except KeyError:\n",
    "            raise AttributeError(name)\n",
    "\n",
    "    def __setattr__(self, name, value):\n",
    "        self[name] = value\n",
    "args=ObjDict()\n",
    "args.device=\"MYRIAD\"\n",
    "args.number_iter=10\n",
    "args.perf_counts=True\n",
    "args.number_top=13\n",
    "args.labels=None\n",
    "\n",
    "\n",
    "if args.device in ['CPU']:\n",
    "    args.model=\"test_class/model_converted/model_fp16/model_fp16.xml\"\n",
    "elif args.device in ['MYRIAD']:\n",
    "    args.model=\"test_class/model_converted/model_fp16/model_fp16.xml\"\n",
    "else:\n",
    "    args.model=\"test_class/model_converted/model_fp32/model_fp32.xml\"\n",
    "    #args.model=\"/home/ubuntu/tf_models/test20190704/model_converted/model_fp16/model_fp16.xml\"\n",
    "    \n",
    "model_xml=args.model\n",
    "model_bin = os.path.splitext(model_xml)[0] + \".bin\"\n",
    "\n",
    "log.info(\"Creating Inference Engine\")\n",
    "ie = IECore()\n",
    "log.info(\"Loading network files:\\n\\t{}\\n\\t{}\".format(model_xml, model_bin))\n",
    "net = IENetwork(model=model_xml, weights=model_bin)\n",
    "\n",
    "log.info(\"Preparing input blobs\")\n",
    "input_blob = next(iter(net.inputs))\n",
    "out_blob = next(iter(net.outputs))\n",
    "n,c,h,w=net.inputs[input_blob].shape\n",
    "print(n,c,h,w)\n",
    "\n",
    "for i in range(n):\n",
    "    np.random.seed(5)\n",
    "    args.input=np.load('data2.npy')\n",
    "    images = args.input.transpose((0,3, 1, 2))  # Change data layout from HWC to CHW\n",
    "\n",
    "log.info(\"Batch size is {}\".format(n))\n",
    "# Loading model to the plugin\n",
    "log.info(\"Loading model to the plugin\")\n",
    "exec_net = ie.load_network(network=net, device_name=args.device)\n",
    "\n",
    "\n",
    "# create one inference request for asynchronous execution\n",
    "request_id = 0\n",
    "infer_request = exec_net.requests[request_id];\n",
    "\n",
    "\n",
    "request_wrap = InferReqWrap(infer_request, request_id, args.number_iter)\n",
    "# Start inference request execution. Wait for last execution being completed\n",
    "infer_time=request_wrap.execute(\"sync\", {input_blob: images})\n",
    "\n",
    "log.info(\"Average running time of one iteration: {} ms\".format(np.average(np.asarray(infer_time))))\n",
    "log.info(\"Performance {:.2f} FPS\".format((1000/np.average(np.asarray(infer_time)))))\n",
    "\n",
    "\n",
    "log.info(\"Processing output blob\")\n",
    "\n",
    "res = infer_request.outputs[out_blob]\n",
    "log.info(\"Top {} results: \".format(args.number_top))\n",
    "if args.labels:\n",
    "    with open(args.labels, 'r') as f:\n",
    "        labels_map = [x.split(sep=' ', maxsplit=1)[-1].strip() for x in f]\n",
    "else:\n",
    "    labels_map = None\n",
    "    \n",
    "classid_str = \"classid\"\n",
    "probability_str = \"probability\"\n",
    "for i, probs in enumerate(res):\n",
    "    probs = np.squeeze(probs)\n",
    "    top_ind = np.argsort(probs)[-args.number_top:][::-1]\n",
    "    #print(\"Image {}\\n\".format(args.input[i]))\n",
    "    print(classid_str, probability_str)\n",
    "    print(\"{} {}\".format('-' * len(classid_str), '-' * len(probability_str)))\n",
    "    for id in top_ind:\n",
    "        det_label = labels_map[id] if labels_map else \"{}\".format(id)\n",
    "        label_length = len(det_label)\n",
    "        space_num_before = (len(classid_str) - label_length) // 2\n",
    "        space_num_after = len(classid_str) - (space_num_before + label_length) + 2\n",
    "        space_num_before_prob = (len(probability_str) - len(str(probs[id]))) // 2\n",
    "        print(\"{}{}{}{}{:.7f}\".format(' ' * space_num_before, det_label,\n",
    "                                      ' ' * space_num_after, ' ' * space_num_before_prob,\n",
    "                                      probs[id]))    \n",
    "if args.perf_counts:\n",
    "    perf_counts = exec_net.requests[0].get_perf_counts()\n",
    "    log.info(\"Performance counters:\")\n",
    "    print(\"{:<60} {:<15} {:<25} {:<15} {:<10}\".format('name', 'layer_type', 'exet_type', 'status', 'real_time, us'))\n",
    "    for layer, stats in perf_counts.items():\n",
    "        layer = layer.split('/')[-1]\n",
    "        print(\"{:<60} {:<15} {:<25} {:<15} {:<10}\".format(layer, stats['layer_type'], stats['exec_type'],\n",
    "                                                          stats['status'], stats['real_time']))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pdb\n",
    "import numpy as np\n",
    "import logging as log\n",
    "import time\n",
    "from datetime import datetime\n",
    "from openvino.inference_engine import IENetwork, IECore\n",
    "import threading\n",
    "\n",
    "log.basicConfig(format='%(asctime)s %(levelname)s:%(message)s', level=log.INFO,stream=sys.stdout)\n",
    "\n",
    "class InferReqWrap:\n",
    "    def __init__(self, request, id, callbackQueue):\n",
    "        self.id = id\n",
    "        self.request = request\n",
    "        self.request.set_completion_callback(self.callback, self.id)\n",
    "        self.callbackQueue = callbackQueue\n",
    "\n",
    "    def callback(self, statusCode, userdata):\n",
    "        if (userdata != self.id):\n",
    "            print(\"Request ID {} does not correspond to user data {}\".format(self.id, userdata))\n",
    "        elif statusCode != 0:\n",
    "            print(\"Request {} failed with status code {}\".format(self.id, statusCode))\n",
    "        self.callbackQueue(self.id, self.request.latency)\n",
    "\n",
    "    def startAsync(self, input_data):\n",
    "        self.request.async_infer(input_data)\n",
    "\n",
    "    def infer(self, input_data):\n",
    "        self.request.infer(input_data)\n",
    "        self.callbackQueue(self.id, self.request.latency);\n",
    "class InferRequestsQueue:\n",
    "    def __init__(self, requests):\n",
    "        self.idleIds = []\n",
    "        self.requests = []\n",
    "        self.times = []\n",
    "        for id in range(0, len(requests)):\n",
    "            self.requests.append(InferReqWrap(requests[id], id, self.putIdleRequest))\n",
    "            self.idleIds.append(id)\n",
    "        self.startTime = datetime.max\n",
    "        self.endTime = datetime.min\n",
    "        self.cv = threading.Condition()\n",
    "\n",
    "    def resetTimes(self):\n",
    "        self.times.clear()\n",
    "\n",
    "    def getDurationInSeconds(self):\n",
    "        return (self.endTime - self.startTime).total_seconds()\n",
    "\n",
    "    def putIdleRequest(self, id, latency):\n",
    "        self.cv.acquire()\n",
    "        self.times.append(latency)\n",
    "        self.idleIds.append(id)\n",
    "        self.endTime = max(self.endTime, datetime.now())\n",
    "        self.cv.notify()\n",
    "        self.cv.release()\n",
    "\n",
    "    def getIdleRequest(self):\n",
    "        self.cv.acquire()\n",
    "        while len(self.idleIds) == 0:\n",
    "            self.cv.wait()\n",
    "        id = self.idleIds.pop();\n",
    "        self.startTime = min(datetime.now(), self.startTime);\n",
    "        self.cv.release()\n",
    "        return self.requests[id]\n",
    "\n",
    "    def waitAll(self):\n",
    "        self.cv.acquire()\n",
    "        while len(self.idleIds) != len(self.requests):\n",
    "            self.cv.wait()\n",
    "        self.cv.release()\n",
    "def parseValuePerDevice(devices, values_string):\n",
    "    ## Format: <device1>:<value1>,<device2>:<value2> or just <value>\n",
    "    result = {}\n",
    "    if not values_string:\n",
    "        return result\n",
    "    device_value_strings = values_string.upper().split(',')\n",
    "    for device_value_string in device_value_strings:\n",
    "        device_value_vec = device_value_string.split(':')\n",
    "        if len(device_value_vec) == 2:\n",
    "            for device in devices:\n",
    "                if device == device_value_vec[0]:\n",
    "                    value = int(device_value_vec[1])\n",
    "                    result[device_value_vec[0]] = value\n",
    "                    break\n",
    "        elif len(device_value_vec) == 1:\n",
    "            value = int(device_value_vec[0])\n",
    "            for device in devices:\n",
    "                result[device] = value\n",
    "        elif not device_value_vec:\n",
    "            raise Exception(\"Unknown string format: \" + values_string)\n",
    "    return result\n",
    "def parseDevices(device_string):\n",
    "    devices = device_string\n",
    "    if ':' in devices:\n",
    "        devices = devices.partition(':')[2]\n",
    "    return [ d[:d.index('(')] if '(' in d else d for d in devices.split(',') ]\n",
    "def str2bool(v):\n",
    "    if v.lower() in ('yes', 'true', 't', 'y', '1'):\n",
    "        return True\n",
    "    elif v.lower() in ('no', 'false', 'f', 'n', '0'):\n",
    "        return False\n",
    "    else:\n",
    "        raise argparse.ArgumentTypeError('Boolean value expected.')\n",
    "class ObjDict(dict):\n",
    "    \"\"\"Makes a dictionary behave like an object, with attribute-style access.\n",
    "    \"\"\"\n",
    "\n",
    "    def __getattr__(self, name):\n",
    "        try:\n",
    "            return self[name]\n",
    "        except KeyError:\n",
    "            raise AttributeError(name)\n",
    "\n",
    "    def __setattr__(self, name, value):\n",
    "        self[name] = value\n",
    "def test(nir=1,api_type='async'):\n",
    "    args=ObjDict()\n",
    "    args.device=\"MYRIAD\"\n",
    "    args.number_streams=None\n",
    "    args.number_iter=10\n",
    "    args.perf_counts=True\n",
    "    args.number_infer_requests=nir\n",
    "    args.number_top=13\n",
    "    args.api_type=api_type\n",
    "    args.labels=None\n",
    "    args.cpu_extension=None\n",
    "\n",
    "\n",
    "    if args.device in ['CPU']:\n",
    "        args.model=\"test_class/model_converted/model_fp16/model_fp16.xml\"\n",
    "    elif args.device in ['MYRIAD']:\n",
    "        args.model=\"test_class/model_converted/model_fp16/model_fp16.xml\"\n",
    "    else:\n",
    "        args.model=\"test_class/model_converted/model_fp32/model_fp32.xml\"\n",
    "        #args.model=\"/home/ubuntu/tf_models/test20190704/model_converted/model_fp16/model_fp16.xml\"\n",
    "\n",
    "    model_xml = args.model\n",
    "    model_bin = os.path.splitext(model_xml)[0] + \".bin\"\n",
    "    # Plugin initialization for specified device and load extensions library if specified\n",
    "    log.info(\"Initializing plugin for {} device...\".format(args.device))\n",
    "    device_nstreams = parseValuePerDevice(args.device, args.number_streams)\n",
    "    ie = IECore()\n",
    "    if args.cpu_extension and 'CPU' in args.device:\n",
    "        ie.add_extension(args.cpu_extension, \"CPU\")\n",
    "    #    plugin = IEPlugin(device=args.device, plugin_dirs=args.plugin_dir)\n",
    "\n",
    "    # Read IR\n",
    "    log.info(\"Reading IR...\")\n",
    "    net = IENetwork(model=model_xml, weights=model_bin)\n",
    "\n",
    "    if \"CPU\" in args.device:\n",
    "        ie.set_config({'CPU_THROUGHPUT_STREAMS': str(device_nstreams.get(args.device))\n",
    "                                                         if args.device in device_nstreams.keys()\n",
    "                                                         else 'CPU_THROUGHPUT_AUTO' }, args.device)\n",
    "        device_nstreams[args.device] = int(ie.get_config(args.device, 'CPU_THROUGHPUT_STREAMS'))\n",
    "        ie.add_extension(args.cpu_extension, \"CPU\")\n",
    "        supported_layers = ie.query_network(net, \"CPU\")\n",
    "        not_supported_layers = [l for l in net.layers.keys() if l not in supported_layers]\n",
    "        if len(not_supported_layers) != 0:\n",
    "            log.error(\"Following layers are not supported by the plugin for specified device {}:\\n {}\".\n",
    "                      format(args.device, ', '.join(not_supported_layers)))\n",
    "            log.error(\"Please try to specify cpu extensions library path in sample's command line parameters using -l \"\n",
    "                      \"or --cpu_extension command line argument\")\n",
    "            sys.exit(1)\n",
    "    # elif \"MYRIAD\" in args.device:\n",
    "    #     ie.set_config({'LOG_LEVEL': 'LOG_INFO',\n",
    "    #                        'VPU_LOG_LEVEL': 'LOG_WARNING'}, MYRIAD_DEVICE_NAME)\n",
    "\n",
    "    input_blob = next(iter(net.inputs))\n",
    "    out_blob = next(iter(net.outputs))\n",
    "    #netoutput = iter(net.outputs)\n",
    "    #out_blob_loc = next(netoutput)\n",
    "    #out_blob_class = next(netoutput)\n",
    "    log.info(\"Loading IR to the plugin...\")\n",
    "    #    exec_net = plugin.load(network=net, num_requests=2)\n",
    "    config = { 'PERF_COUNT' : ('YES' if args.perf_counts else 'NO')}\n",
    "\n",
    "    exe_network = ie.load_network(net,\n",
    "                                      args.device,\n",
    "                                      config=config,\n",
    "                                      num_requests=args.number_infer_requests if args.number_infer_requests else 0)\n",
    "    # exec_net = ie.load_network(network=net, device_name=args.device)\n",
    "    # Read and pre-process input image\n",
    "    n, c, h, w = net.inputs[input_blob].shape\n",
    "    del net\n",
    "\n",
    "    if args.api_type == 'async':\n",
    "        is_async_mode = True\n",
    "    else:\n",
    "        is_async_mode = False\n",
    "\n",
    "    #images = np.zeros((n,c,h,w), dtype = np.float32)\n",
    "    #for i in range(n):\n",
    "    #    print(args.input[i])\n",
    "\n",
    "        #image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        #if image.shape[:-1] != (h, w):\n",
    "        #    log.warning(\"Image {} is resized from {} to {}\".format(args.input[i], image.shape[:-1], (h, w)))\n",
    "        #    image = cv2.resize(image, (w, h))\n",
    "\n",
    "    log.info(\"Batch size is {}\".format(n))\n",
    "\n",
    "    #frame = cv2.imread(input_stream)\n",
    "    #frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    #Img = np.zeros((1,1,448,448), dtype = np.float32)\n",
    "    #Img[0,0,:,:] = frame\n",
    "\n",
    "    # create one inference request for asynchronous execution\n",
    "    # create one inference request for asynchronous execution\n",
    "    infer_requests = exe_network.requests\n",
    "    nireq = len(infer_requests)\n",
    "    print(\"number of infer request: \", nireq)\n",
    "\n",
    "    images = np.zeros((nireq,n,c,h,w), dtype = np.float32)\n",
    "    for i in range(nireq):\n",
    "    #     args.input=np.load('data2.npy')\n",
    "    #     image = args.input.transpose((0,3, 1, 2))\n",
    "        image = np.random.rand(1,1,3,1000)\n",
    "        images[i] = image\n",
    "\n",
    "    request_queue = InferRequestsQueue(infer_requests)\n",
    "\n",
    "    inf_start = time.time()\n",
    "    iteration = 0\n",
    "\n",
    "    while ((nireq and iteration < nireq) or\n",
    "               (args.api_type == \"async\" and iteration % nireq != 0)):\n",
    "        infer_request = request_queue.getIdleRequest()\n",
    "        if not infer_request:\n",
    "            raise Exception(\"No idle Infer Requests!\")\n",
    "\n",
    "        if (args.api_type == 'sync'):\n",
    "            infer_request.infer({input_blob: image})\n",
    "        else:\n",
    "            infer_request.startAsync({input_blob: images[i]})\n",
    "            print(\"flag\")\n",
    "        iteration += 1\n",
    "\n",
    "        #exec_time = (datetime.now() - start_time).total_seconds()\n",
    "\n",
    "\n",
    "        ## wait the latest inference executions\n",
    "    request_queue.waitAll()\n",
    "    print(iteration)\n",
    "    inf_end = time.time()\n",
    "    det_time = inf_end - inf_start\n",
    "#     print(\"[Performance] inference time:{} ms\".format(det_time*1000))\n",
    "    return det_time*1000\n",
    "\n",
    "        \n",
    "            \n",
    "# for infer_request in infer_requests:\n",
    "#     log.info(\"Processing output blob\")\n",
    "\n",
    "#     res = infer_request.outputs[out_blob]\n",
    "#     log.info(\"Top {} results: \".format(args.number_top))\n",
    "#     if args.labels:\n",
    "#         with open(args.labels, 'r') as f:\n",
    "#             labels_map = [x.split(sep=' ', maxsplit=1)[-1].strip() for x in f]\n",
    "#     else:\n",
    "#         labels_map = None\n",
    "\n",
    "#     classid_str = \"classid\"\n",
    "#     probability_str = \"probability\"\n",
    "#     for i, probs in enumerate(res):\n",
    "#         probs = np.squeeze(probs)\n",
    "#         top_ind = np.argsort(probs)[-args.number_top:][::-1]\n",
    "#         #print(\"Image {}\\n\".format(args.input[i]))\n",
    "#         print(classid_str, probability_str)\n",
    "#         print(\"{} {}\".format('-' * len(classid_str), '-' * len(probability_str)))\n",
    "#         for id in top_ind:\n",
    "#             det_label = labels_map[id] if labels_map else \"{}\".format(id)\n",
    "#             label_length = len(det_label)\n",
    "#             space_num_before = (len(classid_str) - label_length) // 2\n",
    "#             space_num_after = len(classid_str) - (space_num_before + label_length) + 2\n",
    "#             space_num_before_prob = (len(probability_str) - len(str(probs[id]))) // 2\n",
    "#             print(\"{}{}{}{}{:.7f}\".format(' ' * space_num_before, det_label,\n",
    "#                                           ' ' * space_num_after, ' ' * space_num_before_prob,\n",
    "#                                           probs[id]))    \n",
    "# if args.perf_counts:\n",
    "#         for ni in range(int(args.number_infer_requests)):\n",
    "#             perf_counts = exe_network.requests[ni].get_perf_counts()\n",
    "#             log.info(\"Pefrormance counts for {}-th infer request\".format(ni))\n",
    "#             for layer, stats in perf_counts.items():\n",
    "#                 max_layer_name = 30\n",
    "#                 print(\"{:<30}{:<15}{:<30}{:<20}{:<20}{:<20}\".format(layer[:max_layer_name - 4] + '...' if (len(layer) >= max_layer_name) else layer,\n",
    "#                                                                         stats['status'],\n",
    "#                                                                         'layerType: ' + str(stats['layer_type']),\n",
    "#                                                                         'realTime: ' + str(stats['real_time']),\n",
    "#                                                                         'cpu: ' + str(stats['cpu_time']),\n",
    "#                                                                         'execType: ' + str(stats['exec_type'])))\n",
    "\n",
    "\n",
    "def test1(nir=1,api_type='async'):\n",
    "    args=ObjDict()\n",
    "    args.device=\"MYRIAD\"\n",
    "    args.number_streams=None\n",
    "    args.number_iter=10\n",
    "    args.perf_counts=True\n",
    "    args.number_infer_requests=nir\n",
    "    args.number_top=13\n",
    "    args.api_type=api_type\n",
    "    args.labels=None\n",
    "    args.cpu_extension=None\n",
    "\n",
    "\n",
    "    if args.device in ['CPU']:\n",
    "        args.model=\"test/model_converted/model_fp16/model_fp16.xml\"\n",
    "    elif args.device in ['MYRIAD']:\n",
    "        args.model=\"test/model_converted/model_fp16/model_fp16.xml\"\n",
    "    else:\n",
    "        args.model=\"test/model_converted/model_fp32/model_fp32.xml\"\n",
    "        #args.model=\"/home/ubuntu/tf_models/test20190704/model_converted/model_fp16/model_fp16.xml\"\n",
    "\n",
    "    model_xml = args.model\n",
    "    model_bin = os.path.splitext(model_xml)[0] + \".bin\"\n",
    "    # Plugin initialization for specified device and load extensions library if specified\n",
    "    log.info(\"Initializing plugin for {} device...\".format(args.device))\n",
    "    device_nstreams = parseValuePerDevice(args.device, args.number_streams)\n",
    "    ie = IECore()\n",
    "    if args.cpu_extension and 'CPU' in args.device:\n",
    "        ie.add_extension(args.cpu_extension, \"CPU\")\n",
    "    #    plugin = IEPlugin(device=args.device, plugin_dirs=args.plugin_dir)\n",
    "\n",
    "    # Read IR\n",
    "    log.info(\"Reading IR...\")\n",
    "    net = IENetwork(model=model_xml, weights=model_bin)\n",
    "\n",
    "    if \"CPU\" in args.device:\n",
    "        ie.set_config({'CPU_THROUGHPUT_STREAMS': str(device_nstreams.get(args.device))\n",
    "                                                         if args.device in device_nstreams.keys()\n",
    "                                                         else 'CPU_THROUGHPUT_AUTO' }, args.device)\n",
    "        device_nstreams[args.device] = int(ie.get_config(args.device, 'CPU_THROUGHPUT_STREAMS'))\n",
    "        ie.add_extension(args.cpu_extension, \"CPU\")\n",
    "        supported_layers = ie.query_network(net, \"CPU\")\n",
    "        not_supported_layers = [l for l in net.layers.keys() if l not in supported_layers]\n",
    "        if len(not_supported_layers) != 0:\n",
    "            log.error(\"Following layers are not supported by the plugin for specified device {}:\\n {}\".\n",
    "                      format(args.device, ', '.join(not_supported_layers)))\n",
    "            log.error(\"Please try to specify cpu extensions library path in sample's command line parameters using -l \"\n",
    "                      \"or --cpu_extension command line argument\")\n",
    "            sys.exit(1)\n",
    "    # elif \"MYRIAD\" in args.device:\n",
    "    #     ie.set_config({'LOG_LEVEL': 'LOG_INFO',\n",
    "    #                        'VPU_LOG_LEVEL': 'LOG_WARNING'}, MYRIAD_DEVICE_NAME)\n",
    "\n",
    "    input_blob = next(iter(net.inputs))\n",
    "    out_blob = next(iter(net.outputs))\n",
    "    #netoutput = iter(net.outputs)\n",
    "    #out_blob_loc = next(netoutput)\n",
    "    #out_blob_class = next(netoutput)\n",
    "    log.info(\"Loading IR to the plugin...\")\n",
    "    #    exec_net = plugin.load(network=net, num_requests=2)\n",
    "    config = { 'PERF_COUNT' : ('YES' if args.perf_counts else 'NO')}\n",
    "\n",
    "    exe_network = ie.load_network(net,\n",
    "                                      args.device,\n",
    "                                      config=config,\n",
    "                                      num_requests=args.number_infer_requests if args.number_infer_requests else 0)\n",
    "    # exec_net = ie.load_network(network=net, device_name=args.device)\n",
    "    # Read and pre-process input image\n",
    "    n, c, h, w = net.inputs[input_blob].shape\n",
    "    del net\n",
    "\n",
    "    if args.api_type == 'async':\n",
    "        is_async_mode = True\n",
    "    else:\n",
    "        is_async_mode = False\n",
    "\n",
    "    #images = np.zeros((n,c,h,w), dtype = np.float32)\n",
    "    #for i in range(n):\n",
    "    #    print(args.input[i])\n",
    "\n",
    "        #image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        #if image.shape[:-1] != (h, w):\n",
    "        #    log.warning(\"Image {} is resized from {} to {}\".format(args.input[i], image.shape[:-1], (h, w)))\n",
    "        #    image = cv2.resize(image, (w, h))\n",
    "\n",
    "    log.info(\"Batch size is {}\".format(n))\n",
    "\n",
    "    #frame = cv2.imread(input_stream)\n",
    "    #frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    #Img = np.zeros((1,1,448,448), dtype = np.float32)\n",
    "    #Img[0,0,:,:] = frame\n",
    "\n",
    "    # create one inference request for asynchronous execution\n",
    "    # create one inference request for asynchronous execution\n",
    "    infer_requests = exe_network.requests\n",
    "    nireq = len(infer_requests)\n",
    "    print(\"number of infer request: \", nireq)\n",
    "\n",
    "    images = np.zeros((nireq,n,c,h,w), dtype = np.float32)\n",
    "    for i in range(nireq):\n",
    "    #     args.input=np.load('data2.npy')\n",
    "    #     image = args.input.transpose((0,3, 1, 2))\n",
    "        image = np.random.rand(1,1,1,500)\n",
    "        images[i] = image\n",
    "\n",
    "    request_queue = InferRequestsQueue(infer_requests)\n",
    "\n",
    "    inf_start = time.time()\n",
    "    iteration = 0\n",
    "\n",
    "    while ((nireq and iteration < nireq) or\n",
    "               (args.api_type == \"async\" and iteration % nireq != 0)):\n",
    "        infer_request = request_queue.getIdleRequest()\n",
    "        if not infer_request:\n",
    "            raise Exception(\"No idle Infer Requests!\")\n",
    "\n",
    "        if (args.api_type == 'sync'):\n",
    "            infer_request.infer({input_blob: image})\n",
    "        else:\n",
    "            infer_request.startAsync({input_blob: images[i]})\n",
    "            print(\"flag\")\n",
    "        iteration += 1\n",
    "\n",
    "        #exec_time = (datetime.now() - start_time).total_seconds()\n",
    "\n",
    "\n",
    "        ## wait the latest inference executions\n",
    "    request_queue.waitAll()\n",
    "    print(iteration)\n",
    "    inf_end = time.time()\n",
    "    det_time = inf_end - inf_start\n",
    "#     print(\"[Performance] inference time:{} ms\".format(det_time*1000))\n",
    "    return det_time*1000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01-13 14:49:59,479 INFO:Initializing plugin for MYRIAD device...\n",
      "2020-01-13 14:49:59,481 INFO:Reading IR...\n",
      "2020-01-13 14:49:59,487 INFO:Loading IR to the plugin...\n",
      "2020-01-13 14:50:01,607 INFO:Batch size is 1\n",
      "number of infer request:  1\n",
      "flag\n",
      "1\n",
      "2020-01-13 14:50:02,041 INFO:Initializing plugin for MYRIAD device...\n",
      "2020-01-13 14:50:02,043 INFO:Reading IR...\n",
      "2020-01-13 14:50:02,048 INFO:Loading IR to the plugin...\n",
      "2020-01-13 14:50:04,436 INFO:Batch size is 1\n",
      "number of infer request:  2\n",
      "flag\n",
      "flag\n",
      "2\n",
      "2020-01-13 14:50:04,878 INFO:Initializing plugin for MYRIAD device...\n",
      "2020-01-13 14:50:04,880 INFO:Reading IR...\n",
      "2020-01-13 14:50:04,886 INFO:Loading IR to the plugin...\n",
      "2020-01-13 14:50:07,273 INFO:Batch size is 1\n",
      "number of infer request:  3\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "3\n",
      "2020-01-13 14:50:07,734 INFO:Initializing plugin for MYRIAD device...\n",
      "2020-01-13 14:50:07,735 INFO:Reading IR...\n",
      "2020-01-13 14:50:07,740 INFO:Loading IR to the plugin...\n",
      "2020-01-13 14:50:10,123 INFO:Batch size is 1\n",
      "number of infer request:  4\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "4\n",
      "2020-01-13 14:50:10,589 INFO:Initializing plugin for MYRIAD device...\n",
      "2020-01-13 14:50:10,591 INFO:Reading IR...\n",
      "2020-01-13 14:50:10,596 INFO:Loading IR to the plugin...\n",
      "2020-01-13 14:50:12,985 INFO:Batch size is 1\n",
      "number of infer request:  5\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "5\n",
      "2020-01-13 14:50:13,474 INFO:Initializing plugin for MYRIAD device...\n",
      "2020-01-13 14:50:13,476 INFO:Reading IR...\n",
      "2020-01-13 14:50:13,480 INFO:Loading IR to the plugin...\n",
      "2020-01-13 14:50:15,868 INFO:Batch size is 1\n",
      "number of infer request:  6\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "6\n",
      "2020-01-13 14:50:16,358 INFO:Initializing plugin for MYRIAD device...\n",
      "2020-01-13 14:50:16,360 INFO:Reading IR...\n",
      "2020-01-13 14:50:16,367 INFO:Loading IR to the plugin...\n",
      "2020-01-13 14:50:18,749 INFO:Batch size is 1\n",
      "number of infer request:  7\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "7\n",
      "2020-01-13 14:50:19,261 INFO:Initializing plugin for MYRIAD device...\n",
      "2020-01-13 14:50:19,264 INFO:Reading IR...\n",
      "2020-01-13 14:50:19,268 INFO:Loading IR to the plugin...\n",
      "2020-01-13 14:50:21,650 INFO:Batch size is 1\n",
      "number of infer request:  8\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "8\n",
      "2020-01-13 14:50:22,166 INFO:Initializing plugin for MYRIAD device...\n",
      "2020-01-13 14:50:22,168 INFO:Reading IR...\n",
      "2020-01-13 14:50:22,172 INFO:Loading IR to the plugin...\n",
      "2020-01-13 14:50:24,559 INFO:Batch size is 1\n",
      "number of infer request:  9\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "9\n",
      "2020-01-13 14:50:25,095 INFO:Initializing plugin for MYRIAD device...\n",
      "2020-01-13 14:50:25,096 INFO:Reading IR...\n",
      "2020-01-13 14:50:25,102 INFO:Loading IR to the plugin...\n",
      "2020-01-13 14:50:27,489 INFO:Batch size is 1\n",
      "number of infer request:  10\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "10\n",
      "2020-01-13 14:50:28,037 INFO:Initializing plugin for MYRIAD device...\n",
      "2020-01-13 14:50:28,038 INFO:Reading IR...\n",
      "2020-01-13 14:50:28,043 INFO:Loading IR to the plugin...\n",
      "2020-01-13 14:50:30,430 INFO:Batch size is 1\n",
      "number of infer request:  11\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "11\n",
      "2020-01-13 14:50:30,994 INFO:Initializing plugin for MYRIAD device...\n",
      "2020-01-13 14:50:30,996 INFO:Reading IR...\n",
      "2020-01-13 14:50:31,001 INFO:Loading IR to the plugin...\n",
      "2020-01-13 14:50:33,384 INFO:Batch size is 1\n",
      "number of infer request:  12\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "12\n",
      "2020-01-13 14:50:33,955 INFO:Initializing plugin for MYRIAD device...\n",
      "2020-01-13 14:50:33,956 INFO:Reading IR...\n",
      "2020-01-13 14:50:33,961 INFO:Loading IR to the plugin...\n",
      "2020-01-13 14:50:36,341 INFO:Batch size is 1\n",
      "number of infer request:  13\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "13\n",
      "2020-01-13 14:50:36,934 INFO:Initializing plugin for MYRIAD device...\n",
      "2020-01-13 14:50:36,936 INFO:Reading IR...\n",
      "2020-01-13 14:50:36,941 INFO:Loading IR to the plugin...\n",
      "2020-01-13 14:50:39,323 INFO:Batch size is 1\n",
      "number of infer request:  14\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "14\n",
      "2020-01-13 14:50:39,914 INFO:Initializing plugin for MYRIAD device...\n",
      "2020-01-13 14:50:39,916 INFO:Reading IR...\n",
      "2020-01-13 14:50:39,921 INFO:Loading IR to the plugin...\n",
      "2020-01-13 14:50:42,311 INFO:Batch size is 1\n",
      "number of infer request:  15\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "15\n",
      "2020-01-13 14:50:42,926 INFO:Initializing plugin for MYRIAD device...\n",
      "2020-01-13 14:50:42,928 INFO:Reading IR...\n",
      "2020-01-13 14:50:42,935 INFO:Loading IR to the plugin...\n",
      "2020-01-13 14:50:45,312 INFO:Batch size is 1\n",
      "number of infer request:  16\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "16\n",
      "2020-01-13 14:50:45,930 INFO:Initializing plugin for MYRIAD device...\n",
      "2020-01-13 14:50:45,932 INFO:Reading IR...\n",
      "2020-01-13 14:50:45,936 INFO:Loading IR to the plugin...\n",
      "2020-01-13 14:50:48,319 INFO:Batch size is 1\n",
      "number of infer request:  17\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "17\n",
      "2020-01-13 14:50:48,958 INFO:Initializing plugin for MYRIAD device...\n",
      "2020-01-13 14:50:48,960 INFO:Reading IR...\n",
      "2020-01-13 14:50:48,964 INFO:Loading IR to the plugin...\n",
      "2020-01-13 14:50:51,345 INFO:Batch size is 1\n",
      "number of infer request:  18\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "18\n",
      "2020-01-13 14:50:51,991 INFO:Initializing plugin for MYRIAD device...\n",
      "2020-01-13 14:50:51,992 INFO:Reading IR...\n",
      "2020-01-13 14:50:51,997 INFO:Loading IR to the plugin...\n",
      "2020-01-13 14:50:54,383 INFO:Batch size is 1\n",
      "number of infer request:  19\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "19\n",
      "[24.45054054260254, 28.92613410949707, 49.49378967285156, 53.98225784301758, 76.17640495300293, 79.46920394897461, 101.49168968200684, 106.68754577636719, 127.98953056335449, 132.2317123413086, 153.97143363952637, 158.54263305664062, 179.56113815307617, 182.68704414367676, 204.15759086608887, 207.74412155151367, 228.75475883483887, 235.43310165405273, 255.40423393249512]\n"
     ]
    }
   ],
   "source": [
    "times=[]\n",
    "for i in range(1,20):\n",
    "    t=test(i)\n",
    "    times.append(t)\n",
    "print(times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40.89889130498376\n",
      "69.14162785905626\n",
      "60.613665266484254\n",
      "74.09841973694671\n",
      "65.6371221913761\n",
      "75.500945043472\n",
      "68.97116425918574\n",
      "74.98532224903906\n",
      "70.3182515037433\n",
      "75.62482420395946\n",
      "71.44182359016604\n",
      "75.68942037005847\n",
      "72.39873913539954\n",
      "76.63378684363356\n",
      "73.47265382769336\n",
      "77.01782308209636\n",
      "74.31539385929896\n",
      "76.45483950022178\n",
      "74.39187560618832\n"
     ]
    }
   ],
   "source": [
    "模型2异步FPS\n",
    "for i,t in enumerate(times):\n",
    "    fps = (i+1)*1000/t\n",
    "    print(fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01-13 14:58:16,485 INFO:Initializing plugin for MYRIAD device...\n",
      "2020-01-13 14:58:16,491 INFO:Reading IR...\n",
      "2020-01-13 14:58:16,507 INFO:Loading IR to the plugin...\n",
      "2020-01-13 14:58:18,615 INFO:Batch size is 1\n",
      "number of infer request:  1\n",
      "1\n",
      "2020-01-13 14:58:19,049 INFO:Initializing plugin for MYRIAD device...\n",
      "2020-01-13 14:58:19,051 INFO:Reading IR...\n",
      "2020-01-13 14:58:19,056 INFO:Loading IR to the plugin...\n",
      "2020-01-13 14:58:21,440 INFO:Batch size is 1\n",
      "number of infer request:  2\n",
      "2\n",
      "2020-01-13 14:58:21,898 INFO:Initializing plugin for MYRIAD device...\n",
      "2020-01-13 14:58:21,899 INFO:Reading IR...\n",
      "2020-01-13 14:58:21,904 INFO:Loading IR to the plugin...\n",
      "2020-01-13 14:58:24,297 INFO:Batch size is 1\n",
      "number of infer request:  3\n",
      "3\n",
      "2020-01-13 14:58:24,781 INFO:Initializing plugin for MYRIAD device...\n",
      "2020-01-13 14:58:24,782 INFO:Reading IR...\n",
      "2020-01-13 14:58:24,787 INFO:Loading IR to the plugin...\n",
      "2020-01-13 14:58:27,171 INFO:Batch size is 1\n",
      "number of infer request:  4\n",
      "4\n",
      "2020-01-13 14:58:27,678 INFO:Initializing plugin for MYRIAD device...\n",
      "2020-01-13 14:58:27,679 INFO:Reading IR...\n",
      "2020-01-13 14:58:27,684 INFO:Loading IR to the plugin...\n",
      "2020-01-13 14:58:30,069 INFO:Batch size is 1\n",
      "number of infer request:  5\n",
      "5\n",
      "2020-01-13 14:58:30,602 INFO:Initializing plugin for MYRIAD device...\n",
      "2020-01-13 14:58:30,603 INFO:Reading IR...\n",
      "2020-01-13 14:58:30,608 INFO:Loading IR to the plugin...\n",
      "2020-01-13 14:58:32,996 INFO:Batch size is 1\n",
      "number of infer request:  6\n",
      "6\n",
      "2020-01-13 14:58:33,554 INFO:Initializing plugin for MYRIAD device...\n",
      "2020-01-13 14:58:33,555 INFO:Reading IR...\n",
      "2020-01-13 14:58:33,560 INFO:Loading IR to the plugin...\n",
      "2020-01-13 14:58:35,947 INFO:Batch size is 1\n",
      "number of infer request:  7\n",
      "7\n",
      "2020-01-13 14:58:36,525 INFO:Initializing plugin for MYRIAD device...\n",
      "2020-01-13 14:58:36,527 INFO:Reading IR...\n",
      "2020-01-13 14:58:36,532 INFO:Loading IR to the plugin...\n",
      "2020-01-13 14:58:38,917 INFO:Batch size is 1\n",
      "number of infer request:  8\n",
      "8\n",
      "2020-01-13 14:58:39,525 INFO:Initializing plugin for MYRIAD device...\n",
      "2020-01-13 14:58:39,527 INFO:Reading IR...\n",
      "2020-01-13 14:58:39,532 INFO:Loading IR to the plugin...\n",
      "2020-01-13 14:58:41,913 INFO:Batch size is 1\n",
      "number of infer request:  9\n",
      "9\n",
      "2020-01-13 14:58:42,543 INFO:Initializing plugin for MYRIAD device...\n",
      "2020-01-13 14:58:42,544 INFO:Reading IR...\n",
      "2020-01-13 14:58:42,549 INFO:Loading IR to the plugin...\n",
      "2020-01-13 14:58:44,943 INFO:Batch size is 1\n",
      "number of infer request:  10\n",
      "10\n",
      "2020-01-13 14:58:45,598 INFO:Initializing plugin for MYRIAD device...\n",
      "2020-01-13 14:58:45,599 INFO:Reading IR...\n",
      "2020-01-13 14:58:45,604 INFO:Loading IR to the plugin...\n",
      "2020-01-13 14:58:47,990 INFO:Batch size is 1\n",
      "number of infer request:  11\n",
      "11\n",
      "2020-01-13 14:58:48,668 INFO:Initializing plugin for MYRIAD device...\n",
      "2020-01-13 14:58:48,669 INFO:Reading IR...\n",
      "2020-01-13 14:58:48,674 INFO:Loading IR to the plugin...\n",
      "2020-01-13 14:58:51,061 INFO:Batch size is 1\n",
      "number of infer request:  12\n",
      "12\n",
      "2020-01-13 14:58:51,767 INFO:Initializing plugin for MYRIAD device...\n",
      "2020-01-13 14:58:51,768 INFO:Reading IR...\n",
      "2020-01-13 14:58:51,773 INFO:Loading IR to the plugin...\n",
      "2020-01-13 14:58:54,152 INFO:Batch size is 1\n",
      "number of infer request:  13\n",
      "13\n",
      "2020-01-13 14:58:54,883 INFO:Initializing plugin for MYRIAD device...\n",
      "2020-01-13 14:58:54,884 INFO:Reading IR...\n",
      "2020-01-13 14:58:54,889 INFO:Loading IR to the plugin...\n",
      "2020-01-13 14:58:57,268 INFO:Batch size is 1\n",
      "number of infer request:  14\n",
      "14\n",
      "2020-01-13 14:58:58,018 INFO:Initializing plugin for MYRIAD device...\n",
      "2020-01-13 14:58:58,020 INFO:Reading IR...\n",
      "2020-01-13 14:58:58,025 INFO:Loading IR to the plugin...\n",
      "2020-01-13 14:59:00,407 INFO:Batch size is 1\n",
      "number of infer request:  15\n",
      "15\n",
      "2020-01-13 14:59:01,186 INFO:Initializing plugin for MYRIAD device...\n",
      "2020-01-13 14:59:01,187 INFO:Reading IR...\n",
      "2020-01-13 14:59:01,192 INFO:Loading IR to the plugin...\n",
      "2020-01-13 14:59:03,583 INFO:Batch size is 1\n",
      "number of infer request:  16\n",
      "16\n",
      "2020-01-13 14:59:04,386 INFO:Initializing plugin for MYRIAD device...\n",
      "2020-01-13 14:59:04,387 INFO:Reading IR...\n",
      "2020-01-13 14:59:04,392 INFO:Loading IR to the plugin...\n",
      "2020-01-13 14:59:06,772 INFO:Batch size is 1\n",
      "number of infer request:  17\n",
      "17\n",
      "2020-01-13 14:59:07,599 INFO:Initializing plugin for MYRIAD device...\n",
      "2020-01-13 14:59:07,601 INFO:Reading IR...\n",
      "2020-01-13 14:59:07,606 INFO:Loading IR to the plugin...\n",
      "2020-01-13 14:59:09,987 INFO:Batch size is 1\n",
      "number of infer request:  18\n",
      "18\n",
      "2020-01-13 14:59:10,834 INFO:Initializing plugin for MYRIAD device...\n",
      "2020-01-13 14:59:10,835 INFO:Reading IR...\n",
      "2020-01-13 14:59:10,840 INFO:Loading IR to the plugin...\n",
      "2020-01-13 14:59:13,222 INFO:Batch size is 1\n",
      "number of infer request:  19\n",
      "19\n",
      "[24.765729904174805, 49.14999008178711, 74.1739273071289, 98.47211837768555, 123.65984916687012, 147.87912368774414, 170.36175727844238, 196.00176811218262, 220.0019359588623, 244.30489540100098, 268.5437202453613, 293.1351661682129, 317.2025680541992, 339.7657871246338, 365.4937744140625, 390.11645317077637, 412.7335548400879, 437.1755123138428, 462.50176429748535]\n"
     ]
    }
   ],
   "source": [
    "times=[]\n",
    "for i in range(1,20):\n",
    "    t=test(i,'sync')\n",
    "    times.append(t)\n",
    "print(times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40.37837785800241\n",
      "40.69176813000242\n",
      "40.44547874050169\n",
      "40.62063522039988\n",
      "40.43349586536255\n",
      "40.57367835550181\n",
      "41.0890337821479\n",
      "40.81595833064709\n",
      "40.908730919908315\n",
      "40.932458531320236\n",
      "40.961672795586466\n",
      "40.936746542084656\n",
      "40.983274756397115\n",
      "41.20485502227593\n",
      "41.040370726005094\n",
      "41.013394513242645\n",
      "41.188800378943235\n",
      "41.173394879167034\n",
      "41.08092436979122\n"
     ]
    }
   ],
   "source": [
    "#模型2同步FPS\n",
    "for i,t in enumerate(times):\n",
    "    fps = (i+1)*1000/t\n",
    "    print(fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01-13 15:37:30,231 INFO:Initializing plugin for MYRIAD device...\n",
      "2020-01-13 15:37:30,237 INFO:Reading IR...\n",
      "2020-01-13 15:37:30,244 INFO:Loading IR to the plugin...\n",
      "2020-01-13 15:37:32,251 INFO:Batch size is 1\n",
      "number of infer request:  1\n",
      "flag\n",
      "1\n",
      "2020-01-13 15:37:32,665 INFO:Initializing plugin for MYRIAD device...\n",
      "2020-01-13 15:37:32,666 INFO:Reading IR...\n",
      "2020-01-13 15:37:32,669 INFO:Loading IR to the plugin...\n",
      "2020-01-13 15:37:34,951 INFO:Batch size is 1\n",
      "number of infer request:  2\n",
      "flag\n",
      "flag\n",
      "2\n",
      "2020-01-13 15:37:35,365 INFO:Initializing plugin for MYRIAD device...\n",
      "2020-01-13 15:37:35,367 INFO:Reading IR...\n",
      "2020-01-13 15:37:35,369 INFO:Loading IR to the plugin...\n",
      "2020-01-13 15:37:37,645 INFO:Batch size is 1\n",
      "number of infer request:  3\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "3\n",
      "2020-01-13 15:37:38,065 INFO:Initializing plugin for MYRIAD device...\n",
      "2020-01-13 15:37:38,066 INFO:Reading IR...\n",
      "2020-01-13 15:37:38,069 INFO:Loading IR to the plugin...\n",
      "2020-01-13 15:37:40,343 INFO:Batch size is 1\n",
      "number of infer request:  4\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "4\n",
      "2020-01-13 15:37:40,765 INFO:Initializing plugin for MYRIAD device...\n",
      "2020-01-13 15:37:40,767 INFO:Reading IR...\n",
      "2020-01-13 15:37:40,769 INFO:Loading IR to the plugin...\n",
      "2020-01-13 15:37:43,042 INFO:Batch size is 1\n",
      "number of infer request:  5\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "5\n",
      "2020-01-13 15:37:43,470 INFO:Initializing plugin for MYRIAD device...\n",
      "2020-01-13 15:37:43,471 INFO:Reading IR...\n",
      "2020-01-13 15:37:43,473 INFO:Loading IR to the plugin...\n",
      "2020-01-13 15:37:45,753 INFO:Batch size is 1\n",
      "number of infer request:  6\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "6\n",
      "2020-01-13 15:37:46,181 INFO:Initializing plugin for MYRIAD device...\n",
      "2020-01-13 15:37:46,183 INFO:Reading IR...\n",
      "2020-01-13 15:37:46,186 INFO:Loading IR to the plugin...\n",
      "2020-01-13 15:37:48,470 INFO:Batch size is 1\n",
      "number of infer request:  7\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "7\n",
      "2020-01-13 15:37:48,906 INFO:Initializing plugin for MYRIAD device...\n",
      "2020-01-13 15:37:48,907 INFO:Reading IR...\n",
      "2020-01-13 15:37:48,910 INFO:Loading IR to the plugin...\n",
      "2020-01-13 15:37:51,185 INFO:Batch size is 1\n",
      "number of infer request:  8\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "8\n",
      "2020-01-13 15:37:51,621 INFO:Initializing plugin for MYRIAD device...\n",
      "2020-01-13 15:37:51,622 INFO:Reading IR...\n",
      "2020-01-13 15:37:51,625 INFO:Loading IR to the plugin...\n",
      "2020-01-13 15:37:53,916 INFO:Batch size is 1\n",
      "number of infer request:  9\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "9\n",
      "2020-01-13 15:37:54,358 INFO:Initializing plugin for MYRIAD device...\n",
      "2020-01-13 15:37:54,359 INFO:Reading IR...\n",
      "2020-01-13 15:37:54,362 INFO:Loading IR to the plugin...\n",
      "2020-01-13 15:37:56,636 INFO:Batch size is 1\n",
      "number of infer request:  10\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "10\n",
      "2020-01-13 15:37:57,082 INFO:Initializing plugin for MYRIAD device...\n",
      "2020-01-13 15:37:57,083 INFO:Reading IR...\n",
      "2020-01-13 15:37:57,086 INFO:Loading IR to the plugin...\n",
      "2020-01-13 15:37:59,358 INFO:Batch size is 1\n",
      "number of infer request:  11\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "11\n",
      "2020-01-13 15:37:59,808 INFO:Initializing plugin for MYRIAD device...\n",
      "2020-01-13 15:37:59,809 INFO:Reading IR...\n",
      "2020-01-13 15:37:59,812 INFO:Loading IR to the plugin...\n",
      "2020-01-13 15:38:02,088 INFO:Batch size is 1\n",
      "number of infer request:  12\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "12\n",
      "2020-01-13 15:38:02,538 INFO:Initializing plugin for MYRIAD device...\n",
      "2020-01-13 15:38:02,539 INFO:Reading IR...\n",
      "2020-01-13 15:38:02,542 INFO:Loading IR to the plugin...\n",
      "2020-01-13 15:38:04,818 INFO:Batch size is 1\n",
      "number of infer request:  13\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "13\n",
      "2020-01-13 15:38:05,273 INFO:Initializing plugin for MYRIAD device...\n",
      "2020-01-13 15:38:05,275 INFO:Reading IR...\n",
      "2020-01-13 15:38:05,278 INFO:Loading IR to the plugin...\n",
      "2020-01-13 15:38:07,556 INFO:Batch size is 1\n",
      "number of infer request:  14\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "14\n",
      "2020-01-13 15:38:08,013 INFO:Initializing plugin for MYRIAD device...\n",
      "2020-01-13 15:38:08,015 INFO:Reading IR...\n",
      "2020-01-13 15:38:08,017 INFO:Loading IR to the plugin...\n",
      "2020-01-13 15:38:10,292 INFO:Batch size is 1\n",
      "number of infer request:  15\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "15\n",
      "2020-01-13 15:38:10,754 INFO:Initializing plugin for MYRIAD device...\n",
      "2020-01-13 15:38:10,755 INFO:Reading IR...\n",
      "2020-01-13 15:38:10,758 INFO:Loading IR to the plugin...\n",
      "2020-01-13 15:38:13,032 INFO:Batch size is 1\n",
      "number of infer request:  16\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "16\n",
      "2020-01-13 15:38:13,498 INFO:Initializing plugin for MYRIAD device...\n",
      "2020-01-13 15:38:13,500 INFO:Reading IR...\n",
      "2020-01-13 15:38:13,502 INFO:Loading IR to the plugin...\n",
      "2020-01-13 15:38:15,783 INFO:Batch size is 1\n",
      "number of infer request:  17\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "17\n",
      "2020-01-13 15:38:16,255 INFO:Initializing plugin for MYRIAD device...\n",
      "2020-01-13 15:38:16,257 INFO:Reading IR...\n",
      "2020-01-13 15:38:16,260 INFO:Loading IR to the plugin...\n",
      "2020-01-13 15:38:18,537 INFO:Batch size is 1\n",
      "number of infer request:  18\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "18\n",
      "2020-01-13 15:38:19,009 INFO:Initializing plugin for MYRIAD device...\n",
      "2020-01-13 15:38:19,011 INFO:Reading IR...\n",
      "2020-01-13 15:38:19,013 INFO:Loading IR to the plugin...\n",
      "2020-01-13 15:38:21,290 INFO:Batch size is 1\n",
      "number of infer request:  19\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "flag\n",
      "19\n",
      "[5.084991455078125, 7.755517959594727, 11.28077507019043, 15.462636947631836, 18.564939498901367, 21.84748649597168, 25.561094284057617, 29.275894165039062, 32.860517501831055, 35.9499454498291, 39.65139389038086, 42.990922927856445, 46.530723571777344, 50.073862075805664, 53.833961486816406, 57.28006362915039, 60.936689376831055, 64.44168090820312, 67.77334213256836]\n"
     ]
    }
   ],
   "source": [
    "times=[]\n",
    "for i in range(1,20):\n",
    "    t=test1(i)\n",
    "    times.append(t)\n",
    "print(times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196.65716429107277\n",
      "257.88090626825294\n",
      "265.9391736235866\n",
      "258.6880888135071\n",
      "269.3248744654347\n",
      "274.63113439188083\n",
      "273.8536903862477\n",
      "273.26236236888394\n",
      "273.8849136961553\n",
      "278.16453891302183\n",
      "277.41773795923274\n",
      "279.12869002922633\n",
      "279.385296468611\n",
      "279.58698250208306\n",
      "278.63451965490975\n",
      "279.32929864724247\n",
      "278.9780700896368\n",
      "279.32232285562065\n",
      "280.3462158149876\n"
     ]
    }
   ],
   "source": [
    "#模型1异步FPS\n",
    "for i,t in enumerate(times):\n",
    "    fps = (i+1)*1000/t\n",
    "    print(fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01-13 15:44:04,233 INFO:Initializing plugin for MYRIAD device...\n",
      "2020-01-13 15:44:04,239 INFO:Reading IR...\n",
      "2020-01-13 15:44:04,245 INFO:Loading IR to the plugin...\n",
      "2020-01-13 15:44:06,253 INFO:Batch size is 1\n",
      "number of infer request:  1\n",
      "1\n",
      "2020-01-13 15:44:06,665 INFO:Initializing plugin for MYRIAD device...\n",
      "2020-01-13 15:44:06,667 INFO:Reading IR...\n",
      "2020-01-13 15:44:06,669 INFO:Loading IR to the plugin...\n",
      "2020-01-13 15:44:08,954 INFO:Batch size is 1\n",
      "number of infer request:  2\n",
      "2\n",
      "2020-01-13 15:44:09,374 INFO:Initializing plugin for MYRIAD device...\n",
      "2020-01-13 15:44:09,375 INFO:Reading IR...\n",
      "2020-01-13 15:44:09,378 INFO:Loading IR to the plugin...\n",
      "2020-01-13 15:44:11,656 INFO:Batch size is 1\n",
      "number of infer request:  3\n",
      "3\n",
      "2020-01-13 15:44:12,082 INFO:Initializing plugin for MYRIAD device...\n",
      "2020-01-13 15:44:12,084 INFO:Reading IR...\n",
      "2020-01-13 15:44:12,086 INFO:Loading IR to the plugin...\n",
      "2020-01-13 15:44:14,359 INFO:Batch size is 1\n",
      "number of infer request:  4\n",
      "4\n",
      "2020-01-13 15:44:14,785 INFO:Initializing plugin for MYRIAD device...\n",
      "2020-01-13 15:44:14,788 INFO:Reading IR...\n",
      "2020-01-13 15:44:14,790 INFO:Loading IR to the plugin...\n",
      "2020-01-13 15:44:17,068 INFO:Batch size is 1\n",
      "number of infer request:  5\n",
      "5\n",
      "2020-01-13 15:44:17,502 INFO:Initializing plugin for MYRIAD device...\n",
      "2020-01-13 15:44:17,504 INFO:Reading IR...\n",
      "2020-01-13 15:44:17,506 INFO:Loading IR to the plugin...\n",
      "2020-01-13 15:44:19,778 INFO:Batch size is 1\n",
      "number of infer request:  6\n",
      "6\n",
      "2020-01-13 15:44:20,214 INFO:Initializing plugin for MYRIAD device...\n",
      "2020-01-13 15:44:20,216 INFO:Reading IR...\n",
      "2020-01-13 15:44:20,218 INFO:Loading IR to the plugin...\n",
      "2020-01-13 15:44:22,502 INFO:Batch size is 1\n",
      "number of infer request:  7\n",
      "7\n",
      "2020-01-13 15:44:22,946 INFO:Initializing plugin for MYRIAD device...\n",
      "2020-01-13 15:44:22,948 INFO:Reading IR...\n",
      "2020-01-13 15:44:22,950 INFO:Loading IR to the plugin...\n",
      "2020-01-13 15:44:25,226 INFO:Batch size is 1\n",
      "number of infer request:  8\n",
      "8\n",
      "2020-01-13 15:44:25,675 INFO:Initializing plugin for MYRIAD device...\n",
      "2020-01-13 15:44:25,677 INFO:Reading IR...\n",
      "2020-01-13 15:44:25,680 INFO:Loading IR to the plugin...\n",
      "2020-01-13 15:44:27,959 INFO:Batch size is 1\n",
      "number of infer request:  9\n",
      "9\n",
      "2020-01-13 15:44:28,410 INFO:Initializing plugin for MYRIAD device...\n",
      "2020-01-13 15:44:28,411 INFO:Reading IR...\n",
      "2020-01-13 15:44:28,413 INFO:Loading IR to the plugin...\n",
      "2020-01-13 15:44:30,686 INFO:Batch size is 1\n",
      "number of infer request:  10\n",
      "10\n",
      "2020-01-13 15:44:31,142 INFO:Initializing plugin for MYRIAD device...\n",
      "2020-01-13 15:44:31,143 INFO:Reading IR...\n",
      "2020-01-13 15:44:31,146 INFO:Loading IR to the plugin...\n",
      "2020-01-13 15:44:33,421 INFO:Batch size is 1\n",
      "number of infer request:  11\n",
      "11\n",
      "2020-01-13 15:44:33,884 INFO:Initializing plugin for MYRIAD device...\n",
      "2020-01-13 15:44:33,885 INFO:Reading IR...\n",
      "2020-01-13 15:44:33,888 INFO:Loading IR to the plugin...\n",
      "2020-01-13 15:44:36,169 INFO:Batch size is 1\n",
      "number of infer request:  12\n",
      "12\n",
      "2020-01-13 15:44:36,634 INFO:Initializing plugin for MYRIAD device...\n",
      "2020-01-13 15:44:36,635 INFO:Reading IR...\n",
      "2020-01-13 15:44:36,638 INFO:Loading IR to the plugin...\n",
      "2020-01-13 15:44:38,911 INFO:Batch size is 1\n",
      "number of infer request:  13\n",
      "13\n",
      "2020-01-13 15:44:39,382 INFO:Initializing plugin for MYRIAD device...\n",
      "2020-01-13 15:44:39,384 INFO:Reading IR...\n",
      "2020-01-13 15:44:39,386 INFO:Loading IR to the plugin...\n",
      "2020-01-13 15:44:41,659 INFO:Batch size is 1\n",
      "number of infer request:  14\n",
      "14\n",
      "2020-01-13 15:44:42,133 INFO:Initializing plugin for MYRIAD device...\n",
      "2020-01-13 15:44:42,135 INFO:Reading IR...\n",
      "2020-01-13 15:44:42,138 INFO:Loading IR to the plugin...\n",
      "2020-01-13 15:44:44,411 INFO:Batch size is 1\n",
      "number of infer request:  15\n",
      "15\n",
      "2020-01-13 15:44:44,889 INFO:Initializing plugin for MYRIAD device...\n",
      "2020-01-13 15:44:44,891 INFO:Reading IR...\n",
      "2020-01-13 15:44:44,893 INFO:Loading IR to the plugin...\n",
      "2020-01-13 15:44:47,166 INFO:Batch size is 1\n",
      "number of infer request:  16\n",
      "16\n",
      "2020-01-13 15:44:47,654 INFO:Initializing plugin for MYRIAD device...\n",
      "2020-01-13 15:44:47,655 INFO:Reading IR...\n",
      "2020-01-13 15:44:47,658 INFO:Loading IR to the plugin...\n",
      "2020-01-13 15:44:49,936 INFO:Batch size is 1\n",
      "number of infer request:  17\n",
      "17\n",
      "2020-01-13 15:44:50,425 INFO:Initializing plugin for MYRIAD device...\n",
      "2020-01-13 15:44:50,427 INFO:Reading IR...\n",
      "2020-01-13 15:44:50,429 INFO:Loading IR to the plugin...\n",
      "2020-01-13 15:44:52,701 INFO:Batch size is 1\n",
      "number of infer request:  18\n",
      "18\n",
      "2020-01-13 15:44:53,197 INFO:Initializing plugin for MYRIAD device...\n",
      "2020-01-13 15:44:53,199 INFO:Reading IR...\n",
      "2020-01-13 15:44:53,202 INFO:Loading IR to the plugin...\n",
      "2020-01-13 15:44:55,473 INFO:Batch size is 1\n",
      "number of infer request:  19\n",
      "19\n",
      "[5.008697509765625, 10.054349899291992, 14.988899230957031, 19.63329315185547, 24.40953254699707, 29.195547103881836, 33.8287353515625, 38.71941566467285, 42.69099235534668, 47.78265953063965, 53.032636642456055, 57.05714225769043, 62.755584716796875, 66.3304328918457, 70.98555564880371, 77.50701904296875, 80.90543746948242, 87.23878860473633, 90.01803398132324]\n"
     ]
    }
   ],
   "source": [
    "times=[]\n",
    "for i in range(1,20):\n",
    "    t=test1(i,'sync')\n",
    "    times.append(t)\n",
    "print(times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199.65270373191166\n",
      "198.9188779018757\n",
      "200.14811987020423\n",
      "203.73556127653373\n",
      "204.83800705208975\n",
      "205.51079171940714\n",
      "206.92467298150655\n",
      "206.61468833319992\n",
      "210.81730602762218\n",
      "209.2809420452561\n",
      "207.4194438824825\n",
      "210.3154754194263\n",
      "207.15287824448362\n",
      "211.06450522986233\n",
      "211.31059499219106\n",
      "206.43291662565213\n",
      "210.1218475756022\n",
      "206.33023782064245\n",
      "211.06881765427227\n"
     ]
    }
   ],
   "source": [
    "#模型1同步FPS\n",
    "for i,t in enumerate(times):\n",
    "    fps = (i+1)*1000/t\n",
    "    print(fps)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
