{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型结构从2012年开始，一直在改进，设计各种结构，感觉深度学习相比之前机器学习由feature engineering 变成了structure engineering,希望未来Auto ML可以解决对不同domain不同分布的数据得到不同的模型结构，或者减少人为过多参与的模型结构。本文将用tensorflow2.0 keras 来实现这些结构，主要是图像CNN的结构，序列模型将在以后研究，这样可以再次熟悉各大家产出知名网络结构的思路。另外文后会写个总结，简单说明一下structure engineering,网络结构设思路可能是要博采众长,归根结底是矩阵运算，拼接，elementwise add,激活等。\n",
    "有些模型以精度为主要考虑，有些以速度为主要考虑，兼顾精度。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本文主要以代码为主，关于结构相关说明和论文部分有链接（网上搜有很多），主要是能过代码来理解论文中所说的内容是如何实现的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.Lenet5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "开山鼻主，那里还没有relu,只是sigmoid.手写数字被数字化为像素大小的灰度图像--32×32。那时，计算能力有限，因此该技术无法扩展到大规模图像。\n",
    "\n",
    "该模型包含7层（不包括输入层）。由于它是一个相对较小的架构，让我们逐层解释：\n",
    "1. 第1层：卷积层，核大小为5×5，步长为1×1，总共为6个核。因此，大小为32x32x1的输入图像的输出为28x28x6。层中的总参数= 5 * 5 * 6 + 6（偏差项）\n",
    "2. 第2层：具有2×2核大小的池化层，总共2×2和6个核。这个池化层的行为与之前的文章略有不同。将接收器中的输入值相加，然后乘以可训练参数（每个filter 1个），最后将结果加到可训练的偏差（每个filter 1个）。最后，将sigmoid激活应用于输出。因此，来自前一层大小为28x28x6的输入被子采样为14x14x6。层中的总参数= [1（可训练参数）+ 1（可训练偏差）] * 6 = 12\n",
    "3. 第3层：与第1层类似，此层是具有相同配置的卷积层，除了它有16个filters而不是6个。因此，前一个大小为14x14x6的输入提供10x10x16的输出。层中的总参数= 5 * 5 * 16 + 16 = 416。\n",
    "4. 第4层：与第2层类似，此层是一个池化层，这次有16个filters。请记住，输出通过sigmoid激活函数传递。来自前一层的大小为10x10x16的输入被子采样为5x5x16。层中的总参数=（1 + 1）* 16 = 32\n",
    "5. 第5层：卷积层，核大小为5×5，filters为120。由于输入大小为5x5x16，因此我们无需考虑步幅，因此输出为1x1x120。层中的总参数= 5 * 5 * 120 = 3000\n",
    "6. 第6层：这是一个包含84个参数的dense层。因此，120个units的输入转换为84个units。总参数= 84 * 120 + 84 = 10164.此处使用的激活函数相当独特。我要说的是，你可以在这里尝试你的任何选择，因为按照今天的标准，这个任务非常简单。\n",
    "7. 输出层：最后，使用具有10个units的dense层。总参数= 84 * 10 + 10 = 924。\n",
    "跳过所使用的损失函数的细节及其使用原因，我建议在最后一层使用softmax激活的交叉熵损失。尝试不同的训练计划和学习率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def lenet5(in_shape=(32,32,1),n_classes=10):\n",
    "    in_layer=layers.Input(shape=in_shape)\n",
    "    conv1 = layers.Conv2D(filters=6,kernel_size=5,padding='same',activation='relu')(in_layer)\n",
    "    pool1 = layers.MaxPooling2D(pool_size=2,strides=2)(conv1)\n",
    "    conv2 = layers.Conv2D(filters=16,kernel_size=5,padding='same',activation='relu')(pool1)\n",
    "    pool2 = layers.MaxPooling2D(pool_size=2,strides=2)(conv2)\n",
    "    flatten = layers.Flatten()(pool2)\n",
    "    dense1= layers.Dense(500,activation='relu')(flatten)\n",
    "    logits = layers.Dense(n_classes,activation='softmax')(dense1)\n",
    "    model = Model(in_layer,logits)\n",
    "    return model\n",
    "model = lenet5()\n",
    "#model.summary()\n",
    "#tf.keras.utils.plot_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.AlexNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2012年，Hinton的深度神经网络将世界上最重要的计算机视觉挑战图像网络中的损失从26％减少到15.3％。\n",
    "\n",
    "该网络与LeNet非常相似，但更深，拥有大约6000万个参数。作者使用了各种其他技术 - dropout，augmentation 和Stochastic Gradient Descent with momentum。\n",
    "- 5个卷积层，3个全连接层，参数量60M。\n",
    "- 激活函数是Relu:f(x)=max(0,x)\n",
    "- 使用了数据增强：从原始图像（256x256）中截取224x224大小的区域，并进行水平翻转，将一张图片变成了2048（2*(256-224)^2）张图片，测试时以图片4个角落和中心点为基准，获取切割区域，并进行水平翻转，1张测试图片变为10张图片。\n",
    "- 使用dropout防止过拟合\n",
    "- 使用max pooling。之前CNN普遍使用平均池化，AlexNet全部使用max pooling，避免平均池化的模糊效果。\n",
    "- 双GPU实现。\n",
    "- 使用LRN,对局部神经元的活动创建竞争机制，使得其中响应比较大的值变得相对更大，并抑制其他反馈较小的神经元，增强了模型的泛化能力。\n",
    "- \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alexnet(in_shape=(224,224,3),n_classes=1000):\n",
    "    in_layer = layers.Input(in_shape)\n",
    "    conv1 = layers.Conv2D(96, 11, strides=4, activation='relu')(in_layer)\n",
    "    pool1 = layers.MaxPool2D(3, 2)(conv1)\n",
    "    conv2 = layers.Conv2D(256, 5, strides=1, padding='same', activation='relu')(pool1)\n",
    "    pool2 = layers.MaxPool2D(3, 2)(conv2)\n",
    "    conv3 = layers.Conv2D(384, 3, strides=1, padding='same', activation='relu')(pool2)\n",
    "    conv4 = layers.Conv2D(256, 3, strides=1, padding='same', activation='relu')(conv3)\n",
    "    pool3 = layers.MaxPool2D(3, 2)(conv4)\n",
    "    flattened = layers.Flatten()(pool3)\n",
    "    dense1 = layers.Dense(4096, activation='relu')(flattened)\n",
    "    drop1 = layers.Dropout(0.5)(dense1)\n",
    "    dense2 = layers.Dense(4096, activation='relu')(drop1)\n",
    "    drop2 = layers.Dropout(0.5)(dense2)\n",
    "    preds = layers.Dense(n_classes, activation='softmax')(drop2)\n",
    "    model = Model(in_layer, preds)\n",
    "    return model\n",
    "model = alexnet()\n",
    "#model.summary()\n",
    "#tf.keras.utils.plot_model(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.VGG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2014年imagenet挑战的亚军被命名为VGGNet。由于其简单的统一结构，它以更简单的形式提出了一种更简单的深度卷积神经网络的形式。\n",
    "VGGNet有两条简单的经验法则：\n",
    "- 每个卷积层都有配置 - 核大小= 3×3，stride = 1×1，padding = same。唯一不同的是filters的数量。\n",
    "- 每个Max Pooling层都有配置 - windows size= 2×2和stride = 2×2。因此，我们在每个Pooling层的图像大小减半。\n",
    "关于模型有几点说明：\n",
    "- 主要是VGG16和VGG19， 前者参数量是138M。\n",
    "- 大量使用3x3的卷积核。这里有一个知识点：stride都为1时，两个3x3的卷积核的感受野等于一个5x5的卷积核，三个3x3卷积核的感受野等于一个7x7的卷积核。为什么要用小卷积核呢？原因是：（1）减少参数量。两个3x3的卷积核参数量为3x3x2=18，一个5x5的卷积核参数量为25。（2）深度增加了，相当于增加了非线性拟合能力。\n",
    "- VGGNet探索了卷积神经网络的深度与其性能之间的关系，通过反复堆叠3x3的小型卷积核和2x2的最大池化层，VGGNet成功地构筑了16~19层深的卷积神经网络。\n",
    "- 优化方法：含有动量的随机梯度下降 (SGD+momentum)。\n",
    "- 数据增强：训练数据采用Multi-Scale方法，原始图像被缩放到S(256,512)，然后随机Scale到尺寸Q(224x224)。\n",
    "- 总参数= 1.38亿。大多数这些参数由全连接层贡献。第一个FC层= 4096 *（7 * 7 * 512）+ 4096 = 102,764,544，第二个FC层= 4096 * 4096 + 4096 = 16,781,312， 第三个FC层= 4096 * 1000 + 4096 = 4,100,096，FC层贡献的总参数= 123,645,952。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv3 = partial(layers.Conv2D,kernel_size=3,strides=1,padding='same',activation='relu')\n",
    "\n",
    "def block(in_tensor, filters, n_convs):\n",
    "    conv_block = in_tensor\n",
    "    for _ in range(n_convs):\n",
    "        conv_block = conv3(filters=filters)(conv_block)\n",
    "\n",
    "    return conv_block\n",
    "\n",
    "def _vgg(in_shape=(224,224,3),n_classes=1000,n_stages_per_blocks=[2, 2, 3, 3, 3]):\n",
    "    in_layer = layers.Input(in_shape)\n",
    "    block1 = block(in_layer, 64, n_stages_per_blocks[0])\n",
    "    pool1 = layers.MaxPooling2D()(block1)\n",
    "    block2 = block(pool1, 128, n_stages_per_blocks[1])\n",
    "    pool2 = layers.MaxPooling2D()(block2)\n",
    "    block3 = block(pool2, 256, n_stages_per_blocks[2])\n",
    "    pool3 = layers.MaxPooling2D()(block3)\n",
    "    block4 = block(pool3, 512, n_stages_per_blocks[3])\n",
    "    pool4 = layers.MaxPooling2D()(block4)\n",
    "    block5 = block(pool4, 512, n_stages_per_blocks[4])\n",
    "    pool5 = layers.MaxPooling2D()(block5)\n",
    "#     flattened = layers.GlobalAvgPool2D()(pool5)\n",
    "    flattened = layers.Flatten()(pool5)\n",
    "    dense1 = layers.Dense(4096, activation='relu')(flattened)\n",
    "    dense2 = layers.Dense(4096, activation='relu')(dense1)\n",
    "    preds = layers.Dense(1000, activation='softmax')(dense2)\n",
    "    model = Model(in_layer, preds)\n",
    "    \n",
    "    return model\n",
    "def vgg16(in_shape=(224,224,3), n_classes=1000):\n",
    "    return _vgg(in_shape, n_classes)\n",
    "\n",
    "def vgg19(in_shape=(224,224,3), n_classes=1000):\n",
    "    return _vgg(in_shape, n_classes, [2, 2, 4, 4, 4])\n",
    "model = vgg16()\n",
    "#model.summary()\n",
    "#tf.keras.utils.plot_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Inception系列（v1到v4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参考文献：\n",
    "- [v1] Going Deeper with Convolutions, 6.67% test error, http://arxiv.org/abs/1409.4842\n",
    "- [v2] Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift, 4.8% test error, http://arxiv.org/abs/1502.03167\n",
    "- [v3] Rethinking the Inception Architecture for Computer Vision, 3.5% test error, http://arxiv.org/abs/1512.00567\n",
    "- [v4] Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning, 3.08% test error, http://arxiv.org/abs/1602.07261"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Inceptionv1(GoogLeNet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "关于模型有几点：\n",
    "- 使用多个“辅助分类器”，增加中间层的辅助分类器，增强模型在低阶段层的识别，增加反向传播梯度信号，并提供附加的正则。较深的网络中，越向前梯度的值越小，使得很难学习，因此较早的分类层通过传播强梯度信号来训练网络而变得有用;:深度神经网络往往overfit(或导致高方差)数据,同时小神经网络往往underfit(或导致高偏差)。较早的分类器规范了更深层的过度拟合效果\n",
    "- 它使用了一个inception 模块，一个新颖的概念，inception模块在一层里使用1x1, 3x3, 5x5的卷积和3x3的maxpooling，然后concatenate一起具有较小的卷积，允许将参数数量减少到仅400万，Inception module的原因：1、每个层类型从输入中提取不同的信息。从3×3层收集的信息将与从5×5层收集的信息不同。我们怎么知道哪一种transformation 是最好的呢?所以我们全部使用它们 2、使用1×1卷积减少尺寸！考虑一个128x128x256输入。如果我们通过20个大小为1×1的过滤器，我们将获得128x128x20的输出。因此，我们在3×3或5×5卷积之前应用它们，以减少用于降维的inception block中这些层的输入filters的数量可以跨通道组织信息，提高网络的表达能力，还可以进行输出通道的升维和降维 3、增加网络宽度，提高特征表达能力； 4、增加了网络对尺度的适应能力，相当于一种多尺度方法\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "conv1x1 = partial(layers.Conv2D, kernel_size=1, activation='relu')\n",
    "conv3x3 = partial(layers.Conv2D, kernel_size=3, padding='same', activation='relu')\n",
    "conv5x5 = partial(layers.Conv2D, kernel_size=5, padding='same', activation='relu')\n",
    "\n",
    "def inception_module(in_tensor, c1, c3_1, c3, c5_1, c5, pp):\n",
    "    conv1 = conv1x1(c1)(in_tensor)\n",
    "    conv3_1 = conv1x1(c3_1)(in_tensor)\n",
    "    conv3 = conv3x3(c3)(conv3_1)\n",
    "    conv5_1 = conv1x1(c5_1)(in_tensor)\n",
    "    conv5 = conv5x5(c5)(conv5_1)\n",
    "    pool_conv = conv1x1(pp)(in_tensor)\n",
    "    pool = layers.MaxPool2D(3, strides=1, padding='same')(pool_conv)\n",
    "    merged = layers.Concatenate(axis=-1)([conv1, conv3, conv5, pool])\n",
    "    return merged\n",
    "\n",
    "def aux_clf(in_tensor):\n",
    "    avg_pool = layers.AvgPool2D(5, 3)(in_tensor)\n",
    "    conv = conv1x1(128)(avg_pool)\n",
    "    flattened = layers.Flatten()(conv)\n",
    "    dense = layers.Dense(1024, activation='relu')(flattened)\n",
    "    dropout = layers.Dropout(0.7)(dense)\n",
    "    out = layers.Dense(1000, activation='softmax')(dropout)\n",
    "    return out\n",
    "\n",
    "def inceptionv1_net(in_shape=(224,224,3), n_classes=1000):\n",
    "    in_layer = layers.Input(in_shape)\n",
    "    conv1 = layers.Conv2D(64, 7, strides=2, activation='relu', padding='same')(in_layer)\n",
    "    pad1 = layers.ZeroPadding2D()(conv1)\n",
    "    pool1 = layers.MaxPool2D(3, 2)(pad1)\n",
    "    conv2_1 = conv1x1(64)(pool1)\n",
    "    conv2_2 = conv3x3(192)(conv2_1)\n",
    "    pad2 = layers.ZeroPadding2D()(conv2_2)\n",
    "    pool2 = layers.MaxPool2D(3, 2)(pad2)\n",
    "    inception3a = inception_module(pool2, 64, 96, 128, 16, 32, 32)\n",
    "    inception3b = inception_module(inception3a, 128, 128, 192, 32, 96, 64)\n",
    "    pad3 = layers.ZeroPadding2D()(inception3b)\n",
    "    pool3 = layers.MaxPool2D(3, 2)(pad3)\n",
    "    inception4a = inception_module(pool3, 192, 96, 208, 16, 48, 64)\n",
    "    inception4b = inception_module(inception4a, 160, 112, 224, 24, 64, 64)\n",
    "    inception4c = inception_module(inception4b, 128, 128, 256, 24, 64, 64)\n",
    "    inception4d = inception_module(inception4c, 112, 144, 288, 32, 48, 64)\n",
    "    inception4e = inception_module(inception4d, 256, 160, 320, 32, 128, 128)\n",
    "    pad4 = layers.ZeroPadding2D()(inception4e)\n",
    "    pool4 = layers.MaxPool2D(3, 2)(pad4)\n",
    "    aux_clf1 = aux_clf(inception4a)\n",
    "    aux_clf2 = aux_clf(inception4d)\n",
    "    inception5a = inception_module(pool4, 256, 160, 320, 32, 128, 128)\n",
    "    inception5b = inception_module(inception5a, 384, 192, 384, 48, 128, 128)\n",
    "    avg_pool = layers.GlobalAvgPool2D()(inception5b)\n",
    "    dropout = layers.Dropout(0.4)(avg_pool)\n",
    "    preds = layers.Dense(1000, activation='softmax')(dropout)\n",
    "    model = Model(in_layer, [preds, aux_clf1, aux_clf2])\n",
    "    return model\n",
    "model = inception_net()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 inceptionv2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "改进有两点：\n",
    "- 加入BN层，每一层的输出都规范化到N(0,1)的高斯分布\n",
    "- 参考VGG,用两个3x3代替5x5,降低参数量，加速计算"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 inceptionv3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "v3的主要改进点是分解（Factorization），将7x7分解成两个一维的卷积(1x7, 7x1)，3x3同样(1x3, 3x1)。\n",
    "\n",
    "好处：减少参数，加速计算(多余的计算力可以用来加深网络)；把一个卷积拆成两个卷积，使得网络深度进一步增加，增加了网络的非线性表达能力。\n",
    "\n",
    "另外，把输入从224x224变为299x299。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def conv2d_bn(x,filters,num_row,num_col,padding='same',strides=(1,1)):\n",
    "    x = layers.Conv2D(filters,(num_row,num_col),strides=strides,padding=padding,use_bias=False)(x)\n",
    "    x = layers.BatchNormalization(axis=3,scale=False)(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def inceptionv3_net(in_shape=(299,299,3), n_classes=1000):\n",
    "    in_layer = layers.Input(in_shape)\n",
    "    x = conv2d_bn(in_layer, 32, 3, 3, strides=(2, 2), padding='valid')\n",
    "    x = conv2d_bn(x, 32, 3, 3, padding='valid')\n",
    "    x = conv2d_bn(x, 64, 3, 3)\n",
    "    x = layers.MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
    "\n",
    "    x = conv2d_bn(x, 80, 1, 1, padding='valid')\n",
    "    x = conv2d_bn(x, 192, 3, 3, padding='valid')\n",
    "    x = layers.MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
    "    # mixed 0: 35 x 35 x 256\n",
    "    branch1x1 = conv2d_bn(x, 64, 1, 1)\n",
    "\n",
    "    branch5x5 = conv2d_bn(x, 48, 1, 1)\n",
    "    branch5x5 = conv2d_bn(branch5x5, 64, 5, 5)\n",
    "\n",
    "    branch3x3dbl = conv2d_bn(x, 64, 1, 1)\n",
    "    branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n",
    "    branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n",
    "\n",
    "    branch_pool = layers.AveragePooling2D((3, 3),\n",
    "                                          strides=(1, 1),\n",
    "                                          padding='same')(x)\n",
    "    branch_pool = conv2d_bn(branch_pool, 32, 1, 1)\n",
    "    x = layers.concatenate(\n",
    "        [branch1x1, branch5x5, branch3x3dbl, branch_pool],\n",
    "        axis=3,\n",
    "        name='mixed0')\n",
    "\n",
    "    # mixed 1: 35 x 35 x 288\n",
    "    branch1x1 = conv2d_bn(x, 64, 1, 1)\n",
    "\n",
    "    branch5x5 = conv2d_bn(x, 48, 1, 1)\n",
    "    branch5x5 = conv2d_bn(branch5x5, 64, 5, 5)\n",
    "\n",
    "    branch3x3dbl = conv2d_bn(x, 64, 1, 1)\n",
    "    branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n",
    "    branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n",
    "\n",
    "    branch_pool = layers.AveragePooling2D((3, 3),\n",
    "                                          strides=(1, 1),\n",
    "                                          padding='same')(x)\n",
    "    branch_pool = conv2d_bn(branch_pool, 64, 1, 1)\n",
    "    x = layers.concatenate(\n",
    "        [branch1x1, branch5x5, branch3x3dbl, branch_pool],\n",
    "        axis=3,\n",
    "        name='mixed1')\n",
    "\n",
    "    # mixed 2: 35 x 35 x 288\n",
    "    branch1x1 = conv2d_bn(x, 64, 1, 1)\n",
    "\n",
    "    branch5x5 = conv2d_bn(x, 48, 1, 1)\n",
    "    branch5x5 = conv2d_bn(branch5x5, 64, 5, 5)\n",
    "\n",
    "    branch3x3dbl = conv2d_bn(x, 64, 1, 1)\n",
    "    branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n",
    "    branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n",
    "\n",
    "    branch_pool = layers.AveragePooling2D((3, 3),\n",
    "                                          strides=(1, 1),\n",
    "                                          padding='same')(x)\n",
    "    branch_pool = conv2d_bn(branch_pool, 64, 1, 1)\n",
    "    x = layers.concatenate(\n",
    "        [branch1x1, branch5x5, branch3x3dbl, branch_pool],\n",
    "        axis=3,\n",
    "        name='mixed2')\n",
    "    # mixed 3: 17 x 17 x 768\n",
    "    branch3x3 = conv2d_bn(x, 384, 3, 3, strides=(2, 2), padding='valid')\n",
    "\n",
    "    branch3x3dbl = conv2d_bn(x, 64, 1, 1)\n",
    "    branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n",
    "    branch3x3dbl = conv2d_bn(\n",
    "        branch3x3dbl, 96, 3, 3, strides=(2, 2), padding='valid')\n",
    "\n",
    "    branch_pool = layers.MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
    "    x = layers.concatenate(\n",
    "        [branch3x3, branch3x3dbl, branch_pool],\n",
    "        axis=3)\n",
    "    # mixed 4: 17 x 17 x 768\n",
    "    branch1x1 = conv2d_bn(x, 192, 1, 1)\n",
    "\n",
    "    branch7x7 = conv2d_bn(x, 128, 1, 1)\n",
    "    branch7x7 = conv2d_bn(branch7x7, 128, 1, 7)\n",
    "    branch7x7 = conv2d_bn(branch7x7, 192, 7, 1)\n",
    "\n",
    "    branch7x7dbl = conv2d_bn(x, 128, 1, 1)\n",
    "    branch7x7dbl = conv2d_bn(branch7x7dbl, 128, 7, 1)\n",
    "    branch7x7dbl = conv2d_bn(branch7x7dbl, 128, 1, 7)\n",
    "    branch7x7dbl = conv2d_bn(branch7x7dbl, 128, 7, 1)\n",
    "    branch7x7dbl = conv2d_bn(branch7x7dbl, 192, 1, 7)\n",
    "\n",
    "    branch_pool = layers.AveragePooling2D((3, 3),\n",
    "                                          strides=(1, 1),\n",
    "                                          padding='same')(x)\n",
    "    branch_pool = conv2d_bn(branch_pool, 192, 1, 1)\n",
    "    x = layers.concatenate(\n",
    "        [branch1x1, branch7x7, branch7x7dbl, branch_pool],\n",
    "        axis=3)\n",
    "    # mixed 5, 6: 17 x 17 x 768\n",
    "    for i in range(2):\n",
    "        branch1x1 = conv2d_bn(x, 192, 1, 1)\n",
    "\n",
    "        branch7x7 = conv2d_bn(x, 160, 1, 1)\n",
    "        branch7x7 = conv2d_bn(branch7x7, 160, 1, 7)\n",
    "        branch7x7 = conv2d_bn(branch7x7, 192, 7, 1)\n",
    "\n",
    "        branch7x7dbl = conv2d_bn(x, 160, 1, 1)\n",
    "        branch7x7dbl = conv2d_bn(branch7x7dbl, 160, 7, 1)\n",
    "        branch7x7dbl = conv2d_bn(branch7x7dbl, 160, 1, 7)\n",
    "        branch7x7dbl = conv2d_bn(branch7x7dbl, 160, 7, 1)\n",
    "        branch7x7dbl = conv2d_bn(branch7x7dbl, 192, 1, 7)\n",
    "\n",
    "        branch_pool = layers.AveragePooling2D(\n",
    "            (3, 3), strides=(1, 1), padding='same')(x)\n",
    "        branch_pool = conv2d_bn(branch_pool, 192, 1, 1)\n",
    "        x = layers.concatenate(\n",
    "            [branch1x1, branch7x7, branch7x7dbl, branch_pool],\n",
    "            axis=3,\n",
    "            name='mixed' + str(5 + i))\n",
    "    # mixed 7: 17 x 17 x 768\n",
    "    branch1x1 = conv2d_bn(x, 192, 1, 1)\n",
    "\n",
    "    branch7x7 = conv2d_bn(x, 192, 1, 1)\n",
    "    branch7x7 = conv2d_bn(branch7x7, 192, 1, 7)\n",
    "    branch7x7 = conv2d_bn(branch7x7, 192, 7, 1)\n",
    "\n",
    "    branch7x7dbl = conv2d_bn(x, 192, 1, 1)\n",
    "    branch7x7dbl = conv2d_bn(branch7x7dbl, 192, 7, 1)\n",
    "    branch7x7dbl = conv2d_bn(branch7x7dbl, 192, 1, 7)\n",
    "    branch7x7dbl = conv2d_bn(branch7x7dbl, 192, 7, 1)\n",
    "    branch7x7dbl = conv2d_bn(branch7x7dbl, 192, 1, 7)\n",
    "\n",
    "    branch_pool = layers.AveragePooling2D((3, 3),\n",
    "                                          strides=(1, 1),\n",
    "                                          padding='same')(x)\n",
    "    branch_pool = conv2d_bn(branch_pool, 192, 1, 1)\n",
    "    x = layers.concatenate(\n",
    "        [branch1x1, branch7x7, branch7x7dbl, branch_pool],\n",
    "        axis=3,\n",
    "        name='mixed7')\n",
    "\n",
    "    # mixed 8: 8 x 8 x 1280\n",
    "    branch3x3 = conv2d_bn(x, 192, 1, 1)\n",
    "    branch3x3 = conv2d_bn(branch3x3, 320, 3, 3,\n",
    "                          strides=(2, 2), padding='valid')\n",
    "\n",
    "    branch7x7x3 = conv2d_bn(x, 192, 1, 1)\n",
    "    branch7x7x3 = conv2d_bn(branch7x7x3, 192, 1, 7)\n",
    "    branch7x7x3 = conv2d_bn(branch7x7x3, 192, 7, 1)\n",
    "    branch7x7x3 = conv2d_bn(\n",
    "        branch7x7x3, 192, 3, 3, strides=(2, 2), padding='valid')\n",
    "\n",
    "    branch_pool = layers.MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
    "    x = layers.concatenate(\n",
    "        [branch3x3, branch7x7x3, branch_pool],\n",
    "        axis=3,\n",
    "        name='mixed8')\n",
    "\n",
    "    # mixed 9: 8 x 8 x 2048\n",
    "    for i in range(2):\n",
    "        branch1x1 = conv2d_bn(x, 320, 1, 1)\n",
    "\n",
    "        branch3x3 = conv2d_bn(x, 384, 1, 1)\n",
    "        branch3x3_1 = conv2d_bn(branch3x3, 384, 1, 3)\n",
    "        branch3x3_2 = conv2d_bn(branch3x3, 384, 3, 1)\n",
    "        branch3x3 = layers.concatenate(\n",
    "            [branch3x3_1, branch3x3_2],\n",
    "            axis=3,\n",
    "            name='mixed9_' + str(i))\n",
    "\n",
    "        branch3x3dbl = conv2d_bn(x, 448, 1, 1)\n",
    "        branch3x3dbl = conv2d_bn(branch3x3dbl, 384, 3, 3)\n",
    "        branch3x3dbl_1 = conv2d_bn(branch3x3dbl, 384, 1, 3)\n",
    "        branch3x3dbl_2 = conv2d_bn(branch3x3dbl, 384, 3, 1)\n",
    "        branch3x3dbl = layers.concatenate(\n",
    "            [branch3x3dbl_1, branch3x3dbl_2], axis=3)\n",
    "\n",
    "        branch_pool = layers.AveragePooling2D(\n",
    "            (3, 3), strides=(1, 1), padding='same')(x)\n",
    "        branch_pool = conv2d_bn(branch_pool, 192, 1, 1)\n",
    "        x = layers.concatenate(\n",
    "            [branch1x1, branch3x3, branch3x3dbl, branch_pool],\n",
    "            axis=3,\n",
    "            name='mixed' + str(9 + i))\n",
    "    x = layers.GlobalAveragePooling2D(name='avg_pool')(x)\n",
    "    x = layers.Dense(n_classes, activation='softmax', name='predictions')(x)\n",
    "    model = Model(in_layer,x)\n",
    "    return model\n",
    "tf.keras.backend.clear_session()\n",
    "model=inceptionv3_net()\n",
    "#model.summary()\n",
    "#tf.keras.utils.plot_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 InceptionV4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用到了ResNet的残差结构，所以先看一下resnet,再回来看这一部分\n",
    "- [Inception-v4, Inception-ResNet and the Impact of\n",
    "   Residual Connections on Learning](https://arxiv.org/abs/1602.07261) (AAAI 2017)\n",
    "文章中提出Inception v4、Inception-ResNet v1和Inception ResNet v2，主要就是看到ResNet觉得挺好，就拿来和Inception模块结合一下，加shortcut。结构设计比较复杂，繁锁。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#以下是inception resnetv2 code\n",
    "def conv2d_bn(x,\n",
    "              filters,\n",
    "              kernel_size,\n",
    "              strides=1,\n",
    "              padding='same',\n",
    "              activation='relu',\n",
    "              use_bias=False,\n",
    "              name=None):\n",
    "    \"\"\"Utility function to apply conv + BN.\n",
    "    # Arguments\n",
    "        x: input tensor.\n",
    "        filters: filters in `Conv2D`.\n",
    "        kernel_size: kernel size as in `Conv2D`.\n",
    "        strides: strides in `Conv2D`.\n",
    "        padding: padding mode in `Conv2D`.\n",
    "        activation: activation in `Conv2D`.\n",
    "        use_bias: whether to use a bias in `Conv2D`.\n",
    "        name: name of the ops; will become `name + '_ac'` for the activation\n",
    "            and `name + '_bn'` for the batch norm layer.\n",
    "    # Returns\n",
    "        Output tensor after applying `Conv2D` and `BatchNormalization`.\n",
    "    \"\"\"\n",
    "    x = layers.Conv2D(filters,\n",
    "                      kernel_size,\n",
    "                      strides=strides,\n",
    "                      padding=padding,\n",
    "                      use_bias=use_bias,\n",
    "                      name=name)(x)\n",
    "    if not use_bias:\n",
    "        bn_axis = 1 if tf.keras.backend.image_data_format() == 'channels_first' else 3\n",
    "        bn_name = None if name is None else name + '_bn'\n",
    "        x = layers.BatchNormalization(axis=bn_axis,\n",
    "                                      scale=False,\n",
    "                                      name=bn_name)(x)\n",
    "    if activation is not None:\n",
    "        ac_name = None if name is None else name + '_ac'\n",
    "        x = layers.Activation(activation, name=ac_name)(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def inception_resnet_block(x, scale, block_type, block_idx, activation='relu'):\n",
    "    \"\"\"Adds a Inception-ResNet block.\n",
    "    This function builds 3 types of Inception-ResNet blocks mentioned\n",
    "    in the paper, controlled by the `block_type` argument (which is the\n",
    "    block name used in the official TF-slim implementation):\n",
    "        - Inception-ResNet-A: `block_type='block35'`\n",
    "        - Inception-ResNet-B: `block_type='block17'`\n",
    "        - Inception-ResNet-C: `block_type='block8'`\n",
    "    # Arguments\n",
    "        x: input tensor.\n",
    "        scale: scaling factor to scale the residuals (i.e., the output of\n",
    "            passing `x` through an inception module) before adding them\n",
    "            to the shortcut branch.\n",
    "            Let `r` be the output from the residual branch,\n",
    "            the output of this block will be `x + scale * r`.\n",
    "        block_type: `'block35'`, `'block17'` or `'block8'`, determines\n",
    "            the network structure in the residual branch.\n",
    "        block_idx: an `int` used for generating layer names.\n",
    "            The Inception-ResNet blocks\n",
    "            are repeated many times in this network.\n",
    "            We use `block_idx` to identify\n",
    "            each of the repetitions. For example,\n",
    "            the first Inception-ResNet-A block\n",
    "            will have `block_type='block35', block_idx=0`,\n",
    "            and the layer names will have\n",
    "            a common prefix `'block35_0'`.\n",
    "        activation: activation function to use at the end of the block\n",
    "            (see [activations](../activations.md)).\n",
    "            When `activation=None`, no activation is applied\n",
    "            (i.e., \"linear\" activation: `a(x) = x`).\n",
    "    # Returns\n",
    "        Output tensor for the block.\n",
    "    # Raises\n",
    "        ValueError: if `block_type` is not one of `'block35'`,\n",
    "            `'block17'` or `'block8'`.\n",
    "    \"\"\"\n",
    "    if block_type == 'block35':\n",
    "        branch_0 = conv2d_bn(x, 32, 1)\n",
    "        branch_1 = conv2d_bn(x, 32, 1)\n",
    "        branch_1 = conv2d_bn(branch_1, 32, 3)\n",
    "        branch_2 = conv2d_bn(x, 32, 1)\n",
    "        branch_2 = conv2d_bn(branch_2, 48, 3)\n",
    "        branch_2 = conv2d_bn(branch_2, 64, 3)\n",
    "        branches = [branch_0, branch_1, branch_2]\n",
    "    elif block_type == 'block17':\n",
    "        branch_0 = conv2d_bn(x, 192, 1)\n",
    "        branch_1 = conv2d_bn(x, 128, 1)\n",
    "        branch_1 = conv2d_bn(branch_1, 160, [1, 7])\n",
    "        branch_1 = conv2d_bn(branch_1, 192, [7, 1])\n",
    "        branches = [branch_0, branch_1]\n",
    "    elif block_type == 'block8':\n",
    "        branch_0 = conv2d_bn(x, 192, 1)\n",
    "        branch_1 = conv2d_bn(x, 192, 1)\n",
    "        branch_1 = conv2d_bn(branch_1, 224, [1, 3])\n",
    "        branch_1 = conv2d_bn(branch_1, 256, [3, 1])\n",
    "        branches = [branch_0, branch_1]\n",
    "    else:\n",
    "        raise ValueError('Unknown Inception-ResNet block type. '\n",
    "                         'Expects \"block35\", \"block17\" or \"block8\", '\n",
    "                         'but got: ' + str(block_type))\n",
    "\n",
    "    block_name = block_type + '_' + str(block_idx)\n",
    "    channel_axis = 1 if tf.keras.backend.image_data_format() == 'channels_first' else 3\n",
    "    mixed = layers.Concatenate(\n",
    "        axis=channel_axis, name=block_name + '_mixed')(branches)\n",
    "    up = conv2d_bn(mixed,\n",
    "                   tf.keras.backend.int_shape(x)[channel_axis],\n",
    "                   1,\n",
    "                   activation=None,\n",
    "                   use_bias=True,\n",
    "                   name=block_name + '_conv')\n",
    "\n",
    "    x = layers.Lambda(lambda inputs, scale: inputs[0] + inputs[1] * scale,\n",
    "                      output_shape=tf.keras.backend.int_shape(x)[1:],\n",
    "                      arguments={'scale': scale},\n",
    "                      name=block_name)([x, up])\n",
    "    if activation is not None:\n",
    "        x = layers.Activation(activation, name=block_name + '_ac')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def InceptionResNetV2(input_shape=(299,299,3),\n",
    "                      classes=1000):\n",
    "    \"\"\"Instantiates the Inception-ResNet v2 architecture.\n",
    "    Optionally loads weights pre-trained on ImageNet.\n",
    "    Note that the data format convention used by the model is\n",
    "    the one specified in your Keras config at `~/.keras/keras.json`.\n",
    "    # Arguments\n",
    "        \n",
    "        input_shape: optional shape tuple, only to be specified\n",
    "            if `include_top` is `False` (otherwise the input shape\n",
    "            has to be `(299, 299, 3)` (with `'channels_last'` data format)\n",
    "            or `(3, 299, 299)` (with `'channels_first'` data format).\n",
    "            It should have exactly 3 inputs channels,\n",
    "            and width and height should be no smaller than 75.\n",
    "            E.g. `(150, 150, 3)` would be one valid value.\n",
    "        \n",
    "        classes: optional number of classes to classify images\n",
    "            into, only to be specified if `include_top` is `True`, and\n",
    "            if no `weights` argument is specified.\n",
    "    # Returns\n",
    "        A Keras `Model` instance.\n",
    "    # Raises\n",
    "        ValueError: in case of invalid argument for `weights`,\n",
    "            or invalid input shape.\n",
    "    \"\"\"\n",
    "   \n",
    "    img_input = layers.Input(shape=input_shape)\n",
    "    \n",
    "    # Stem block: 35 x 35 x 192\n",
    "    x = conv2d_bn(img_input, 32, 3, strides=2, padding='valid')\n",
    "    x = conv2d_bn(x, 32, 3, padding='valid')\n",
    "    x = conv2d_bn(x, 64, 3)\n",
    "    x = layers.MaxPooling2D(3, strides=2)(x)\n",
    "    x = conv2d_bn(x, 80, 1, padding='valid')\n",
    "    x = conv2d_bn(x, 192, 3, padding='valid')\n",
    "    x = layers.MaxPooling2D(3, strides=2)(x)\n",
    "\n",
    "    # Mixed 5b (Inception-A block): 35 x 35 x 320\n",
    "    branch_0 = conv2d_bn(x, 96, 1)\n",
    "    branch_1 = conv2d_bn(x, 48, 1)\n",
    "    branch_1 = conv2d_bn(branch_1, 64, 5)\n",
    "    branch_2 = conv2d_bn(x, 64, 1)\n",
    "    branch_2 = conv2d_bn(branch_2, 96, 3)\n",
    "    branch_2 = conv2d_bn(branch_2, 96, 3)\n",
    "    branch_pool = layers.AveragePooling2D(3, strides=1, padding='same')(x)\n",
    "    branch_pool = conv2d_bn(branch_pool, 64, 1)\n",
    "    branches = [branch_0, branch_1, branch_2, branch_pool]\n",
    "    channel_axis = 1 if tf.keras.backend.image_data_format() == 'channels_first' else 3\n",
    "    x = layers.Concatenate(axis=channel_axis, name='mixed_5b')(branches)\n",
    "\n",
    "    # 10x block35 (Inception-ResNet-A block): 35 x 35 x 320\n",
    "    for block_idx in range(1, 11):\n",
    "        x = inception_resnet_block(x,\n",
    "                                   scale=0.17,\n",
    "                                   block_type='block35',\n",
    "                                   block_idx=block_idx)\n",
    "\n",
    "    # Mixed 6a (Reduction-A block): 17 x 17 x 1088\n",
    "    branch_0 = conv2d_bn(x, 384, 3, strides=2, padding='valid')\n",
    "    branch_1 = conv2d_bn(x, 256, 1)\n",
    "    branch_1 = conv2d_bn(branch_1, 256, 3)\n",
    "    branch_1 = conv2d_bn(branch_1, 384, 3, strides=2, padding='valid')\n",
    "    branch_pool = layers.MaxPooling2D(3, strides=2, padding='valid')(x)\n",
    "    branches = [branch_0, branch_1, branch_pool]\n",
    "    x = layers.Concatenate(axis=channel_axis, name='mixed_6a')(branches)\n",
    "\n",
    "    # 20x block17 (Inception-ResNet-B block): 17 x 17 x 1088\n",
    "    for block_idx in range(1, 21):\n",
    "        x = inception_resnet_block(x,\n",
    "                                   scale=0.1,\n",
    "                                   block_type='block17',\n",
    "                                   block_idx=block_idx)\n",
    "\n",
    "    # Mixed 7a (Reduction-B block): 8 x 8 x 2080\n",
    "    branch_0 = conv2d_bn(x, 256, 1)\n",
    "    branch_0 = conv2d_bn(branch_0, 384, 3, strides=2, padding='valid')\n",
    "    branch_1 = conv2d_bn(x, 256, 1)\n",
    "    branch_1 = conv2d_bn(branch_1, 288, 3, strides=2, padding='valid')\n",
    "    branch_2 = conv2d_bn(x, 256, 1)\n",
    "    branch_2 = conv2d_bn(branch_2, 288, 3)\n",
    "    branch_2 = conv2d_bn(branch_2, 320, 3, strides=2, padding='valid')\n",
    "    branch_pool = layers.MaxPooling2D(3, strides=2, padding='valid')(x)\n",
    "    branches = [branch_0, branch_1, branch_2, branch_pool]\n",
    "    x = layers.Concatenate(axis=channel_axis, name='mixed_7a')(branches)\n",
    "\n",
    "    # 10x block8 (Inception-ResNet-C block): 8 x 8 x 2080\n",
    "    for block_idx in range(1, 10):\n",
    "        x = inception_resnet_block(x,\n",
    "                                   scale=0.2,\n",
    "                                   block_type='block8',\n",
    "                                   block_idx=block_idx)\n",
    "    x = inception_resnet_block(x,\n",
    "                               scale=1.,\n",
    "                               activation=None,\n",
    "                               block_type='block8',\n",
    "                               block_idx=10)\n",
    "\n",
    "    # Final convolution block: 8 x 8 x 1536\n",
    "    x = conv2d_bn(x, 1536, 1, name='conv_7b')\n",
    "\n",
    "    \n",
    "    x = layers.GlobalAveragePooling2D(name='avg_pool')(x)\n",
    "    x = layers.Dense(classes, activation='softmax', name='predictions')(x)\n",
    "    \n",
    "    model = Model(img_input, x, name='inception_resnet_v2')\n",
    "\n",
    "    \n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = InceptionResNetV2()\n",
    "#model.summary()\n",
    "#tf.keras.utils.plot_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.ResNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ResNet有效的原因：\n",
    "\n",
    "- 网络加深之后很容易发生梯度消失问题。残差网络的跳远连接部分保证了网络后面的梯度可以更加方便地传到网络前面，因此可以有效减轻梯度消失问题，使得网络更容易训练。\n",
    "- 另一种理解的角度是，ResNet类似于很多神经网络的集成，比如删除网络中的某个residual block，对网络最终的performance不会有太大影响，这和bagging集成时删除某个基学习器很相似。作为对照，删除VGG16中的某个模块就会对最终表现有很大影响。模型集成可以提高模型的表现。\n",
    "- 还有一种理解的角度是，加入跳远连接，网络的卷积层学习的是残差，而不是整个映射，这样网络的学习压力就减轻了很多，因此可以学得很好。\n",
    "- 还有一种理解的角度是，数据中冗余度比较低的部分可以通过跳远连接得到保留，卷积层集中力量学习冗余度比较高的部分。因此在参数相同的情况下ResNet可以学得更好。\n",
    "关于ResNet的说明参照[说明](\"https://zhuanlan.zhihu.com/p/80226180\")\n",
    "关于ResNet两个版本的对比参照[说明](\"https://blog.csdn.net/chenyuping333/article/details/82344334\")，现有资料很多，这里就不再缀述了\n",
    "\n",
    "- [Deep Residual Learning for Image Recognition]\n",
    "  (https://arxiv.org/abs/1512.03385) (CVPR 2016 Best Paper Award)\n",
    "- [Identity Mappings in Deep Residual Networks]\n",
    "  (https://arxiv.org/abs/1603.05027) (ECCV 2016)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 ResNet V1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _after_conv_relu(in_tensor):\n",
    "    norm=layers.BatchNormalization()(in_tensor)\n",
    "    return layers.Activation('relu')(norm)\n",
    "def _after_conv(in_tensor):\n",
    "    norm=layers.BatchNormalization()(in_tensor)\n",
    "    return norm\n",
    "def conv1(in_tensor,filters):\n",
    "    conv =layers.Conv2D(filters,kernel_size=1,strides=1)(in_tensor)\n",
    "    return _after_conv(conv)\n",
    "def conv1_downsample(in_tensor,filters):\n",
    "    conv=layers.Conv2D(filters,kernel_size=1,strides=2)(in_tensor)\n",
    "    return _after_conv(conv)\n",
    "def conv1_relu(in_tensor,filters):\n",
    "    conv =layers.Conv2D(filters,kernel_size=1,strides=1)(in_tensor)\n",
    "    return _after_conv_relu(conv)\n",
    "def conv1_downsample_relu(in_tensor,filters):\n",
    "    conv=layers.Conv2D(filters,kernel_size=1,strides=2)(in_tensor)\n",
    "    return _after_conv_relu(conv)\n",
    "def conv3(in_tensor,filters):\n",
    "    conv=layers.Conv2D(filters,kernel_size=3,strides=1,padding='same')(in_tensor)\n",
    "    return _after_conv(conv)\n",
    "def conv3_downsample(in_tensor,filters):\n",
    "    conv=layers.Conv2D(filters,kernel_size=3,strides=2,padding='same')(in_tensor)\n",
    "    return _after_conv(conv)\n",
    "def conv3_relu(in_tensor,filters):\n",
    "    conv=layers.Conv2D(filters,kernel_size=3,strides=1,padding='same')(in_tensor)\n",
    "    return _after_conv(conv)\n",
    "def conv3_downsample_relu(in_tensor,filters):\n",
    "    conv=layers.Conv2D(filters,kernel_size=3,strides=2,padding='same')(in_tensor)\n",
    "    return _after_conv(conv)\n",
    "def resnet_block_wo_bottlneck(in_tensor,filters,downsample=False):\n",
    "    if downsample:\n",
    "        conv1_rb = conv3_downsample_relu(in_tensor,filters)\n",
    "    else:\n",
    "        conv1_rb = conv3_relu(in_tensor,filters)\n",
    "    conv2_rb = conv3(conv1_rb,filters)\n",
    "    if downsample:\n",
    "        in_tensor = conv1_downsample(in_tensor,filters)\n",
    "    result = layers.Add()([conv2_rb,in_tensor])\n",
    "    return layers.Activation('relu')(result)\n",
    "def resnet_block_w_bottlneck(in_tensor,filters,downsample=False,change_channels=False):\n",
    "    if downsample:\n",
    "        conv1_rb = conv1_downsample_relu(in_tensor,int(filters/4))\n",
    "    else:\n",
    "        conv1_rb = conv1_relu(in_tensor,int(filters/4))\n",
    "    conv2_rb = conv3_relu(conv1_rb,int(filters/4))\n",
    "    conv3_rb = conv1(conv2_rb,filters)\n",
    "    if downsample:\n",
    "        in_tensor=conv1_downsample(in_tensor,filters)\n",
    "    elif change_channels:\n",
    "        in_tensor=conv1(in_tensor,filters)\n",
    "    result = layers.Add()([conv3_rb,in_tensor])\n",
    "    return layers.Activation('relu')(result)\n",
    "def _pre_res_blocks(in_tensor):\n",
    "    conv = layers.Conv2D(64,7,strides=2,padding='same')(in_tensor)\n",
    "    conv = _after_conv(conv)\n",
    "    pool = layers.MaxPool2D(3,2,padding='same')(conv)\n",
    "    return pool\n",
    "def _post_res_blocks(in_tensor,n_classes):\n",
    "    pool = layers.GlobalAvgPool2D()(in_tensor)\n",
    "    preds = layers.Dense(n_classes,activation='softmax')(pool)\n",
    "    return preds\n",
    "def convx_wo_bottleneck(in_tensor,filters,n_times,downsample_1=False):\n",
    "    res=in_tensor\n",
    "    for i in range(n_times):\n",
    "        if i==0:\n",
    "            res=resnet_block_wo_bottlneck(res,filters,downsample_1)\n",
    "        else:\n",
    "            res=resnet_block_wo_bottlneck(res,filters)\n",
    "    return res\n",
    "def convx_w_bottleneck(in_tensor,filters,n_times,downsample_1=False):\n",
    "    res=in_tensor\n",
    "    for i in range(n_times):\n",
    "        if i==0:\n",
    "            res=resnet_block_w_bottlneck(res,filters,downsample_1,not downsample_1)\n",
    "        else:\n",
    "            res=resnet_block_w_bottlneck(res,filters)\n",
    "    return res\n",
    "def _resnet(in_shape=(224,224,3),n_classes=1000,convx=[64,128,256,512],n_convx=[2,2,2,2],convx_fn=convx_wo_bottleneck):\n",
    "    in_layer = layers.Input(in_shape)\n",
    "    downsampled = _pre_res_blocks(in_layer)\n",
    "    conv2x = convx_fn(downsampled,convx[0],n_convx[0])\n",
    "    conv3x = convx_fn(conv2x,convx[1],n_convx[1],True)\n",
    "    conv4x = convx_fn(conv3x,convx[2],n_convx[2],True)\n",
    "    conv5x = convx_fn(conv4x,convx[3],n_convx[3],True)\n",
    "    preds = _post_res_blocks(conv5x,n_classes)\n",
    "    model =Model(in_layer,preds)\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet18(in_shape=(224,224,3),n_classes=1000):\n",
    "    return _resnet(in_shape,n_classes)\n",
    "def resnet34(in_shape=(224,224,3),n_classes=1000):\n",
    "    return _resnet(in_shape,n_classes,n_convx=[3,4,6,3])\n",
    "def resnet50(in_shape=(224,224,3),n_classes=1000):\n",
    "    return _resnet(in_shape,n_classes,convx=[256,512,1024,2048],n_convx=[3,4,6,3],convx_fn=convx_w_bottleneck)\n",
    "def resnet101(in_shape=(224,224,3),n_classes=1000):\n",
    "    return _resnet(in_shape,n_classes,convx=[256,512,1024,2048],n_convx=[3,4,23,3],convx_fn=convx_w_bottleneck)\n",
    "def resnet152(in_shape=(224,224,3),n_classes=1000):\n",
    "    return _resnet(in_shape,n_classes,convx=[256,512,1024,2048],n_convx=[3,8,36,3],convx_fn=convx_w_bottleneck)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = resnet18()\n",
    "#model.summary()\n",
    "#tf.keras.utils.plot_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Resnet V2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resnet v2改动要是改动residual path,identify path不变。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def block2(x, filters, kernel_size=3, stride=1,\n",
    "           conv_shortcut=False, name=None):\n",
    "    \"\"\"A residual block.\n",
    "    # Arguments\n",
    "        x: input tensor.\n",
    "        filters: integer, filters of the bottleneck layer.\n",
    "        kernel_size: default 3, kernel size of the bottleneck layer.\n",
    "        stride: default 1, stride of the first layer.\n",
    "        conv_shortcut: default False, use convolution shortcut if True,\n",
    "            otherwise identity shortcut.\n",
    "        name: string, block label.\n",
    "    # Returns\n",
    "        Output tensor for the residual block.\n",
    "    \"\"\"\n",
    "    bn_axis = 3 if tf.keras.backend.image_data_format() == 'channels_last' else 1\n",
    "\n",
    "    preact = layers.BatchNormalization(axis=bn_axis, epsilon=1.001e-5,\n",
    "                                       name=name + '_preact_bn')(x)\n",
    "    preact = layers.Activation('relu', name=name + '_preact_relu')(preact)\n",
    "\n",
    "    if conv_shortcut is True:\n",
    "        shortcut = layers.Conv2D(4 * filters, 1, strides=stride,\n",
    "                                 name=name + '_0_conv')(preact)\n",
    "    else:\n",
    "        shortcut = layers.MaxPooling2D(1, strides=stride)(x) if stride > 1 else x\n",
    "\n",
    "    x = layers.Conv2D(filters, 1, strides=1, use_bias=False,\n",
    "                      name=name + '_1_conv')(preact)\n",
    "    x = layers.BatchNormalization(axis=bn_axis, epsilon=1.001e-5,\n",
    "                                  name=name + '_1_bn')(x)\n",
    "    x = layers.Activation('relu', name=name + '_1_relu')(x)\n",
    "\n",
    "    x = layers.ZeroPadding2D(padding=((1, 1), (1, 1)), name=name + '_2_pad')(x)\n",
    "    x = layers.Conv2D(filters, kernel_size, strides=stride,\n",
    "                      use_bias=False, name=name + '_2_conv')(x)\n",
    "    x = layers.BatchNormalization(axis=bn_axis, epsilon=1.001e-5,\n",
    "                                  name=name + '_2_bn')(x)\n",
    "    x = layers.Activation('relu', name=name + '_2_relu')(x)\n",
    "\n",
    "    x = layers.Conv2D(4 * filters, 1, name=name + '_3_conv')(x)\n",
    "    x = layers.Add(name=name + '_out')([shortcut, x])\n",
    "    return x\n",
    "\n",
    "\n",
    "def stack2(x, filters, blocks, stride1=2, name=None):\n",
    "    \"\"\"A set of stacked residual blocks.\n",
    "    # Arguments\n",
    "        x: input tensor.\n",
    "        filters: integer, filters of the bottleneck layer in a block.\n",
    "        blocks: integer, blocks in the stacked blocks.\n",
    "        stride1: default 2, stride of the first layer in the first block.\n",
    "        name: string, stack label.\n",
    "    # Returns\n",
    "        Output tensor for the stacked blocks.\n",
    "    \"\"\"\n",
    "    x = block2(x, filters, conv_shortcut=True, name=name + '_block1')\n",
    "    for i in range(2, blocks):\n",
    "        x = block2(x, filters, name=name + '_block' + str(i))\n",
    "    x = block2(x, filters, stride=stride1, name=name + '_block' + str(blocks))\n",
    "    return x\n",
    "\n",
    "def ResNet(stack_fn,\n",
    "           preact,\n",
    "           use_bias,\n",
    "           model_name='resnet',\n",
    "           input_shape=None,\n",
    "           classes=1000):\n",
    "\n",
    "\n",
    "  \n",
    "    img_input = layers.Input(shape=input_shape)\n",
    "\n",
    "\n",
    "    bn_axis = 3 if tf.keras.backend.image_data_format() == 'channels_last' else 1\n",
    "\n",
    "    x = layers.ZeroPadding2D(padding=((3, 3), (3, 3)), name='conv1_pad')(img_input)\n",
    "    x = layers.Conv2D(64, 7, strides=2, use_bias=use_bias, name='conv1_conv')(x)\n",
    "\n",
    "    x = layers.ZeroPadding2D(padding=((1, 1), (1, 1)), name='pool1_pad')(x)\n",
    "    x = layers.MaxPooling2D(3, strides=2, name='pool1_pool')(x)\n",
    "\n",
    "    x = stack_fn(x)\n",
    "\n",
    "    if preact is True:\n",
    "        x = layers.BatchNormalization(axis=bn_axis, epsilon=1.001e-5,\n",
    "                                      name='post_bn')(x)\n",
    "        x = layers.Activation('relu', name='post_relu')(x)\n",
    "\n",
    " \n",
    "    x = layers.GlobalAveragePooling2D(name='avg_pool')(x)\n",
    "    x = layers.Dense(classes, activation='softmax', name='probs')(x)\n",
    "    \n",
    "    # Create model.\n",
    "    model = Model(img_input, x, name=model_name)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def ResNet50V2(input_shape=(224,224,3),classes=1000):\n",
    "    def stack_fn(x):\n",
    "        x = stack2(x, 64, 3, name='conv2')\n",
    "        x = stack2(x, 128, 4, name='conv3')\n",
    "        x = stack2(x, 256, 6, name='conv4')\n",
    "        x = stack2(x, 512, 3, stride1=1, name='conv5')\n",
    "        return x\n",
    "    return ResNet(stack_fn, True, True, 'resnet50v2',\n",
    "                  input_shape,classes)\n",
    "\n",
    "\n",
    "def ResNet101V2(input_shape=(224,224,3),classes=1000):\n",
    "    def stack_fn(x):\n",
    "        x = stack2(x, 64, 3, name='conv2')\n",
    "        x = stack2(x, 128, 4, name='conv3')\n",
    "        x = stack2(x, 256, 23, name='conv4')\n",
    "        x = stack2(x, 512, 3, stride1=1, name='conv5')\n",
    "        return x\n",
    "    return ResNet(stack_fn, True, True, 'resnet101v2',\n",
    "                  input_shape,classes)\n",
    "\n",
    "\n",
    "def ResNet152V2(input_shape=(224,224,3),classes=1000):\n",
    "    def stack_fn(x):\n",
    "        x = stack2(x, 64, 3, name='conv2')\n",
    "        x = stack2(x, 128, 8, name='conv3')\n",
    "        x = stack2(x, 256, 36, name='conv4')\n",
    "        x = stack2(x, 512, 3, stride1=1, name='conv5')\n",
    "        return x\n",
    "    return ResNet(stack_fn, True, True, 'resnet152v2',\n",
    "                  input_shape,classes)\n",
    "\n",
    "\n",
    "model=ResNet50V2()\n",
    "#model.summary()\n",
    "#tf.keras.utils.plot_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.ResNeXt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Aggregated Residual Transformations for Deep Neural Networks]\n",
    "  (https://arxiv.org/abs/1611.05431) (CVPR 2017)\n",
    "接着ResNet来研究\n",
    "中心思想：Inception那边把ResNet拿来搞了Inception-ResNet，这头ResNet也把Inception拿来搞了一个ResNeXt， 主要就是单路卷积变成多个支路的多路卷积，不过分组很多，结构一致，进行分组卷积。不同于Inceptionv4,ResNext不需要人工设计复杂的Inception结构细节，而是每一个分支都采用相同的拓扑结构。ResNeXt的本质是分组卷积（Group Convolution），通过变量基数（Cardinality）来控制组的数量。组卷机是普通卷积和深度可分离卷积的一个折中方案，即每个分支产生的Feature Map的通道数为 。关于更多的说明[参考](https://zhuanlan.zhihu.com/p/51075096)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ResNeXt确实比Inception V4的超参数更少，但是他直接废除了Inception的囊括不同感受野的特性仿佛不是很合理，在更多的环境中我们发现Inception V4的效果是优于ResNeXt的。类似结构的ResNeXt的运行速度应该是优于Inception V4的，因为ResNeXt的相同拓扑结构的分支的设计是更符合GPU的硬件设计原则.以下代码提供了一种用depwise convlution实现group convolution的方法，想起来有些困难。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def block3(x, filters, kernel_size=3, stride=1, groups=32,\n",
    "           conv_shortcut=True, name=None):\n",
    "    \"\"\"A residual block.\n",
    "    # Arguments\n",
    "        x: input tensor.\n",
    "        filters: integer, filters of the bottleneck layer.\n",
    "        kernel_size: default 3, kernel size of the bottleneck layer.\n",
    "        stride: default 1, stride of the first layer.\n",
    "        groups: default 32, group size for grouped convolution.\n",
    "        conv_shortcut: default True, use convolution shortcut if True,\n",
    "            otherwise identity shortcut.\n",
    "        name: string, block label.\n",
    "    # Returns\n",
    "        Output tensor for the residual block.\n",
    "    \"\"\"\n",
    "    bn_axis = 3 \n",
    "\n",
    "    if conv_shortcut is True:\n",
    "        shortcut = layers.Conv2D((64 // groups) * filters, 1, strides=stride,\n",
    "                                 use_bias=False, name=name + '_0_conv')(x)\n",
    "        shortcut = layers.BatchNormalization(axis=bn_axis, epsilon=1.001e-5,\n",
    "                                             name=name + '_0_bn')(shortcut)\n",
    "    else:\n",
    "        shortcut = x\n",
    "    x = layers.Conv2D(filters, 1, use_bias=False, name=name + '_1_conv')(x)\n",
    "    x = layers.BatchNormalization(axis=bn_axis, epsilon=1.001e-5,\n",
    "                                  name=name + '_1_bn')(x)\n",
    "    x = layers.Activation('relu', name=name + '_1_relu')(x)\n",
    "\n",
    "    c = filters // groups\n",
    "    x = layers.ZeroPadding2D(padding=((1, 1), (1, 1)), name=name + '_2_pad')(x)\n",
    "    x = layers.DepthwiseConv2D(kernel_size, strides=stride, depth_multiplier=c,\n",
    "                               use_bias=False, name=name + '_2_conv')(x)\n",
    "    kernel = np.zeros((1, 1, filters * c, filters), dtype=np.float32)\n",
    "    for i in range(filters):\n",
    "        start = (i // c) * c * c + i % c\n",
    "        end = start + c * c\n",
    "        kernel[:, :, start:end:c, i] = 1.\n",
    "    x = layers.Conv2D(filters, 1, use_bias=False, trainable=False,\n",
    "                      kernel_initializer={'class_name': 'Constant',\n",
    "                                          'config': {'value': kernel}},\n",
    "                      name=name + '_2_gconv')(x)\n",
    "    x = layers.BatchNormalization(axis=bn_axis, epsilon=1.001e-5,\n",
    "                                  name=name + '_2_bn')(x)\n",
    "    x = layers.Activation('relu', name=name + '_2_relu')(x)\n",
    "\n",
    "    x = layers.Conv2D((64 // groups) * filters, 1,\n",
    "                      use_bias=False, name=name + '_3_conv')(x)\n",
    "    x = layers.BatchNormalization(axis=bn_axis, epsilon=1.001e-5,\n",
    "                                  name=name + '_3_bn')(x)\n",
    "\n",
    "    x = layers.Add(name=name + '_add')([shortcut, x])\n",
    "    x = layers.Activation('relu', name=name + '_out')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def stack3(x, filters, blocks, stride1=2, groups=32, name=None):\n",
    "    \"\"\"A set of stacked residual blocks.\n",
    "    # Arguments\n",
    "        x: input tensor.\n",
    "        filters: integer, filters of the bottleneck layer in a block.\n",
    "        blocks: integer, blocks in the stacked blocks.\n",
    "        stride1: default 2, stride of the first layer in the first block.\n",
    "        groups: default 32, group size for grouped convolution.\n",
    "        name: string, stack label.\n",
    "    # Returns\n",
    "        Output tensor for the stacked blocks.\n",
    "    \"\"\"\n",
    "    x = block3(x, filters, stride=stride1, groups=groups, name=name + '_block1')\n",
    "    for i in range(2, blocks + 1):\n",
    "        x = block3(x, filters, groups=groups, conv_shortcut=False,\n",
    "                   name=name + '_block' + str(i))\n",
    "    return x\n",
    "\n",
    "\n",
    "def ResNet(stack_fn,\n",
    "           model_name='resnet',\n",
    "           input_shape=None,\n",
    "           classes=1000):\n",
    "   \n",
    "    print(input_shape)\n",
    "    img_input = layers.Input(shape=input_shape)\n",
    "    \n",
    "\n",
    "    bn_axis = 3 \n",
    "    \n",
    "    x = layers.ZeroPadding2D(padding=((3, 3), (3, 3)), name='conv1_pad')(img_input)\n",
    "    x = layers.Conv2D(64, 7, strides=2, use_bias=False, name='conv1_conv')(x)\n",
    "\n",
    "    \n",
    "    x = layers.BatchNormalization(axis=bn_axis, epsilon=1.001e-5,\n",
    "                                  name='conv1_bn')(x)\n",
    "    x = layers.Activation('relu', name='conv1_relu')(x)\n",
    "\n",
    "    x = layers.ZeroPadding2D(padding=((1, 1), (1, 1)), name='pool1_pad')(x)\n",
    "    x = layers.MaxPooling2D(3, strides=2, name='pool1_pool')(x)\n",
    "\n",
    "    x = stack_fn(x)  \n",
    "\n",
    "  \n",
    "    x = layers.GlobalAveragePooling2D(name='avg_pool')(x)\n",
    "    x = layers.Dense(classes, activation='softmax', name='probs')(x)\n",
    "    \n",
    "    # Create model.\n",
    "    model = Model(img_input, x, name=model_name)\n",
    "\n",
    "   \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNeXt50(input_shape=(224,224,3),classes=1000):\n",
    "    def stack_fn(x):\n",
    "        x = stack3(x, 128, 3, stride1=1, name='conv2')\n",
    "        x = stack3(x, 256, 4, name='conv3')\n",
    "        x = stack3(x, 512, 6, name='conv4')\n",
    "        x = stack3(x, 1024, 3, name='conv5')\n",
    "        return x\n",
    "    return ResNet(stack_fn, 'resnext50', input_shape,classes)\n",
    "\n",
    "\n",
    "def ResNeXt101(input_shape=(224,224,3),classes=1000):\n",
    "    def stack_fn(x):\n",
    "        x = stack3(x, 128, 3, stride1=1, name='conv2')\n",
    "        x = stack3(x, 256, 4, name='conv3')\n",
    "        x = stack3(x, 512, 23, name='conv4')\n",
    "        x = stack3(x, 1024, 3, name='conv5')\n",
    "        return x\n",
    "    return ResNet(stack_fn, 'resnext101', input_shape,classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=ResNeXt50()\n",
    "#model.summary()\n",
    "#tf.keras.utils.plot_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.Densenet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Densely Connected Convolutional Networks]\n",
    "  (https://arxiv.org/abs/1608.06993) (CVPR 2017 Best Paper Award)\n",
    " CNN史上的一个里程碑事件是ResNet模型的出现，ResNet可以训练出更深的CNN模型，从而实现更高的准确度。ResNet模型的核心是通过建立前面层与后面层之间的“短路连接”（shortcuts，skip connection），这有助于训练过程中梯度的反向传播，从而能训练出更深的CNN网络。今天我们要介绍的是DenseNet模型，它的基本思路与ResNet一致，但是它建立的是前面所有层与后面层的密集连接（dense connection），它的名称也是由此而来。DenseNet的另一大特色是通过特征在channel上的连接来实现特征重用（feature reuse）。这些特点让DenseNet在参数和计算成本更少的情形下实现比ResNet更优的性能.详细介绍[参考](https://zhuanlan.zhihu.com/p/37189203).这个网络没有ResNet出名。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense_block(x, blocks, name):\n",
    "    \"\"\"A dense block.\n",
    "    # Arguments\n",
    "        x: input tensor.\n",
    "        blocks: integer, the number of building blocks.\n",
    "        name: string, block label.\n",
    "    # Returns\n",
    "        output tensor for the block.\n",
    "    \"\"\"\n",
    "    for i in range(blocks):\n",
    "        x = conv_block(x, 32, name=name + '_block' + str(i + 1))\n",
    "    return x\n",
    "\n",
    "\n",
    "def transition_block(x, reduction, name):\n",
    "    \"\"\"A transition block.\n",
    "    # Arguments\n",
    "        x: input tensor.\n",
    "        reduction: float, compression rate at transition layers.\n",
    "        name: string, block label.\n",
    "    # Returns\n",
    "        output tensor for the block.\n",
    "    \"\"\"\n",
    "    bn_axis = 3 if tf.keras.backend.image_data_format() == 'channels_last' else 1\n",
    "    x = layers.BatchNormalization(axis=bn_axis, epsilon=1.001e-5,\n",
    "                                  name=name + '_bn')(x)\n",
    "    x = layers.Activation('relu', name=name + '_relu')(x)\n",
    "    x = layers.Conv2D(int(tf.keras.backend.int_shape(x)[bn_axis] * reduction), 1,\n",
    "                      use_bias=False,\n",
    "                      name=name + '_conv')(x)\n",
    "    x = layers.AveragePooling2D(2, strides=2, name=name + '_pool')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def conv_block(x, growth_rate, name):\n",
    "    \"\"\"A building block for a dense block.\n",
    "    # Arguments\n",
    "        x: input tensor.\n",
    "        growth_rate: float, growth rate at dense layers.\n",
    "        name: string, block label.\n",
    "    # Returns\n",
    "        Output tensor for the block.\n",
    "    \"\"\"\n",
    "    bn_axis = 3 if tf.keras.backend.image_data_format() == 'channels_last' else 1\n",
    "    x1 = layers.BatchNormalization(axis=bn_axis,\n",
    "                                   epsilon=1.001e-5,\n",
    "                                   name=name + '_0_bn')(x)\n",
    "    x1 = layers.Activation('relu', name=name + '_0_relu')(x1)\n",
    "    x1 = layers.Conv2D(4 * growth_rate, 1,\n",
    "                       use_bias=False,\n",
    "                       name=name + '_1_conv')(x1)\n",
    "    x1 = layers.BatchNormalization(axis=bn_axis, epsilon=1.001e-5,\n",
    "                                   name=name + '_1_bn')(x1)\n",
    "    x1 = layers.Activation('relu', name=name + '_1_relu')(x1)\n",
    "    x1 = layers.Conv2D(growth_rate, 3,\n",
    "                       padding='same',\n",
    "                       use_bias=False,\n",
    "                       name=name + '_2_conv')(x1)\n",
    "    x = layers.Concatenate(axis=bn_axis, name=name + '_concat')([x, x1])\n",
    "    return x\n",
    "\n",
    "\n",
    "def DenseNet(blocks,\n",
    "             input_shape=(224,224,3),\n",
    "             classes=1000):\n",
    "    \"\"\"Instantiates the DenseNet architecture.\n",
    "    Optionally loads weights pre-trained on ImageNet.\n",
    "    Note that the data format convention used by the model is\n",
    "    the one specified in your Keras config at `~/.keras/keras.json`.\n",
    "    # Arguments\n",
    "        blocks: numbers of building blocks for the four dense layers.\n",
    "        \n",
    "        input_shape: optional shape tuple, only to be specified\n",
    "            if `include_top` is False (otherwise the input shape\n",
    "            has to be `(224, 224, 3)` (with `'channels_last'` data format)\n",
    "            or `(3, 224, 224)` (with `'channels_first'` data format).\n",
    "            It should have exactly 3 inputs channels,\n",
    "            and width and height should be no smaller than 32.\n",
    "            E.g. `(200, 200, 3)` would be one valid value.\n",
    "        \n",
    "        classes: optional number of classes to classify images\n",
    "            into, only to be specified if `include_top` is True, and\n",
    "            if no `weights` argument is specified.\n",
    "    # Returns\n",
    "        A Keras model instance.\n",
    "    # Raises\n",
    "        ValueError: in case of invalid argument for `weights`,\n",
    "            or invalid input shape.\n",
    "    \"\"\"\n",
    "   \n",
    "    img_input = layers.Input(shape=input_shape)\n",
    "    \n",
    "    bn_axis = 3 if tf.keras.backend.image_data_format() == 'channels_last' else 1\n",
    "\n",
    "    x = layers.ZeroPadding2D(padding=((3, 3), (3, 3)))(img_input)\n",
    "    x = layers.Conv2D(64, 7, strides=2, use_bias=False, name='conv1/conv')(x)\n",
    "    x = layers.BatchNormalization(\n",
    "        axis=bn_axis, epsilon=1.001e-5, name='conv1/bn')(x)\n",
    "    x = layers.Activation('relu', name='conv1/relu')(x)\n",
    "    x = layers.ZeroPadding2D(padding=((1, 1), (1, 1)))(x)\n",
    "    x = layers.MaxPooling2D(3, strides=2, name='pool1')(x)\n",
    "\n",
    "    x = dense_block(x, blocks[0], name='conv2')\n",
    "    x = transition_block(x, 0.5, name='pool2')\n",
    "    x = dense_block(x, blocks[1], name='conv3')\n",
    "    x = transition_block(x, 0.5, name='pool3')\n",
    "    x = dense_block(x, blocks[2], name='conv4')\n",
    "    x = transition_block(x, 0.5, name='pool4')\n",
    "    x = dense_block(x, blocks[3], name='conv5')\n",
    "\n",
    "    x = layers.BatchNormalization(\n",
    "        axis=bn_axis, epsilon=1.001e-5, name='bn')(x)\n",
    "    x = layers.Activation('relu', name='relu')(x)\n",
    "\n",
    "  \n",
    "    x = layers.GlobalAveragePooling2D(name='avg_pool')(x)\n",
    "    x = layers.Dense(classes, activation='softmax', name='fc1000')(x)\n",
    "    \n",
    "    # Create model.\n",
    "    if blocks == [6, 12, 24, 16]:\n",
    "        model = Model(img_input, x, name='densenet121')\n",
    "    elif blocks == [6, 12, 32, 32]:\n",
    "        model = Model(img_input, x, name='densenet169')\n",
    "    elif blocks == [6, 12, 48, 32]:\n",
    "        model = Model(img_input, x, name='densenet201')\n",
    "    else:\n",
    "        model = Model(img_input, x, name='densenet')\n",
    "\n",
    "    \n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DenseNet121(input_shape=(224,224,3),classes=1000):\n",
    "    return DenseNet([6, 12, 24, 16],input_shape,classes)\n",
    "def DenseNet169(input_shape=(224,224,3),classes=1000):\n",
    "    return DenseNet([6, 12, 32, 32],input_shape,classes)\n",
    "def DenseNet201(input_shape=(224,224,3),classes=1000):\n",
    "    return DenseNet([6, 12, 48, 16],input_shape,classes)\n",
    "model = DenseNet121()\n",
    "#model.summary()\n",
    "#tf.keras.utils.plot_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8.Xception"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Xception: Deep Learning with Depthwise Separable Convolutions](\n",
    "    https://arxiv.org/abs/1610.02357) (CVPR 2017)\n",
    "更多关于这部分的说明[参见](https://www.zhihu.com/question/62478193/answer/200145164)\n",
    "关于分组卷积在分组卷积相关的论文中自然是说分组好，这里却有新的观点，分组后信息各自一体，无互相沟通，无法充分利用channel的信息；在shuffleNet中，却是先将channel打散再分组。shufflenet将在后边写。顺便说一名，本篇大作的作者是keras的创造者，所以本代码用keras实现最合适不过。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Xception(input_shape=(299,299,3),classes=1000):\n",
    "    \"\"\"Instantiates the Xception architecture.\n",
    "     Note that the default input image size for this model is 299x299.\n",
    "    # Arguments\n",
    "        \n",
    "        input_shape: optional shape tuple, only to be specified\n",
    "            if `include_top` is False (otherwise the input shape\n",
    "            has to be `(299, 299, 3)`.\n",
    "            It should have exactly 3 inputs channels,\n",
    "            and width and height should be no smaller than 71.\n",
    "            E.g. `(150, 150, 3)` would be one valid value.\n",
    "        \n",
    "        classes: optional number of classes to classify images\n",
    "            into, only to be specified if `include_top` is True,\n",
    "            and if no `weights` argument is specified.\n",
    "    # Returns\n",
    "        A Keras model instance.\n",
    "    # Raises\n",
    "        ValueError: in case of invalid argument for `weights`,\n",
    "            or invalid input shape.\n",
    "        RuntimeError: If attempting to run this model with a\n",
    "            backend that does not support separable convolutions.\n",
    "    \"\"\"\n",
    "        \n",
    "    img_input = layers.Input(shape=input_shape)\n",
    "    \n",
    "\n",
    "    channel_axis = 1 if tf.keras.backend.image_data_format() == 'channels_first' else -1\n",
    "\n",
    "    x = layers.Conv2D(32, (3, 3),\n",
    "                      strides=(2, 2),\n",
    "                      use_bias=False,\n",
    "                      name='block1_conv1')(img_input)\n",
    "    x = layers.BatchNormalization(axis=channel_axis, name='block1_conv1_bn')(x)\n",
    "    x = layers.Activation('relu', name='block1_conv1_act')(x)\n",
    "    x = layers.Conv2D(64, (3, 3), use_bias=False, name='block1_conv2')(x)\n",
    "    x = layers.BatchNormalization(axis=channel_axis, name='block1_conv2_bn')(x)\n",
    "    x = layers.Activation('relu', name='block1_conv2_act')(x)\n",
    "\n",
    "    residual = layers.Conv2D(128, (1, 1),\n",
    "                             strides=(2, 2),\n",
    "                             padding='same',\n",
    "                             use_bias=False)(x)\n",
    "    residual = layers.BatchNormalization(axis=channel_axis)(residual)\n",
    "\n",
    "    x = layers.SeparableConv2D(128, (3, 3),\n",
    "                               padding='same',\n",
    "                               use_bias=False,\n",
    "                               name='block2_sepconv1')(x)\n",
    "    x = layers.BatchNormalization(axis=channel_axis, name='block2_sepconv1_bn')(x)\n",
    "    x = layers.Activation('relu', name='block2_sepconv2_act')(x)\n",
    "    x = layers.SeparableConv2D(128, (3, 3),\n",
    "                               padding='same',\n",
    "                               use_bias=False,\n",
    "                               name='block2_sepconv2')(x)\n",
    "    x = layers.BatchNormalization(axis=channel_axis, name='block2_sepconv2_bn')(x)\n",
    "\n",
    "    x = layers.MaxPooling2D((3, 3),\n",
    "                            strides=(2, 2),\n",
    "                            padding='same',\n",
    "                            name='block2_pool')(x)\n",
    "    x = layers.add([x, residual])\n",
    "\n",
    "    residual = layers.Conv2D(256, (1, 1), strides=(2, 2),\n",
    "                             padding='same', use_bias=False)(x)\n",
    "    residual = layers.BatchNormalization(axis=channel_axis)(residual)\n",
    "\n",
    "    x = layers.Activation('relu', name='block3_sepconv1_act')(x)\n",
    "    x = layers.SeparableConv2D(256, (3, 3),\n",
    "                               padding='same',\n",
    "                               use_bias=False,\n",
    "                               name='block3_sepconv1')(x)\n",
    "    x = layers.BatchNormalization(axis=channel_axis, name='block3_sepconv1_bn')(x)\n",
    "    x = layers.Activation('relu', name='block3_sepconv2_act')(x)\n",
    "    x = layers.SeparableConv2D(256, (3, 3),\n",
    "                               padding='same',\n",
    "                               use_bias=False,\n",
    "                               name='block3_sepconv2')(x)\n",
    "    x = layers.BatchNormalization(axis=channel_axis, name='block3_sepconv2_bn')(x)\n",
    "\n",
    "    x = layers.MaxPooling2D((3, 3), strides=(2, 2),\n",
    "                            padding='same',\n",
    "                            name='block3_pool')(x)\n",
    "    x = layers.add([x, residual])\n",
    "\n",
    "    residual = layers.Conv2D(728, (1, 1),\n",
    "                             strides=(2, 2),\n",
    "                             padding='same',\n",
    "                             use_bias=False)(x)\n",
    "    residual = layers.BatchNormalization(axis=channel_axis)(residual)\n",
    "\n",
    "    x = layers.Activation('relu', name='block4_sepconv1_act')(x)\n",
    "    x = layers.SeparableConv2D(728, (3, 3),\n",
    "                               padding='same',\n",
    "                               use_bias=False,\n",
    "                               name='block4_sepconv1')(x)\n",
    "    x = layers.BatchNormalization(axis=channel_axis, name='block4_sepconv1_bn')(x)\n",
    "    x = layers.Activation('relu', name='block4_sepconv2_act')(x)\n",
    "    x = layers.SeparableConv2D(728, (3, 3),\n",
    "                               padding='same',\n",
    "                               use_bias=False,\n",
    "                               name='block4_sepconv2')(x)\n",
    "    x = layers.BatchNormalization(axis=channel_axis, name='block4_sepconv2_bn')(x)\n",
    "\n",
    "    x = layers.MaxPooling2D((3, 3), strides=(2, 2),\n",
    "                            padding='same',\n",
    "                            name='block4_pool')(x)\n",
    "    x = layers.add([x, residual])\n",
    "\n",
    "    for i in range(8):\n",
    "        residual = x\n",
    "        prefix = 'block' + str(i + 5)\n",
    "\n",
    "        x = layers.Activation('relu', name=prefix + '_sepconv1_act')(x)\n",
    "        x = layers.SeparableConv2D(728, (3, 3),\n",
    "                                   padding='same',\n",
    "                                   use_bias=False,\n",
    "                                   name=prefix + '_sepconv1')(x)\n",
    "        x = layers.BatchNormalization(axis=channel_axis,\n",
    "                                      name=prefix + '_sepconv1_bn')(x)\n",
    "        x = layers.Activation('relu', name=prefix + '_sepconv2_act')(x)\n",
    "        x = layers.SeparableConv2D(728, (3, 3),\n",
    "                                   padding='same',\n",
    "                                   use_bias=False,\n",
    "                                   name=prefix + '_sepconv2')(x)\n",
    "        x = layers.BatchNormalization(axis=channel_axis,\n",
    "                                      name=prefix + '_sepconv2_bn')(x)\n",
    "        x = layers.Activation('relu', name=prefix + '_sepconv3_act')(x)\n",
    "        x = layers.SeparableConv2D(728, (3, 3),\n",
    "                                   padding='same',\n",
    "                                   use_bias=False,\n",
    "                                   name=prefix + '_sepconv3')(x)\n",
    "        x = layers.BatchNormalization(axis=channel_axis,\n",
    "                                      name=prefix + '_sepconv3_bn')(x)\n",
    "\n",
    "        x = layers.add([x, residual])\n",
    "\n",
    "    residual = layers.Conv2D(1024, (1, 1), strides=(2, 2),\n",
    "                             padding='same', use_bias=False)(x)\n",
    "    residual = layers.BatchNormalization(axis=channel_axis)(residual)\n",
    "\n",
    "    x = layers.Activation('relu', name='block13_sepconv1_act')(x)\n",
    "    x = layers.SeparableConv2D(728, (3, 3),\n",
    "                               padding='same',\n",
    "                               use_bias=False,\n",
    "                               name='block13_sepconv1')(x)\n",
    "    x = layers.BatchNormalization(axis=channel_axis, name='block13_sepconv1_bn')(x)\n",
    "    x = layers.Activation('relu', name='block13_sepconv2_act')(x)\n",
    "    x = layers.SeparableConv2D(1024, (3, 3),\n",
    "                               padding='same',\n",
    "                               use_bias=False,\n",
    "                               name='block13_sepconv2')(x)\n",
    "    x = layers.BatchNormalization(axis=channel_axis, name='block13_sepconv2_bn')(x)\n",
    "\n",
    "    x = layers.MaxPooling2D((3, 3),\n",
    "                            strides=(2, 2),\n",
    "                            padding='same',\n",
    "                            name='block13_pool')(x)\n",
    "    x = layers.add([x, residual])\n",
    "\n",
    "    x = layers.SeparableConv2D(1536, (3, 3),\n",
    "                               padding='same',\n",
    "                               use_bias=False,\n",
    "                               name='block14_sepconv1')(x)\n",
    "    x = layers.BatchNormalization(axis=channel_axis, name='block14_sepconv1_bn')(x)\n",
    "    x = layers.Activation('relu', name='block14_sepconv1_act')(x)\n",
    "\n",
    "    x = layers.SeparableConv2D(2048, (3, 3),\n",
    "                               padding='same',\n",
    "                               use_bias=False,\n",
    "                               name='block14_sepconv2')(x)\n",
    "    x = layers.BatchNormalization(axis=channel_axis, name='block14_sepconv2_bn')(x)\n",
    "    x = layers.Activation('relu', name='block14_sepconv2_act')(x)\n",
    "\n",
    "    \n",
    "    x = layers.GlobalAveragePooling2D(name='avg_pool')(x)\n",
    "    x = layers.Dense(classes, activation='softmax', name='predictions')(x)\n",
    "    \n",
    "    # Create model.\n",
    "    model = Model(img_input, x, name='xception')\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Xception()\n",
    "#model.summary()\n",
    "#tf.keras.utils.plot_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面将接着写一些轻量级的模型：squeezenet,mobilenet,shufflenet,之前的Xception模型参数也很精简。相关介绍[参见](https://zhuanlan.zhihu.com/p/32746221)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9.1 squeezenet "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参数是alexnet的1/50，但精度相当。关于说明[详见](https://zhuanlan.zhihu.com/p/31558773)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input,Convolution2D,Activation,MaxPooling2D,Dropout,GlobalAveragePooling2D,concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sq1x1 = \"squeeze1x1\"\n",
    "exp1x1 = \"expand1x1\"\n",
    "exp3x3 = \"expand3x3\"\n",
    "relu = \"relu_\"\n",
    "def fire_module(x, fire_id, squeeze=16, expand=64):\n",
    "    s_id = 'fire' + str(fire_id) + '/'\n",
    "\n",
    "    if tf.keras.backend.image_data_format() == 'channels_first':\n",
    "        channel_axis = 1\n",
    "    else:\n",
    "        channel_axis = 3\n",
    "    \n",
    "    x = Convolution2D(squeeze, (1, 1), padding='valid', name=s_id + sq1x1)(x)\n",
    "    x = Activation('relu', name=s_id + relu + sq1x1)(x)\n",
    "\n",
    "    left = Convolution2D(expand, (1, 1), padding='valid', name=s_id + exp1x1)(x)\n",
    "    left = Activation('relu', name=s_id + relu + exp1x1)(left)\n",
    "\n",
    "    right = Convolution2D(expand, (3, 3), padding='same', name=s_id + exp3x3)(x)\n",
    "    right = Activation('relu', name=s_id + relu + exp3x3)(right)\n",
    "\n",
    "    x = concatenate([left, right], axis=channel_axis, name=s_id + 'concat')\n",
    "    return x\n",
    "\n",
    "\n",
    "# Original SqueezeNet from paper.\n",
    "\n",
    "def SqueezeNet(input_shape=(299,299,3),classes=1000):\n",
    "    \"\"\"Instantiates the SqueezeNet architecture.\n",
    "    \"\"\"\n",
    "        \n",
    "    \n",
    "    img_input = Input(shape=input_shape)\n",
    "    \n",
    "\n",
    "    x = Convolution2D(64, (3, 3), strides=(2, 2), padding='valid', name='conv1')(img_input)\n",
    "    x = Activation('relu', name='relu_conv1')(x)\n",
    "    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name='pool1')(x)\n",
    "\n",
    "    x = fire_module(x, fire_id=2, squeeze=16, expand=64)\n",
    "    x = fire_module(x, fire_id=3, squeeze=16, expand=64)\n",
    "    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name='pool3')(x)\n",
    "\n",
    "    x = fire_module(x, fire_id=4, squeeze=32, expand=128)\n",
    "    x = fire_module(x, fire_id=5, squeeze=32, expand=128)\n",
    "    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name='pool5')(x)\n",
    "\n",
    "    x = fire_module(x, fire_id=6, squeeze=48, expand=192)\n",
    "    x = fire_module(x, fire_id=7, squeeze=48, expand=192)\n",
    "    x = fire_module(x, fire_id=8, squeeze=64, expand=256)\n",
    "    x = fire_module(x, fire_id=9, squeeze=64, expand=256)\n",
    "    \n",
    "    \n",
    "    x = Dropout(0.5, name='drop9')(x)\n",
    "\n",
    "    x = Convolution2D(classes, (1, 1), padding='valid', name='conv10')(x)\n",
    "    x = Activation('relu', name='relu_conv10')(x)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Activation('softmax', name='loss')(x)\n",
    "   \n",
    "\n",
    "    model = Model(img_input, x, name='squeezenet')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SqueezeNet()\n",
    "#model.summary()\n",
    "#tf.keras.utils.plot_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.2 mobilenet v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9.13 ShuffleNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[论文](https://arxiv.org/pdf/1707.01083.pdf)ShuffleNet: An Extremely Efficient Convolutional Neural Network for Mobile\n",
    "Devices "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
