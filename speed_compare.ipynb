{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本文将对比tf.data与tf.keras中keras读数据方式下那种速度快，具体有三点：\n",
    "1. tf.data与keras生成器读数据速度对比\n",
    "2. tf.data包装后的keras生成器与原始生成器速度对比\n",
    "3. model.fit 与 model.fit_generator分别使用以上数据的实验"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1、准备本文所用数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (60000,) (10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "(train_x,train_y),(test_x,test_y) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "print(train_x.shape,train_y.shape,test_x.shape,test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2、准备tf.data数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.from_tensor_slices((train_x,train_y))\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((test_x,test_y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.shuffle(buffer_size=1000).batch(256).prefetch(buffer_size=1000).repeat()\n",
    "test_ds = test_ds.batch(256).prefetch(buffer_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 28, 28) (256,)\n",
      "<RepeatDataset shapes: ((None, 28, 28), (None,)), types: (tf.uint8, tf.uint8)>\n"
     ]
    }
   ],
   "source": [
    "#检查数据\n",
    "for data,label in test_ds.take(1):\n",
    "    pass\n",
    "print(data.shape,label.shape)\n",
    "np.testing.assert_array_almost_equal(data,test_x[:256,...])#不返回报错信息表示数据相等\n",
    "np.testing.assert_array_almost_equal(label,test_y[:256])\n",
    "print(train_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3、keras生成器读数据方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = tf.keras.preprocessing.image.ImageDataGenerator()#不做任何数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train_x=np.expand_dims(train_x,-1)# keras生成器读数据要求输入形状是rank=4\n",
    "new_test_x=np.expand_dims(test_x,-1)\n",
    "train_flow=gen.flow(new_train_x,train_y,batch_size=256,shuffle=True)#与tf.data中batch相同大小，并且shuffle\n",
    "test_flow=gen.flow(new_test_x,test_y,batch_size=256,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras_preprocessing.image.numpy_array_iterator.NumpyArrayIterator object at 0x0000025F0F253E48>\n"
     ]
    }
   ],
   "source": [
    "#检查数据\n",
    "data,label= next(test_flow)\n",
    "np.testing.assert_array_almost_equal(data,new_test_x[:256,...])#不返回报错信息表示数据相等\n",
    "np.testing.assert_array_almost_equal(label,test_y[:256])\n",
    "print(train_flow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4、tf.data包装keras生成器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = tf.keras.preprocessing.image.ImageDataGenerator()\n",
    "wrap_train_ds = tf.data.Dataset.from_generator(lambda:gen.flow(new_train_x,train_y,batch_size=256,shuffle=True),\n",
    "    output_types=(tf.uint8, tf.uint8),\n",
    "    output_shapes = ([None,28,28,1],[None])\n",
    ")\n",
    "wrap_test_ds = tf.data.Dataset.from_generator(lambda:gen.flow(new_test_x,test_y,batch_size=256,shuffle=False),\n",
    "    output_types=(tf.uint8, tf.uint8),\n",
    "    output_shapes = (tf.TensorShape([None,28,28,1]),tf.TensorShape([None]))#tf.TensorShape可以不用\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 28, 28, 1) (256,)\n",
      "<DatasetV1Adapter shapes: ((None, 28, 28, 1), (None,)), types: (tf.uint8, tf.uint8)>\n"
     ]
    }
   ],
   "source": [
    "#检查数据\n",
    "for data,label in wrap_test_ds.take(1):\n",
    "    pass\n",
    "print(data.shape,label.shape)\n",
    "np.testing.assert_array_almost_equal(data,new_test_x[:256,...])#不返回报错信息表示数据相等\n",
    "np.testing.assert_array_almost_equal(label,test_y[:256])\n",
    "print(wrap_train_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5、有了三种数据开始比较速度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_timeit_steps = 1000\n",
    "\n",
    "def timeit(ds, steps=default_timeit_steps):\n",
    "    start = time.time()\n",
    "    it = iter(ds)\n",
    "    for i in range(steps):\n",
    "        batch = next(it)\n",
    "        if i%10 == 0:\n",
    "            print('.',end='')\n",
    "    print()\n",
    "    end = time.time()\n",
    "\n",
    "    duration = end-start\n",
    "    print(\"{} batches: {} s\".format(steps, duration))\n",
    "    print(\"{:0.5f} samples/s\".format(256*steps/duration))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....................................................................................................\n",
      "1000 batches: 1.3849620819091797 s\n",
      "184842.60569 samples/s\n"
     ]
    }
   ],
   "source": [
    "timeit(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....................................................................................................\n",
      "1000 batches: 4.649678945541382 s\n",
      "55057.56483 samples/s\n"
     ]
    }
   ],
   "source": [
    "timeit(train_flow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....................................................................................................\n",
      "1000 batches: 6.324928283691406 s\n",
      "40474.76723 samples/s\n"
     ]
    }
   ],
   "source": [
    "timeit(wrap_train_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**对比结论**\n",
    "显然tf.data是最快的，wrap后的生成器最慢，我们肯定是要用tf.data的。关于wrap后比原始keras读数据的方式慢的原因，可能是因为这个生成器有问题，具体不再深究，所以我们就直接用tf.data了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#明天对tf.data进行改造，还要进行训练，查看效果"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
